 Hello, everybody. Welcome to This Week in Svelte. My name is Enrico, and I have a special new co-host for all of you. Please give a warm welcome to Paolo Ricciuti. Hi, everyone. I'm Paolo, and I will start to co-host This Week in Svelte, and I hope I can provide you with some useful information. Yeah, we're all doing our best to just learn stuff together. In case you don't know, Paolo is one of the co-creators of SvelteLab.com or is it .io? .dev .dev, I'm wrong in both accounts yeah I am one of the co-creators of SvelteLab.dev which is a super charge repl for Svelte and SvelteKit and together with me Antonio Sarshevik did SvelteLab and I just to bring everyone to up to date. I work as a full-time developer and luckily I work with Svelte. I work at Main Matter, which is a very cool company. And the coolest thing is that not only we work with Svelte, but we also teach other companies how to use Svelte. And I'm very fortunate to be able to do this. Wow. We're all learning Svelte and teaching Svelte now. Isn't that wonderful? Yeah, this is the year of Svelte. Maybe next year will be the year of Linux. So today's agenda is the changelog, which will be brief, quick facts and announcements, followed by a community showcase, discussions and questions and answers. So let's begin with the changelog. Drumroll breeze, there's no changelog today, which is good. So since last Friday, there were some releases for Svelte and SvelteKit, but not this week, which I suppose is a good thing. Then again, if you want more releases, I guess they got to go ship some more features and patch them too, I guess. This is what I say for internal projects. If I'm spinning my thumbs, I'm at work, at my job and I have nothing to patch, the only thing to do next is ship more bugs. That way you can patch them as well. And obviously every contribution is always appreciated. so even if those are bugs moving on to quick facts and announcements Let go So we have a quick fact for you today. And I was looking through WebAIM, which is a very reputable source of accessibility information. And did you know that they have a regular interval of surveys for screen reader usage? So if you go to this site, which I'll share in the chat, you can see some very interesting demographics and stats on screen reader usage. The most important one to me, a Mac user, is the fact that JAWS, a Windows screen reader, is the most popular. So down here to screen readers commonly used, you can see JAWS is utilized by 70% of respondents. Second, by not a far margin, is NVDA, which I think started off as a Firefox screen reader, but it's also usable on Chromium browsers. And then third is voiceover for macOS and iOS, Narrator is built into Windows, and then the rest will flow. You hardly see TalkBack on Android make a dent in this graph. So the point here is when you're testing screen readers, JAWS is a very good choice to test in. I know other users also use Dragon, naturally speaking, but with these numbers, you can't go wrong with JAWS. So unfortunately for myself, being on Mac, VoiceOver is the most accessible to me. but in order to test JAWS on macOS, I need to install VirtualBox with Windows 11 and load Edge or Chrome to test JAWS against. Otherwise, if you have a Windows machine, you're done. You got Windows, you can install the trial of JAWS and that way you can utilize JAWS as a text environment. And I feel also that probably it should also be up to something like Apple to provide us with a better way to do these things because I mean accessibility is very important and it's also I think it's also a job for for the who makes the computer to allows everyone to use the most accessible thing yeah I'm surprised JAWS isn't on macOS but I guess they have a certain demographic they're targeting, which is Windows users. And that has probably a lot to do with affordability as well because Windows PCs tend to be powerful enough yet affordable enough for most users You can also see some other interesting stats on here I think I show you one more graph and then we'll move on just for sake of time. 92% of respondents report they do have a disability. 7% do not. They're probably people like me who are just using these for testing purposes, but I am also a user of voiceover. The number one respondent reports total blindness, 79%. This is why they use screen readers. However, there are a non-trivial amount of people who have low vision or just vision deficiencies, but also use a screen reader paired with some other assistive technology. The one I can think of top of my head is a magnifier. So if you're zooming in a lot to websites like this, you usually zoom in as well as use a screen reader together. That way, when you see something and you don't see the full image, such as a picture, the alt text can be read out loud to you, even though you're zoomed into one part and the rest is sort of hard to see. Hopefully that adds a bit of background so that when you actually use a screen reader, you know who you're testing for and why. And also interesting, most of these users are very adept and literate when it comes to the internet and screen reader usage. So they understand the keyboard shortcuts, they understand how to jump to skip links, and they will very likely use these features. That's why things like hyperlinks on a page should be descriptive. Do not put a hyperlink on your page like this. A, href, some site, just like some site.com, and then click here. Don't do this because when a screen reader user is a power user, they're going to scan all of the links on the page and when they see this link the screener will say click here but it has no indication of where it takes you because the label just says click here. It should say something like go to some site.com or the article. So if you're going to an article slash article, article cook soup then the description could be how to cook soup. Something like that. Something more descriptive. Maybe in a future week we'll talk about how to actually test with these tools end to end. Wouldn't that be fun? Yeah. Also, I think accessibility in general. When someone says that HTML is not a programming language I kind of agree but also it I think one of the most difficult things in web development because getting HTML right is very very difficult and very very key to allow everyone to have a joyful experience on the web. Indeed. How can HPL not be a programming language? You're sending signals to a computer. You're sending instructions to a machine. It's a programming language. Yeah. also it actually has a script tag i mean so technically it's a superset of javascript it also has if statements it can do things like if ie11 yeah i mean it's nightmare fuel but yes all good so that was a quick fact now let's move on to a special guest in community showcase you knew who you are, please raise your hand and join us. Okay, hi. So I'm Oli. I am a designer turned developer. And in recent roles, like at Twitch, I built UI and front-end stuff for broadcast tools and solutions. But now I'm working for myself, so I get to come up with my own job title. And currently I'm going with Supreme Unicorn, but feel free to just throw out ideas because I'm still playing around with that. And it's only my wife that has to agree with me. So what I want to talk about today is Svelte podcast, which I was, I started building for Hackathon actually, that happened early this year, inspired by some challenges that I was having at the time on a project for my wife. And for me, side projects are pretty much synonymous with wife projects and her endeavours and aspirations. And I'm usually having fun figuring out how to build for that. And so that's what I'm going to be talking about. Awesome. So a lot of this revolves around the audio element and working with that. And there's a lot of good stuff that we get for free with the DOM. We were just talking about how HTML is a programming language and I couldn't agree more. But there are a lot of limitations with that too. I mean, we get free stuff like playing and pausing. I don't know if I'll be able to take audio when I play it. We get a scrub-able timeline, audio management, like playback speed. There's a lot of free stuff that we get. But the challenge comes when you want to extend that or when you want consistency. And consistency can be for the operating system that the user is on or for

 for the project that you are working on. And so if you want consistency in your project, then you're gonna have a hard time when the differences in implementations vary quite a lot from Chrome to Firefox and Safari, both in style and to some extent feature set. Like Firefox doesn't have the ability to change speed. And Safari has things like airplay and depending on the size of the audio player, you can skip forwards or backwards in time. And so when I was implementing a podcast functionality for my wife's coaching company, we had to try and figure out how we were going to do this. And with the hackathon, I wanted to be able to abstract this into a way that can be used by other people. And so this is just going to be some of the challenges that I faced, the problem solving that I went through, and the meeting the expectations that Svelte developers usually have when consuming libraries. But importantly, I think that it's worth noting that I don't think the right abstraction equals the solution. There are plenty of things that I find that work, but when I'm trying to build an abstraction that can be consumed in unknown ways, there are other considerations there. So some of the expectations that Svelte developers have is reactivity, ideally in both directions. like we like our input fields with binding values to them and knowing that both ends of the both the value in the user input and also the value in our state is going to be sync. We like simpler leading abstractions. We like having our like small 20 line components compared to like a 50 line JSX component and keeping that simple and reusable and abstracting away like the boilerplate that we might have in other frameworks. And then leveraging platform defaults. We like being able to be compatible with or extend or build on top of the work done by browser companies so that we can build on top of that and be compatible with that, which is something that's always going to be around rather than whatever solution that we come up with that might not be around in the future. So one tool I like to work with when I'm trying to problem-solve in this way is working backwards and pretending that the solution is already there. And so I have an example over here. I can catch my breath. I'm talking a little bit fast. Sorry. I know that feels. By the way please zoom in to the sharing code Yep So here I won go too much through this one because this one just a contrived example Well it not actually contrived It copied and pasted from an early version that I was working on And essentially, I'm just building the controls and functionality that I wanted at the time I was styling this. And then I'm just creating empty functions that console.log what I'm trying to do, whatever I want to have an action. And this kind of gave me a shape for what the API should look like, what kind of functionality I'd need and what I want that the audio element isn't providing. And a lot of this is just duplicating functionality, unfortunately. And so that was something that I had in mind. So I just want to go through some of the abstraction attempts I have, and I don't have too much time so I'll go through them fairly quickly. And hopefully that will be valuable to you guys. So my instinct was to just work with the JavaScript audio API. And essentially this is just creating a new instance of an audio element. And this is like a virtual like DOM node. And then we just pass it the audio source. And we can, we can mutate this. We can like do like audio source equals and then pass in a new value. And so this can be extended. And we can also pass this around in things like context so that we can like initialize our audio, set it in context. and then in the child component we can retrieve that and then then manage it and consume it. So I don't know if you're able to hear audio but if I play you can hear the intro to syntax and then pause and it works as you'd expect. However things like the current time like values of attributes aren't really syncing and these are things that we're going to need to be able to build things like a podcast player because the audio element has things like these timestamps. So this just wasn't quite good enough. So I found that the challenges here were a lot of orchestration of components that felt very React-esque where we had to have some kind of provider up top and then we were consuming that and had a lot of opinions around how you structure your code and I thought for this abstraction I wanted to be able to solve the problem well without having to have too many opinions over things like that. I also had some issues with race conditions where I had multiple for audio files playing sometimes and though I'm sure there were solutions for these things I took them as like red flags to just continue looking at other solutions and I glad I did So the next one was to work with element actions I consumed a lot of these You might be familiar with things like use enhance for like form elements and there a lot of power there and I never actually created one and so I don't have a full example for this. I couldn't find it in my git history and so I've just copied and pasted the one from the docs and renamed values so that I can use it as a reference. So essentially what we're doing here is we have an audio element, and we have an audio element and then we're using the use action to bind a function that we've created to it. And this function provides us with the element node and we can also pass in options. So if we had options here, we can have like, double square brackets, so source equals, then we can pass in our source here and then we can pass in other values and so on so like this is a very clean API it felt very sveltey to be doing things this way however again I think I faced some challenges with bi-directional reactivity and it felt like I was puppeteering this element rather than having a reactive relationship between the audio element and the kind of extensions that i wanted to add on top of it um so we kind of spoil as felt devs there's a lot of stuff that we get for free that just works and uh abstracts away the like complexities of reactive code um a lot of things are as simple as just placing a dollar sign before a value uh or throwing things into a store and then we just get reactivity out of the out of the box and uh i wanted to be be able to like uh i wanted to continue that simplicity and i realized i could probably use it to at least prototype something um and so i ended up just like uh throwing a store into uh a bind so this is essentially binding the value uh of the audio element that it's referencing to a writable store so this means that when the audio element is mounted in the dom uh it will pass a reference to itself to whatever it's bound to. In this case, a writable store. And this is a super slick and super simple solution. Here you can see the example in a REPL. I can share the links to all these REPLs after if you like. And so essentially we're creating an empty store. We're just using JavaScript here, no TypeScript and so there no typings here And then we can reference that store right away and play and pause it Now this works here because they actions they not they not consuming they not calling the data here we have to have a ternary my mind is drawing a blank right now what these are actually called an operator to know that if this is undefined we're not going to continue trying to access it and here when we play and pause we get similar expectations that we did earlier however this time we actually have an audio element that's here. An audio element is in the DOM and it exists and we're just controlling it rather than creating a virtual one like we were earlier with the audio API. And so this was like quite a, this was a big step towards what the kind of like a relationship that I wanted. We had like better bi-directional reactivity. It was a simple API. However, it was quite inconsistent when consuming it, because here it's a much simpler example where everything is all in one component. But when you start breaking this out into other files so that we can reference this store from other components, there were a lot of things that you had to contend with, like if there was no value, if there was no reference to an element, you had to wait for there to be a value or keep subscribing to it until there is a change. There were a lot of things you just had to account for as worst case scenarios. and whilst it was a big step in the right direction in terms of using it, there were a lot of gotchas that proved to make the code a bit messy when consuming it. So I dug a bit deeper into the slides, into the docs, and admittedly I'm not the kind of person who reads the docs very much ahead of time. I usually go there when I have a thing I need to fix. I like getting stuck into things right away. And so I learned a few things about stores that I wasn't fully aware of, especially with readable stores. So this is the section I'm talking about, but there's not too much here that I was talking about right now. What I want to talk about is how I fix my mental model around stores and how beforehand I was referring to them as readable, writable, and derived, which is what they're called, but my expectation was that readable stores hold readable data, writable stores hold writable data, and so on. And you might have the the same understanding of stores, but I figured that my mental model would be better served if I thought of them as describing the relationship that the store has with the outside world, the rest of your code base.

 that I mean rather than readable stores holding readable data, readable stores are readable by the outside world and they control their own state and writable stores are written to by the outside world but can also handle their own state and so this was an important change because because readable stores have things like a set function inside them so that when you initialize them you can initialize them with a value and you can also use things like like event listeners so that you can update itself when certain things change, in this case, DOM node. So this was a much simpler API. We had our bidirectional reactivity and predictable usage. I've got a code example here that I didn't actually show. This is great because when the audio element in this store is created, so we've got a readable store here, it does start with null, but as soon as it's initialized, it creates its own audio element itself. Now this does exist in the DOM, and if we go over to the elements tab in Chrome, let me just pull this over so we can see it better. This is a little bit more messy than it would be in a project because we're working with the REPL where there are iframes involved. But as you can see here, we have got an actual audio element that's been created using the ID that we have. And this is particularly valuable because it behaves just how we had in the previous version with the writable store, the initial audio element. And we can make sure that we're always referencing the same element by giving an ID. And if we create the element, we can assign that ID. If we read the element, we can read it based on that ID. And so we know that when the store is created, then we're referencing that ID and using it straight away. I'll share a better example of this in a moment. But essentially this works as expected. So even though we don't see the audio player anymore, it plays and pauses as expected. there is there is just one ingredient left out here which is it being extendable meaning being able to build on top of what the audio player already does that this currently doesn't support that because all this is really doing is just having a cleaner like it cleaner and tidying up and controlling the the creation and deletion and mutation of the audio element It not actually allowing us to do that much more than we already had But that changes when we change it to a derived store, because then you can derive things like preferences for the audio element, and then you can return a new fresh reference to the same audio element when those values change. And so if I go over to my encode base, I've got better syntax highlighting. And this is the actual version I have right now. Essentially, we have a derived store here, which is very similar to the readable store. However, it starts with the stores that we're doing, which in this case is an empty writable store that can either be null or it has a source value for the audio file. a starting at time if you want to skip to a certain point in the audio, the playback rate, the volume and the auto playing and so on. And so when the audio element is mounted, it sources from these values. So aside from the readable store that I just shared with you guys, the derived store here is very similar. It just references these values from this other store. And this means we can extend this by adding additional stores in the future or building on top of this other one or deriving from this audio element store. It's very encapsulated into a single entity. So this is a very simple solution. I would hope that if you're familiar with Savelle, it would be fairly easy to grok this and understand it so that you could build on top of it yourself or leverage these. But I found it interesting trying to find the right abstraction here. There are several solutions along the way that I've just shared that probably could have been good enough if I was just building a small project or just a solution for one specific use case. But my goal here was to build an abstraction that is easier to consume and more predictable and easier to understand from the outside. when you're consuming it. There are still some unresolved challenges here, such as performance, accessibility, being pluggable, because at the moment it extensible within the library but there not a clear way to extend it for those using it from the library perspective Like if you install this as a package there not a clear or opinionated way of how to leverage this. And then headers UI components. There are some challenges around things like the playhead for an audio element that I'm currently working on. But yeah, so at the moment i snatched up spotpodcast.com if you want to like download this and uh like check this out or look at the code yourself then it's all available there i've actually taken a break from this over the past couple of weeks to test it on another side project um to like build and consume this library myself and and actually dog food it uh in addition to the knowing project and so uh yeah i uh very cool thank you for presenting ollie I like how concise and well put together your slides were, as well as sharing us the journey you went through to find that ideal Svelte API. It was very pleasant to watch that journey unfold. Thank you. Yeah, I practiced a couple of times, and I'm sure I missed out several things that I wanted to share. But yeah, this is the first time I've ever presented, I think, to other devs. Usually I'm speaking with people like my wife, who aren't technically savvy. it's all good sounds like yeah you have a bit of a unicornish background being a designer and developer is that right uh so well it's fun to play around with the unicorn name but yeah i uh i really enjoy uh like building ui and uh i'm usually so excited to get things working get getting things in the browser that uh i'm usually throwing things harder challenges at other devs once we've got past that. So yeah, that's my sweet spot, the gap between design and dev. Cool. And it seems like the big takeaway here is you've come up with a derived store that contains both the readable audio player, but also you can combine it with other stores to have a full controllable player. Is that right? Is that the big takeaway? Yeah. So the main value here in the end is that by creating and destroying the audio element from the store's perspective, it can have a complete control over the lifecycle of that element. And in addition to that, it still gives us control over extending that and either sourcing from the attributes of it in a reactive way so that we have things like the One of the smallest challenges that would seem so simple that you would expect to be native as a React developer is the current playtime. So if I go to... This is a live demo of it actually working. You have the current time that's updating, and that was tricky for me to get in a reactive way without having a bunch of event listeners and so on. and having it in a clean way to consume for just focusing on building the UI that you want. Yeah, it's been a while since I touched audio. Does there happen to be an event listener just for playback elapsed time or some other solution? Yes, well, there are event listeners. And so instead of just having an event listener to update this specific value, what I'm doing is updating a reference to the same audio element within the derived store. And this means that we can keep that all encapsulated within the store and just reference that. Yeah. Very cool. So we're looking at the chat and Paolo, if it's all good, maybe we can say thanks to Oli. So yeah, that's it. Thank you again, Oli, for presenting. Much appreciated. Awesome. Thank you for having me. You can share SveltePodcast.com in the chat, your repos, your repls, and I'll be sure to include them in the YouTube description below. okay let's shift back to this week in svelte and that was community showcase let's move on to this week in discussions we have one sort of mini discussion topic today and that is about uh we're shifting gears majorly get ready it's about artificial intelligence wow but it's a it's a pretty easy that's not that hot so the question was let me just bring this on screen and it's a pleasant one don't worry no hot takes just a lot of realism to be had is ai and specifically large language models and helpful chat is ai helpful for junior developers you know you're getting started into software you have so many questions there are so many concepts that you have to learn all at once. Getting started to software today can be very daunting and challenging. So yeah, AI is like right there, so accessible. It just, you can ask it questions and it gives you sometimes confident good answers and sometimes confident

 correct answers, as we all know. So my response to the question is, it's a double-edged sword. It can be useful. It cannot be useful. But I don't think we should shame people for using AI if they're getting started in their software development journey. However, it should definitely not be a crutch due to its tendency to hallucinate and give confident wrong answers. When you're using AI as a junior, it's okay to use it to get obstacles out of your way. Let's say you're learning CSS and you're not in the mood for JavaScript, you can have AI get you past the JavaScript parts for a short term. And then you can work on learning the CSS solutions in a more traditional way via articles, books, YouTube, courses, teachers, mentors, whatever the case may be. And then you can defer the JavaScript lessons for later as an example. So that's my Yeah, there are certainly some LLMs that can do some tools that can do a better job at it. Like, for example, I love to use find.com with the PH at the start because at least it used to also give you a source. And that's very important because, I mean, if at least if it's hallucinating, you can kind of understand why and where is picking that information. And that I think is very important because, again, if you don't know what you don't know, it's very easy to get sidetracked, to get a wrong understanding of something. something and maybe you can even lose a bunch of time because you might go into a cul-de-sac and not knowing that LLM, that specific LLM is basically joking on you. That's right. Yeah, that's the thing. When you're going into using these tools, especially as a newcomer to software, definitely have that skeptical mindset and be cautious about what's being given to you. And if you intend to learn something, it's okay to defer that lesson for later. Just say like, hey, I need an answer to this MySQL query for now. I'll go and learn MySQL next month. That's a promise you can make to yourself. And with that right attitude, these tools can be very helpful. In fact, they have, in a very very positive way I can say they can help destroy imposter syndrome Because when you getting started you feel like you not good enough or you feel like you making mistakes all the time But when you ask a really well chat tool how to explain a complex process to you in a concise and friendly way, you can even ask it to explain it to you like you're a five-year-old, for example. If that improves your mood and it motivates you and you feel like you finally understand something, how could I say that that's a wrong or bad thing? That's getting yourself in the right mindset is everything when you're in a learning mood. So that's why I think it can be positive. But yeah, absolutely don't lean on it as a crutch. Also, let's not forget that, I mean, LLM can hallucinate, but it's also there are some people that hallucinate too. If you are a junior and you maybe look at a friend of you as an inspiration and you ask them something about code and they can give you wrong answer. So it's not just the AI that can give you wrong answer. So I think it's a tool. You have to know your tools like for everything else. Yeah. By the way, chat, this is an open discussion. So if you'd like to speak on stage with a mic, you're welcome to. Otherwise, we'll just address the chat directly. So for example, Captain writes, the danger is a junior lacks the knowledge to know whether they're asking the right questions. That's absolutely true because you don't know what you don't know and you don't have enough domain knowledge to know that you're asking the right question. And often what comes to mind when we're helping each other out is the XY problem. I think it's .info. Yeah, the XY problem, which is when you're looking for help with human help or AI help, it's important to ask for how to solve X and not ask how to do why. Because if you're asking for help and you give someone a question like, how do I make an audio player work in JavaScript? Or how do I make a button change an icon? Maybe asking for the solution is not as helpful as explaining the problem. That's what the XY problem is all about. And this applies also to chat tools. However, this does not 100% alleviate the knowledge gap. You also don't know what you don't know. Roadmaps are very helpful in this regard. I don't have... There's another really useful website that was shared in Discord this week. I regrettably lost it but there developer roadmaps which give you contextual awareness This is not a perfect guide but it gives you awareness to what you can expose yourself to, to make sure that you're asking the right questions and learning the right steps. And it looks like someone wants to join us on stage. Come on down. Hello, Megan. I just had an idea that, not an idea. I was talking about this with someone the other day about asking track GPT to ask you questions. And this started for me when writing like creative content, but I've started using it when I'm trying to understand something to like asking it to do a task and then asking me to me like to explain something about it or to, or asking me to ask clarifying questions. And that way, not only does it get the context that it needs to build a more appropriate solution, but I can also have to think about some of the challenges and intricacies of what I'm doing beyond just getting a button to change an icon, like you said. But having chat.gpt ask you questions is a tool that I found pretty valuable. Yeah, that's good. Paolo, feel free to fill in the airways for a minute. I'm just going to look up a link. Yeah, I mean, as I've said, there are, in my opinion, different ways to use tools like Sean, Ollie, this is another way of using AI. And you can ask direct questions, you can even ask to explain things in a better way. And just like code, I guess, just like we all learn to code, I think it's a valuable skill to being able to prompt engineer because if you learn how to prompt you can learn how to get the most out of llms in my opinion okay and i just found that guide this was shared by fabian in tech chat earlier this week on discord another interesting resource so if you're very new to like front-end development, this is a very good exposure to concepts that you need to learn and understand, kind of like a roadmap, but at least in a sensible, linear fashion. So these tools, which I shared in the chat are also helpful in that regard I just collapse the previews because it filling up the chat vertical space And we offer one more guest to the stage Thanks Ollie for bringing up that suggestion Let's see. Another person wrote, people can give wrong answers. That's okay. It's about growing one's deterministic thinking. Of course, you got to learn when you're learning. It's all about, it's not about what concepts to learn. It's about how to teach yourself to learn. It's like learning how to learn is the most important thing to have. Yes, come on down. Thanks. This is a great conversation. Am I the only one who feels like we're sort of repeating the early days of learning how to do really good Google searches? And, you know, like, are a way of generating the search results in our conversations that are most efficient. But I totally agree with what everyone's saying. I think for myself, it's been an interesting journey in viewing the AI tools not as a single question and answer, but an ongoing conversation where, like in the case of an app, I have a thread with Chad where it generally remembers everything that we discussed. And it's getting better and better at understanding what my goal is. And in some ways, the goal changes because of what it tells me is possible. Like when I was writing this little utility, I thought it would be maybe interesting to have it run in other languages like Bash. And I asked, could we do that without any other dependencies? Yep, it's possible. And that's the real power of AI is sort of opening at least my mind to what's possible. And then, of course, you still have to do some work. I'm curious before you leave, do you find that with your long running threads, you find yourself like speaking politely and like asking questions, almost humanizing them when working with an AI? Absolutely. And it's really strange. Like, or I don't know, is it strange? Like, it feels like a person. It really, it feels, and they're so polite. And then when the answer is correct, I feel like it deserves to know that. Thanks, Chad, that works great. You know, even if there were some missteps along the way, we both learned something from them, you know, from his hallucinate or her.

 or its hallucinations, and maybe my bad questions. Yeah, I mean, also, I tend to be polite to them to maybe fear of the overlords, but... I always say thank you after a correct answer is given. I think it was Bing's chatbot that came out as showing that they collect data on how polite users are to them. And I think that was around the time that there was some outcry about how toxic it could get. But yeah, I've been thinking about this a lot since I've had an episode on The Verge talking about their guidelines for talking about AI and how they don't think you should humanize AI tools. But I think it's fascinating how hard it is to have a conversation with someone who isn't actually human or something that isn't actually human. And yeah, it's a crazy world we live in at the moment. It is. It's definitely a transitionary one. So it sounds like we should not, as senior or junior developers, we should not forget that what we're doing is we're solving problems for people and AI is a tool. The tool is to help us solve people problems, not machine problems. So on your learning journey, try to surround yourself with more people, more mentors, and eventually your reliance on ChatGPT as your sole source of information will dwindle, hopefully. But it's too early. Maybe that's a hot take for all I know. So someone in chat asked me, what is a crutch? One of the points I made about it should not be a crutch, a crutch is just a metaphor for a walking stick. So if you lean on something too much, even though your leg's not hurting, you might get this phantom pain that your leg is hurting and you need to lean on a literal wooden crutch. So that's what I mean by it. If you're constantly reaching for it as your first way of problem solving, that's probably a negative thing. And during Ollie's presentation, they mentioned how getting deep into problems before reading documentation, it's an interesting workflow, but it sort of resonates with this point as well, because exercising your problem solving skills is an important skill in itself. Of course, you should read the docs too, but the point being made is don't make a crutch habit out of AI. And you can even ask AI to maybe summarize some documentation that you have to read. Yeah my favorite usage of it recently was I was working with a MySQL fork that lacked some features So I asked it hey I constrained I cannot use these MySQL procedures How do I query JSON this way And it actually worked around those constraints and gave me a working solution. So that was fascinating. Also, LLMs are very, very good at changing information. like I very often feed the LLMs a too sharp class to convert them to Zod schema, for example. And it's very easy to also verify the answer in this case. So it's very, very good at it. Indeed. So that's the end of chat, then we'll close the discussion and move on to questions and answers. Thank you for joining the stage and for participating in chat. So let's close the chat and move on to this week in Svelte, questions and answers. Okie dokie. So one of the questions that we got, and I will share my screen, but I think you need to first exactly. Okay, I will share my screen. one of the answers that one of the questions that we do want to answer is how do I use Svelte in a project which is not Svelte? And before doing that, I just want to make this quick, very quick demo. And this is actually a Svelte project. So what you are seeing here is a Svelte project. It's a very simple Svelte project. project, you have your base route, you have a card and inside that card there is a button. It's very, very simple. Just some quick styling. So how can someone use these inside outside Svelte? Because maybe you like to use Svelte, but you don't have the power to choose to use Svelte. And one way you can do it is by compiling your Svelte. Because if you compile your Svelte, actually, every Svelte project is just a JavaScript project. So for example, if you have your if you have your components inside your source lib you can actually tell Vite to compile them into a library And I made this quick VIT config that imports that you have to install the VIT plugin Svelte separately And you cannot use, obviously, you cannot use Svelte package, which is the normal way to build a in Svelte because it does not compile your Svelte components. And this is very, a very quick bit config that just read from source lib config and map over the entries to get some JavaScript file out. So basically it reads every Svelte file and it compiles them to Svelte. And what I did actually is specify a compiler option, which is custom element true. And this small little things here basically allows you to use a Svelte component as a web component, which is standard in browsers. And it's very cool because it's also used by YouTube, like I think. So basically, if we run this script, this is another VIT config. So we have to run actually VIT build with a key parameter. I've made a script so I can do build CL. And if I build this, what it will do is build inside this, this button dot Js card.js and button with the ash. And the reason because there is these extra button here is because button is actually used by card. So the bundler is smart enough to extract that. And if we go to see for example, card.js, it's this mess, and because it's obviously a minified element, but we can actually just use this as a asvelte component inside our JavaScript. So if I go to index.html, this is a very basic index.html, but I can just import this. Actually I can import this inside the module So I can just do import card from this And this is basically importing this card as a Svelte component. So I can just do new card. And I can pass a target, which is document.body for example. And when I save, you can see this is the live server that I this is not as that project, but I do get a basic cart. And obviously, I can also pass some props like the title my title. And when I save, I get the card. So this is a way to use as that component inside a JavaScript only project. But I I mean, this gets probably tedious. And I said that we would have used web components. So I will actually go back to do this. And to allows Velt to compile, as you can see now, it doesn't work. Because this, despite the compiler being a custom element, I have a custom element custom element true. This component is actually not a custom web component. And to make this component be a web component, I just need to do this belt options. And then I can pass custom element. And this custom element, actually, I can just do this and specify a tag name. And the reason because you need a tag name is because then you can use this Svelte component as basically just another Svelte, another HTML component. So, for example, I can say that this component is called this Waking Svelte cart. And when I do this and I save, if I compile again, and we can even add a watch to get a custom to rebuilding. Now, if I go to my index.html, just by importing this card, I can do this week in Svelte card. Actually I think Svelte, uh, web component needs to be this way and

 I get the card. And I can also pass props to it. So I can say, for example, title equal my card. When I save, I get a card. And as you can see, this button, which is as that component is actually rendered here. And web components have their own gotchas like you need JavaScript for them to work. So they are not very progressive and unsaid. But another thing that you can do is also instead of specifying just the tag, you can specify an object where you specify the tag. So I can specify this with insvelled card. And then you can specify some other things. For example, you can specify shadow and shadow can have just two things. It can be shadow none. And if it's shadow none, what it will happen is that you forego the shadow route of the web component. And the shadow route is something that allows you to have contained style like this style that normally in a Svelte component are just scoped to the Svelte component In the case of web component are actually inside the web component and cannot get out And also outside the outside world cannot interfere with the web component. By setting shadow none, you can actually interfere with them. But another cool thing that I think it's even cooler is you can specify props. And if you specify props, you can specify every props that you get in. So for example, let's say that I get another props, which is a complex object. So complex, for example. And this complex object is, for example, of type object, and it's it has a number, which is a number. So this is a complex object and you might think, how do I pass that as HTML? So let's just also show, for example, complex dot number, for example. And obviously now this is undefined, but now what I can do is specify that the props complex is of type object. And I can also say that reflect, it's true. So this means that this object, it's actually an actual attribute on the the web component And now if I go to the index I can pass complex and I can literally pass a string Like I can do this and I can pass a JSON of number which is three And when I save, I get this. So Svelte it's also taking care of this complexity. And obviously you can also select these with JavaScript. Like if I do script, a script tag and I do document dot query selector and I select this week as that card, I get to change the title, for example, another title. And I say save and it works. So this is another way to use a web component to use components, Svelte components, not inside of that project. But I also think that it's very important to understand if it's worth it, because again, each one of these solutions has their own gotchas. And at the end of the day, the thing that Svelte allows Svelte, it's very important, it's more important for developer than users because the end user doesn't even know that you have used Svelte. Obviously it can make your website a bit more performant because it built a certain way But at the end of the day if you have to use something else maybe it better to use something else and not entering these gotcha world Cool. Thanks for demoing that. Everybody give Paolo a hand. There are lots of emojis that exist with hands in them. This is interesting because if people are using PHP projects like WordPress or Rails projects, but you love Svelte, it's very difficult to integrate a compiler framework like Svelte into these other server frameworks. So yeah, Paolo, you definitely highlighted the trade-offs there, which is, should you even use this? Probably not, especially if you're already in another full stack or backend framework. You should probably use the framework you already have because integrating Svelte with it might add complexity overhead. It may decrease speed to market. It's really just to make the developer happy most of the time. But it's nice to see that compiling to web components or compiling to plain JavaScript is totally possible, as demonstrated here. So if you're migrating gradually... Yeah, I mean, if you are using Svelte because you want to move faster as a developer, but then you have to be slowed down by those gotchas, is also when maybe it's not even worth it. Indeed. Okay, now it's time to wrap up. Thanks again, Paolo. Thanks to you. And that was Q&A. Thank you, everybody, and have a nice day.