 If you've been following along with AI news for a while, then you might remember hearing about Devin, the AI service from Cognition Labs that touted itself as the first AI software engineer. It feels like that was an eternity ago, but it actually launched just about a year ago. Is anyone else scared that AI is moving so fast? At the time, the general consensus was that people thought the demo was impressive, but people were also a bit skeptical, both by the claims that were made in the video, but also the price tag, which came in at a hefty $500 per month. Now at the time, that pricing seemed really expensive, at least for hobby or solo programmers. But as time has gone on, the prices for AI have really crept up. For example, CloudMax starts at $100 per month for their introductory plan, with even more expensive plans available. But what's happened since then is that Ignition have recently revamped the pricing of their new Devin 2.0, and they've introduced a pay-as-you-go plan starting at just $20 a month. Now this definitely puts it more in reach for people like me who are excited to try out the absolute best AI tech without chatting out for the expensive enterprise subscriptions. You might have seen the video I made a while back where I tested out the GitHub Copilot coding agent. And since then, I've been working on testing some other agenting coding tools for future videos. So when Cognition reached out to me and asked me if I wanted to do a sponsored video on everything they've been working on in Devon since the initial launch, I thought this was an amazing fit because Devon was already on my list of tools to try anyway. But don't worry, Cognition gave me full creative control over this video and you'll hear my unfiltered opinion about both the good and the bad, as always. So for this video, I thought that we would jump right in and set Devin up for some of the real world projects that I'm currently working on, and then try giving it some tasks and see what the experience is like and how it might be similar or different to other coding agents out there. Let's get into it. So I thought we'd start by looking at the Devin site. And specifically, I want to look a little bit at the pricing and explain this new $20 plan. Oh, look at that. They got the liquid glass thing going. You can't escape it, but it does look good. I can't deny that. So they still have this $500 plan, but now they also have a $20 plan. And I was looking at this a little bit earlier. So basically what the deal is, you pay the $20, but you then have to buy the kind of AI credits on top. So they call these ACUs, agent compute units. And so what that means is basically any time you do any kind of like AI stuff in the Devon platform, it consumes like a little bit of AI credits of this ACU And so when you have the team plan that a month and you get 250 credits When you have the core plan it a month but then you buy the credits on top So once you sign up for the core plan, you then buy these compute units and they cost, it's a little bit down here, they cost $2.25 per unit. And so it makes it a little bit hard to know how much is a compute unit. And that's partly like what I want to show in this video. I want to try out a few tasks and see like how many units does this consume? Like what does this cost in like real world money, so to speak? And is it, is it worth it? I already signed up for the platform. So I'm just going to take you to the dashboard and let you have a look at what it looks like. When you first start with a new account, then they take you through this sort of onboarding process, which is really nice. And one of the things you do is that you connect your GitHub account. So you can do it in two ways, which I actually really like. You can either do it with a private token, which they make it very easy. You just type a CLI command, you get the token, you put it in, it's done. This gives them access to your whole GitHub account, which can be good, but also like some people maybe don't like that. So they have a separate way, which is you basically install a GitHub app. And in the GitHub app, you can specify exactly which repositories it has and doesn't have access to. And I did that. That also allows you to easily share the account with multiple people. And so I really appreciate that, that they give you this option. And once you can do that, you end up here. And as you can see, I have already kind of experimented just a little bit, but I thought we would go like from start and actually set up a brand new repo in Devon and see what the kind of onboarding experience for new repos is like. So the first application that I wanted to do some work on is this thing I built called Sveltebench. So if you're using any, let's say like lesser famous frameworks, like you're not using React for front-end, for example, and using something like Vue or Svelte, then you might know that LLM support for those frameworks that are not the most popular is kind of hit or miss, whether it's front-end languages or like lesser known programming languages. So in order to kind of try to figure out what the situation is like, I made my own LLM benchmark that basically shows you which models do really, really good at Svelte specifically. So the output of the project is this kind of dashboard that shows you which models are doing like a good job at writing Svelte specifically And we benchmark these different providers I have a few things in this app that I been putting off and I thought we would give Devin a chance to fix these issues that I been thinking about fixing for a long time, but haven't had the energy to do. And we'll see kind of how autonomous it can be in fixing them. So in order to set up a new repository, what you have to do is you have to go to settings here, and then you go to repositories. And then here, I'm going to search for my repository. And then we get the choice here between repoindex and setup on machine. Now, honestly, I don't know what repoindex is, but I do know to start working with it in Devon, you have to set it up on the machine. And I'm going to explain what machine with the capital M actually means. So when you press this, it basically tells you this, clone a repo to Devon's machine snapshot. So the way Devon works, it's a little bit different than something like, let's say, Cloud Code, where with Cloud Code, you install a CLI tool and you run it on your computer. And that's not how Devon works. Devon works by having a computer in the cloud, and every time you want to do something, that computer boots up. And they actually have already like a preset snapshot of a like kind of working state of your application so they don't have to like do all the setup steps again like stuff like adding environment variables or or installing the dependencies or stuff like that so that's actually something that's really nice about devin is i see a lot of people on the like cloud code subreddit and they're like oh you know like how can i run cloud code like in the um in the background when i'm like you know on the phone and i get like inspiration and I want to do something. And there's all kinds of weird solutions to do that, but they're all very complicated. So with this, you can kind of like fire off a task and either go directly and start a new task, or you can basically close the computer, go do something else, get a coffee, come back, and then the task is kind of worked on in the background. So let me set up this reposter and I'll show you kind of what the steps are and how it works. So I'm going to press start here and that's going to start the setup. This is very, I have to say this onboarding experience is to me at least quite impressive. I have never seen anything quite this intricate. I saw it once when I was like setting up my very first repository and testing this What it does is it starting up like a server somewhere in the cloud and actually cloning this Sveltebench repository for me Then it asks you basically to follow a number of steps to kind of get the application into a runnable state on its own machine. So first it's asking me what command should we use to pull the latest code? And it already kind of has a suggestion here, which is just using Git, because it's starting from the snapshot, which maybe doesn't have the latest code on it. And then it has pulled the latest changes to be able to do work in the repository, just like a normal developer would. You press verify command here, and that's going to actually run the command. Then you see here, so here you kind of see a little chat window, which is actually like an interactive agent that helps you set up the repository. And here you have the kind of actual Linux box that you are, I'm going to make it a little smaller here, the actual Linux box that your application is being set up on. It says verification successful. And then it's saying here, create an NRC file in your repo. Now they have like a lot of stuff here, like you can set up secrets and you can kind of store those secrets in Devon or get them from external services. You can set up VPNs. It's very enterprise. So whatever it is you might need, they probably have it. But in this case, I actually don't need to have any secrets on the dev machine because when you run the benchmarks, you actually run it on your own computers and verify them. So I'm going to skip this step for now. Then it's going to come to the next step, which is installing dependencies. Use the VSCO terminal to install any tools or dependencies. So in order to run my application, I need to basically do two things. I need to get the right version of a node. Let me see if I can make that a little bit bigger here. There we go. So I need the right version of node and I'm going to go ahead and install that. and then I need to use that version. There we go. And then I'm done here and I just press next and then we're onto the next step, maintain dependencies. How should we keep dependencies up to date? These commands will be run after GitPullDirectSessionStartup in case new dependencies were added. And I mean, I think this is the command. So now it didn't actually suggest anything for me. I wonder if I can get the bot here.

 Suggest a command for me and see if the interactive bot here can help me. All right, it finished and it, well, essentially kind of suggested what it says here. So I'm just going to paste that in. Press verify. Let me get the command right. Press verify and it's going to actually, I guess, run these commands. Yes, so it's running them right now. Okay, it installed the dependencies. It went well. Great. And then we're all to the next step. And then what command should Devin use to run lint or check for syntax errors? And I do in fact have a command for that. And I believe the command is mpm run check. Okay, let's try that and see if that works. Yes, it did work. But actually, so my code has some typescript issues. And this is actually something that I would like to ask Devin to fix for me later. So I wonder if we can just sort of bypass this for now and add it later. Let me check. So I asked the AI to please let me use this command and it says it will allow it. Let's see. Ah, there we go. So it did actually allow me to continue even though the command failed. So that was great. And the AI actually was okay with that. Right. And then we're onto the testing. And then for that, I do have a little tiny test suite that I thought I would try to run. Let's try that. Yes, that worked okay. Now we're in the seventh step. We're almost at the end. It says, how should Devin run this app locally? Make sure you run your commands and check they work. This one is more of like a prompt. So in my case, like what I do is I do mpm run build, and then there's a special build folder that gets created. Let me see what that folder is called. We have this benchmarks folders and there's an index file inside. So and then check the benchmarks index.html file. It exists and has content. Let's see. Let's try that. Okay it didn't actually run it but I think actually I might not want this to run because I would actually like the test environment to not have this benchmarks folder. And then there's additional notes where it like a prompt I think here Add any additional information about the repository Devon will always see these instructions when working so this is kind of like your your starting prompt or like your little kind of repository specific prompt with instructions maybe like how you what patterns you prefer to use or or stuff like that great so I do still need to fix this lint command. Give me a second. Okay, I actually decided to just bypass the command for now, but we're going to in the very, very soon, we're going to try to fix these errors. So now that all the steps are finished, I'm going to press finish here. And then, yeah, I guess it will start a new box maybe, and then try to run these commands and see if they work. And then it says, yeah, set up past all checks. And I press complete here. And yeah, so what I'm just going to do now is going to kind of save that all these steps that we did into like a starting configuration and for simple apps usually this is not so problematic but but if you have like a really complicated app with the different dependencies and and maybe even like some docker stuff you know like it could be quite hard to actually get this to run i know like with other agents i had a lot of problem with them not being able to like understand which steps need to be taken to to get an environment up and running. So this is actually, I think, really, really cool. And I mean, you can do something similar by maybe doing some startup scripts and such, but this is definitely a lot nicer and more ergonomic to kind of get started. And you have that chat that can help you while you're setting things up. And that can also interface with the steps and mark them as completed or suggest new commands, stuff like that. All right, so now I have the Sveltebench repository set up. Now let's look at what we can actually do. So I have two tasks that I wanted to do. One task was to fix the TypeScript errors. So let's see what we have here that we have to work with in the kind of main UI. So first we have this wonderful box that suggests for us that we can use MCPs. I do love this. I'm actually a huge fan of MCP lately. I've built a couple of MCPs myself. And in fact, I have already added one of the MCPs that I use that I also made, which is called Svelte LLM So this MCP basically allows you to get like up to date Svelte documentation So they make it really easy to add MCPs They have a bunch of them already but if you want to add a custom one you can just in this case you can add actually all three kinds of MCPs, which I really enjoyed because a lot of older clients, especially, only support this like old standard IO method, but DevIn supports both server center events, which is a slightly older protocol and HTTP, which is the HTTP streamable, as it's sometimes called, which is the very latest protocol that it seems like more and more clients are moving to. Now, how you set it up is just you basically select the transport type, you set up a description, and then you add a URL. Like in this case, this is all I did. And what I also really like is that they make it easy for you to add authentication. So they have both like basic auth or kind of like a header. And they also support OAuth. Now, I've got to be honest, I have actually never tried OAuth with MCPs. But it's cool that they have it because that is something that I think a lot of these more like enterprise MCPs have. So you kind of like log in using a more complex flow using your actual like account credentials. I do like that a lot of this stuff in the UI here has like test buttons and little like explanations and stuff. I thought that was quite nice that you can kind of get instant feedback on things. So we set up our Sveltebench repo. And now let me pick the repo here. And let's see what kind of things do we have to work with here. We can add files, repos, macros. Okay, you can add attachments. And then here is one that is quite important. So you can select between agent and ask mode. And agent mode is kind of like it works by itself, like until it finishes with the task. And ask is kind of more like, I guess, chat GPT, where you can ask a question about the repository, but it's not going to like trigger like a long process of changing code and making fixes and stuff like that. And what do we have here in the meatball menu? We have improved prompt. That's pretty good. And send to Slack channel. First ask I'm going to give it is to fix those pesky typescript errors. So let me compose a prompt for this. All right, that's about as short of a prompt as I could make. Let's try this improve prompt function. Let's see what it comes up with. Your prompt is missing a repository name. Aha, okay. Fixed. Okay, so it says the prompt is missing a repository name. Maybe this is not the right way Maybe I should have tagged it in a different way Let me see here Devon does better when providing some hints It did do something with my prompt. I wonder if I could just set it like repose. Svelte bench, yes. Okay, so, and I'm going to pick the agent mode so that it actually works. And then I'm going to fire it off. And let's just, for this first time, let's just see kind of what it's going to do. it's first that kind of analyzes the repository, looks over all the files, quite standard stuff. And then it's going to at some point actually boot up this machine. Let me move that here so I can show you. So you have shell, and this is actually like inside the machine. So inside the machine that is running remotely somewhere and running your project. And I can do like, let's see, to run commands and devons shall use the IDE in the code tab. Okay. Well, I was going to go there next. So we have the code tab. And this is really cool. This is basically like a local VS code. They really have everything here. It's insane. Now, I would zoom out a little bit. I don't usually have this zoomed in, but it's just going to be hard to kind of follow this on a screen if I zoom out. But here you have a full sort of VS code instance, and you can actually make changes here too and actually code along with Devin. So you can take turns kind of like pair programming, I guess. And then you have browser. And this one is, I think, for basically seeing the results. I was reading about this. So Devin can actually surf to like websites and not only like fetch the raw HTML, but it can actually like in a browser, go to a website and actually like visually read any information. and I guess this browser can be used both for testing your application locally, but also for browsing. So I can go to svelte.dev here and kind of tell it like, oh, here's the documentation for whatever it is I'm working on. So I think that's pretty neat. While it's doing that, let me make another task. And this is what's so great, right? So it's doing my task right now. So I'm going to add another task and this next task I wanted to add was, as you saw in this visualization, we do support a few different providers here for benchmarking and recently this new provider has come out called ZAI.

 They're out of China. And so what I basically want to do was sort of integrate with their API because we already have in Sveltebench a bunch of different providers here. So we support basically a few different providers, including like Olama, which is a local provider. But I want to add also this provider. So if you look at the kind of page they have, it's very bare bones here. They have a Python SDK, they have a Java SDK, And I actually found that they have a sort of work in progress TypeScript SDK that actually isn't released yet. But I thought, so I'm like, what is easiest? Is it easiest if I just kind of use the raw HTTP requests or should I try using this not yet released package? Why not both? I thought, so let's actually fire off two tasks to implement this other provider. and let's see which one we like better. So I'm going to do a new session again and I wonder, can I, yes, I can even include individual files. That is really cool. There we go. I'm going to do agent again and I'm going to, well, let's try the improve prompt again and see if they like it better when I included some files. You should let Devin know commands to run for verifying results. I don't know if there's a way to do it other than kind of building it and checking that everything is still working okay. So let's just fire that off and I will right away fire off a new session with exactly the same prompt, but I'm going to tell it to use the unreleased SDK from GitHub, which is, I'm just going to drop in the GitHub link here, and I'm gonna let's do improv prompt again. There we go and let's fire it up. Now we fired off three tasks and let's go check into the first task and let's see how that has turned out. All TypeScript compilation errors have been fixed and I assume that it has also created a PR. Let's have a look. No, it actually hasn't created a PR for me. Let me ask it to do that and see if that works. There we go. so now it has created a PR and let see what it did here it did some fixes to the to the types and It wrote a very comprehensive PR message here including this diagram that I That I really like I like it does these like kind of cute little mermaid diagrams Unfortunately, I don't have like a good CI flow set up for PR apps But it would have run on them and then Devin could have gotten feedback on the CI this looks good and I'm gonna just go ahead and merge it because the code looks totally okay so that's one down and one to go for this project so let's see how it's doing with those new LLM providers looks like it's still working on it so I think now would be a good time actually to check in on the like agent compute unit situation so up here you can kind of see I'm not sure what the excess stands for, I guess, like maybe instance size. So maybe there are different sizes of instances. And then you see here the ACU usage, and it's showing up as 0.8. Oh, no, it says here, right here, session size. I'm blind. Okay. So it's a 0.8. So if we kind of do the math, there is one credit is $2.25. So 0.8 is like around $2. So to kind of fix that and to test it, that was about roughly $2. What they have here is also this session insight, which I used it before. I think it's really cool. It's actually showing you kind of where the AI got stuck on different things. So let's say it did a fix, but it couldn't figure out how to run the test suite. That would show up in this analysis here. Let's see here what it thought about this particular request. I feel like this request went well, so we'll see. It was basically saying there are no major issues, which matches up with my experience. No actionable feedback for this one. Basically, like when you end up using a lot of ACU, you can also kind of have some tools to control that so it doesn't get out of control and you can sort of fix any missing instructions. So while we wait for this kind of other PRs to finish, let's look at some of the other features that exist. You go to settings here, they have a bunch of stuff, right? So we have this thing knowledge. This is just a kind of one-off prompt that it kind of keeps in a permanent memory. That's the way I understand. So for example I was working on setting up a GitHub Actions workflow and it used the wrong Node.js version and I corrected it and then like this box popped up which said like we can remember this for you so next time we do it correctly So in this case it added this like extra prompt saying always check the project actual node version by running node dash dash version locally or checking packages to JSON before configuring the node version in GitHub Actions workflows. So now, anytime I do that, it's going to remember it. I think that's really cool. So it is like a sort of permanent memory. Then we have playbooks, which it does look just like prompts. So like kind of how to set things up. So I think there wasn't really that much here, only two pages and very specific stuff, nothing that I really found super useful. But it's good to know that this is like a library that they could work on over time. And you can also create your own playbooks. Then we have secrets, which is like, yeah, you can have your own kind of environment variables here, or rather like secrets and that can be placed as environment variables on your machine. Then we have repositories, which we already saw before. We have Devon's machine, which has the setup for different repositories. Yeah. And here you can actually see all the commands. So like actually now what I can do that I fixed this lin thing, I can actually remove this workaround I did so that it works correctly. Then we have a few settings here. Now, one thing that I also really like is that with tools like Cloud Code that you run locally, you're always kind of worried that they're going to accidentally wipe your whole computer. Or rather, I saw a funny Reddit thread a while back of someone who didn't use Git. And then at some point, the AI was getting really frustrated and deleted his whole source code folder. And that was, of course, not very good because he didn't have a backup for it. But here, since it's running on a cloud machine, there's really no damage that can happen on your computer. So basically, they can kind of like go full blast and not ask you for every minor detail or every file that needs to be changed. And here they have another, just one kind of toggle, which is whether to proceed when waiting for complex tasks, which I think is more like a cost thing, because maybe it kind of figures that, oh, this is going to cost a couple of these agent compute units. Some people might want to have a chance to say no to that and adjust the plan first Another thing I wanted to show here was this DeepWiki So what Devon does for you when you import a repository and start working on it is that it actually generates a up-to-date knowledge base of a wiki for your project. So without me having to do anything, it generated this whole wiki based on the Sveltebench repo that I had. And it has, I love these mermaid diagrams. It has like all these different parts, basically like almost like down to each file that it scanned. And then you can also ask about things in the project. So let's say you have a project and you're onboarding new people. Well, I mean, you could already kind of build this with maybe some rag or maybe you can use some other service for it. But here it's just, it's included kind of in the, in the offering that they have. So I can ask a question, I could say like, providers are supported. And then it's going to go ahead and search here. It does seem to, even though I searched here, it does seem to take you to this sort of unified prompt page. And then it basically answers. All right, let's check in with our two tasks that we did. And so it generated two PRs here and you can just easily review it and you can also of course tell Devin whether you wanted to make any changes so if you leave comments on the on the sort of individual lines somewhere here so you can maybe say I want you to do it differently then it would like spring into action and kind of fix those errors for you. Both these PR look very, very comprehensive. All right. So that was some backend stuff, but I also thought it would be fun to show a little bit of frontend stuff. That's something that I personally sometimes wish that we could get AI to do, just build some components for us. So I've had this app that I worked on for a while. It's called Appreciation Jar, and it's basically like a little virtual gratitude jar where if you're couple or friends or family, you can sort of post appreciations to each other. And so one thing that I've been wanting to do for this app almost since I launched it is to kind of make a sort of like a wrapped function. Like if you know Spotify wrap, it shows you kind of what you listen to during the years and some insights about your particular taste. And I've been thinking that it would be fun if after a year has passed, you get like sort of this like screen where you see how many appreciations

 who posted the most and so on. I actually even designed this a while back in Figma. It's still very basic, but you kind of see here that you go through these different screens and it kind of has a few different features here. This is actually quite a complex feature. That's why I've been putting it off. So I thought, well, maybe I can make Devon do it for me. So I'm going to go ahead and set up this repository in Devon. And this is a Svelte kit and the capacitor project that is actually available also on the iOS and Android app store. So it's a little bit more complicated, but I'm going to try to set it up and I'm going to then kind of try to get it to do this and actually just upload the Figma sketches and see what it can do with that. So let's try it. All right, so I got the new repository set up for my app. Now I can write a prompt and basically tell it to make this wrapped feature for me. And what's going to be really cool is to see how well it works. You just upload an image and tell it to make that design. Let's see. Maybe they have some fancy Figma integration, but I'm actually just going to use a screenshot here of my sort of mock-up of the design. So I guess I should probably be able to drop it here. Yes. Then I'm going to write a prompt for it. Let me make one. All right, there we go. So I asked it to make the design and to not make the backend right now, because I want to really see how well it does on the kind of design department. Let's have a look. All right. So it has been working for a while and it did finish the pull request What I really love about this is that it made screenshots of the actual result So let see here it giving me it going to give me seven screenshots Wow Now granted the design is not exactly what I sent it. So I think I'm going to actually ask it to iterate on this. And to do that, I'm just going to go ahead and write a message. Actually, yeah, what's so nice here is that I can actually, without setting up a local environment, I can sort of see the result here. Yeah, there's definitely a little bit of UI design that can be applied here. Let me see if I can craft a prompt. Oh, and this was nice. So when I complained about the design, they actually added back some of these agent compute units to my account. But let's see, I think maybe part of the problem was part of the problem is that this is like a full screen browser and the app is supposed to kind of be in a small window. But the second problem, I think, is because I tried to do too much at the same time, I kind of send it just all these different screens. And I'm going to see if I send it just one screen, if it's going to work any better. It's also funny to kind of see it working because I saw a little bit earlier, it can actually navigate in the browser, like pressing the next and the right and left button to kind of navigate between screens. I thought that was pretty cool. And you can actually see it working in real time. So now I have been going back and forth with Devin for a little while and asked it to adhere to the design that I sent And it gotten a bit forward but not quite exactly like the design I had in the beginning Let me show you So this is what it came up with So the kind of general composition is right with these pills and the hearts and the kind of general fonts and stuff is correct. Let me size that up a little bit. And it did implement this switching correctly, which is also very nice. And it kind of got the general sort of stuff right. But if we kind of compare it to the designs, then we see that it does look a little bit different, like the sizes on the buttons is not quite right, and the font sizes aren't quite right either. It didn't include the images, but that's okay, because I haven't actually given it these images to add and it'll be very easy for it to add it. I think this is a great start and I could keep prompting it, but I think I would need to use more descriptive, not only the pictures, but use kind of more descriptive language, like move this higher up, lower, align this in different ways. I think this is something that nobody has truly solved. I think the first company that manages to do this sort of tool that lets you convert from a design into like whatever tech stack you're running, not just like a tech stack that they have set up for you, but like any tech stack, they are going to be like very rich, I think. So this is a great start and it saves me a lot of time not having to code this out by myself And it also is much faster to do it with Devin because you can kind of follow along with it even in the browser as it working if you want and you can give feedback right away and you can do it from anywhere, right? So you don't have to have anything running locally even to do this. So overall, I would say still pretty impressive and definitely on par with the very, very best agents that are out there right now. So I really hope you like that overview of the new Devon 2.0 platform. I have to say that I'm really impressed with what Devon have built up, and it's honestly the best onboarding experience of any agentic coding tool I've seen so far. Just the fact that they guide you through configuring your application step by step, so it always works out of the box when starting a new task. So good, because this is something that I've had some issues with when trying other agents. Just small things like the AI being unable to install dependencies correctly or forgetting to run tests and linting, stuff like that. I also really like the deep wiki feature that automatically documents your projects as you code. Finally, it's great to have a tool that you don't have to leave your computer on to run. So for example, if you're using cloud code, then you either have to run it on your own computer or figure out some way of running it in the cloud somewhere. And with Devin, you just don't have to care about that. The only thing that I really think could be improved is the cost aspect. I definitely wouldn't say it's bad value. God knows I spent a lot more on some intense cloud code sessions. But with each unit costing a couple of dollars, you really need to have discipline and make a comprehensive prompt before firing off a new task. They do make it quite easy to explore code base by using the ask feature. And from what I've seen, using that isn't very expensive. So that's usually what I did before creating a big task prompt. But what do you think about Devin? Leave a comment. And if you like the video, don't forget to press like and subscribe. And thanks again to Cognition for sponsoring this video. See you in the next one.