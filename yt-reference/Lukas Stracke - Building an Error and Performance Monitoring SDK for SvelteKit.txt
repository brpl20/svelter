 Okay, cool. So yeah, hey again, I'm still Lucas, I still work at Sentry. Nothing changed since the last hour, so let's just get directly into this talk. So around one year ago, we at Sentry kind of decided to go more or less all in on the SEL community, and we started working on a dedicated SDK for SELTKit so that we could really provide first-class support Svelte kit with Sentry without having to, you know, add a ton of custom code, deal with some workarounds, stuff like this. So we really want a nice experience basically for people using Svelte with Sentry. And yeah, this was basically more or less one year ago. So I thought today is a good time to kind of take a step back, take a look at kind of what we learned in this year, talk about some challenges that we kind of encountered along the way, and just take a look at basically behind the scenes of our SDK. And yeah, learn about all what it takes to build an error and performance monitoring SDK for SELTKit. So with that ahead, this talk is kind of structured in three parts. So first of all, we're going to look a bit at SDK architecture, some one-on-ones basically, you know, what kind of tasks do SDKs usually have to take care of. Then we're going to talk about a couple of specific challenges we encountered in SELTKit. and this is where we're going to look a bit about SvelteKit internal code, and how SvelteKit does certain things, learn about some limitations. And ultimately, we're just going to conclude with some takeaways, what we've kind of learned along the way, and how SDK building works here at Sentry. Cool. So let's get started into the SDK architecture. And for that, let's first take a look at what an SDK generally has to do here. So not specifically for SvelteKit, that of course as well, but just generally so we always need some kind of way to instrument global apis and with that i mean kind of global functions that are available in the browser or also on the node side of things and we like hook into these functions for example a very prominent one being windowed on error so whenever a error kind of bubbles up to this callback that means it hasn't been handled before then we basically um capture this error and we send it off to century so that one very important and aspects that every SDK needs to get right basically Then we would like to expose some functionality to capture errors or spans that first of all users could invoke manually or second of all, our instrumentation can actually also use to send, to basically kind of put this data into the SDK on the more or less front end part of the SDK. So the next thing that SDK also has to do, it has to hold basically contextual data. So, for example, some information we kind of collect about the browser, but also some more additional data that users can put there. For example, they could set the user, which would, for example, then trigger the SDK to add a user ID to all the events, to all the errors that kind of happened while the user was active. And ideally, this data is properly scoped. So, meaning users can kind of define how long this data is basically valuable. and the SDK has to kind of handle the scoping, which is a challenge in itself. And ultimately, moving more to the back end of SDKs, they have to take care of converting all this data into more or less a standardized data structure that then our Sentry servers, our ingestion can handle and apply all this contextual data, process it, serialize it, and ultimately send it off to Sentry. So as you can see, those are quite a few different things. each of the, like all of these things they have their own challenges but yeah, that's basically more or less what a Sentry SDK has to handle and now with that in mind now that we're all experts in what SDKs have to do let's take a look at how our Sentry SDK is built so for this, I kind of made this diagram actually a while ago but it's still kind of valid so here on the bottom part we have a, let's say, a conceptual overview of SvelteKit So we all know SvelteKit basically has a client set and a server set. And the thing that kind of sticks them together and makes everything work is SvelteKit's build process. So Veed with a couple of plugins that basically SvelteKit kind of adds to the build process. And this will generate JavaScript and all the necessary files for the client set as well as for the server set. And what you can see here is that for all of these three parts, we basically have counterparts in the SDK. And yeah, this is basically how, for example, the client's head in the SDK looks, like again, in a very simplified manner, of course. But what we see here in green are basically sentry packages that the SvelteKit SDK already depends on And that for us pretty good news because it means we don really have to reinvent the wheel for every SDK we build So, for example, on the client side, we already take the Sentry Svelte SDK, which is based on the Sentry browser SDK internally. And that's basically where all the instrumentation magic basically happens. So we don't really have to do this anew just for SvelteKit. But what we do add here is all the custom functionality that's necessary to make these SvelteKit monitoring experience good. Like we add what we've seen before, this handle arrow hook, for example. We have some instrumentation for load functions, some stuff for fetch. So we're going to talk about those two things in quite a bit of detail later on. But basically, we just add additional features that are specific for SvelteKit on top. Same goes for the node side, basically. Here we rely on the Sentry node SDK. And yeah, on the build side, we also have kind of a counterpart, which basically takes care of two things. First of all, uploading source maps, because no one really can debug minified source code. So what we're doing on the back end of Sentry is we kind of try to map back minified code from the production to your actual source code. And then we also do a little bit of auto instrumentation during build time. And yeah, this is basically where the fun starts, because now we're going to talk a bit about challenges. And the first challenge is basically how we instrument load functions. So for everybody who is maybe a little bit new to SvelteKit, load functions are these data fetching or these data loading functions, basically, that we register in our plus page or plus layout or plus page.server files or whatever other file basically there is. And we would like to ideally instrument these functions because they contain very interesting data where things could go wrong. So, for example, what we want to do is we want to basically add some performance instrumentation. We want to time things in there, see how long they take to see if there's some kind of performance issue that we could notify our users about. Then we also want to associate errors that we capture within these load functions with that specific function. And kind of related to both of these to make this very valuable for users we want to get distributed tracing to work meaning we want to basically extend or add some information to requests that we make So for example here this fetch request we would like to if there on on this service on this API endpoint here if there also a sentry instance running then we can basically connect and show you one kind of distributed but connected trace between these two services. So yeah, that's what we basically want to do. So in this example of this very, very simple load function here, which is the three lines of code, we want to get these messages we convert them to json and ultimately just return this as a prop for our pages and now we would like to ideally know how can we instrument this and we can kind of iterate on getting better here so the first idea that we that we had or like basically how we can always start out is by just um kind of letting users do the job and say hey you just have to use our start span method which is kind of a manual way of doing instrumentation you import it you start to span you give it a name some additional data and i think by now you can already see there's a big problem here actually too this is a lot of code um users credit so you know some stuff like for example this off name here um could be completely arbitrary data essentially so it's not really great for us and not for users and obviously users have to add this to their own load functions, and if you have many of them, this is just a tedious job. So it would be very naive of us to assume that anybody's doing this. So one thing that we could already do to make this better is we can provide a specific wrapper for load functions from the SDK. So users just import this one here and add more or less one line of code to get all this instrumentation. And they're more or less ready to go. But still, they have to add this stuff. So again, it's safe to assume this is not always going to happen and they're just going to miss out essentially on data. So ideally, we don't want to have any sentry code at all. But still, we would like to have the instrumentation. And we did find a way to do this. And let's take a quick peek into our GitHub repository on how we did this. So let's zoom in a little bit. Does this work for everyone? Yeah. Cool. All right. So we are here in the VIT part of our SvelteKit SDK. So the one I showed you before, where you basically kind of hook into the build time. And what we're doing here is we have this Sentry SvelteKit function, which kind of serves as the entry point for this, and it will return a set of VIT plugins

 It kind of do something during the build. And here we can already see, among some other things, we create a plugin for auto-instrumentation. Now, if we jump to this function again, I really love the navigation here in GitHub. It's amazing. We can already see, we kind of create this plugin. The plugin always gets a name. It can have some additional metadata. And here we define a load hook. So a load hook for a read plugin basically takes an ID, like when you implement it, you get an ID. And this ID usually is a file path, not always. There are many special cases here, but usually it's a file path. And now the idea here we had was basically, well, if we see that this ID is a plus page file or a plus layout file, then maybe we don't return the user's original code, but we actually add something to this code. Maybe this works. And after some trial and error, actually, let's say two weeks of being quite desperate to get this right, we came up with a solution, which basically is somewhere here at the bottom. So what we actually return here as the source code of the user is, first of all, an import statement of our own wrapper function, the one we saw before, this wrapper load with century one. And then we import the user module from this ID that we actually got. So basically, we now kind of import what the user defined as their plus page file. Then we now basically, as we are pretending to actually be a plus page file, we just export a load function. And what we do, though, is we don't just plainly take the user's load function, but we use a wrapper function and we apply the user's load function as the argument. And this way, we just created the wrapping we saw before, just basically automatically at built-in. Ultimately, we just export everything else that's in there because users can define SSR, pre-render booleans, actions, all this stuff, and this needs to be exported as well. And yeah, after a lot of trial and error, dealing with source maps issues all over, we kind of got this to work, and now our users can enjoy automatic load instrumentation. Yeah. So I thought at this point, hooray, now I can finally move on, work on something else maybe create another SDK Like we desperately want to create a next SDK just never have the time for it But while it turns out it not so simple there is of course some other stuff that we also need to take care of And one of the, oh, I completely forgot. This is a picture of the final result of this load function instrumentation. So here we can see we have a server request to one of a side project with mine. and it's a cocktail menu app, whatever. And here we have a couple of load functions. So we can see here all in all two server load functions and two client load functions, sorry, two universal load functions. And we can also see some HTTP requests I made to my Superbase database and we see the timing information of these and how long the overall load functions took to evaluate. Oh, yeah, this is good. No, really. So if you, for example, would have called here directly a database or something, then you would see the individual database operations as well. So, yeah, that's basically what we got with all this instrumentation. Cool. So next problem. We want to instrument client-side fetch, and by that I mean properly instrument it. And for that, maybe you already know this, but generally you should not use the window.fetch function in your load functions. What you should actually use instead is this fetch utility that's provided in the load event of a load function. And with that, for example, here we just fetch the messages of the API. The problem here is there's kind of a timing issue between SvelteKit creating this function here and our SDK. And for that, we're going to take a look at how SvelteKit bootstraps itself basically on the client side and how the whole hydration and initialization process of the framework is started. First of all, though, let's just quickly kind of get some primers here. So SvelteKit adds this additional behavior of, or kind of adds additional behavior to this fetch function. So it's not a one-to-one copy of window.fetch. They do this for two reasons. One more or less a side reason being they actually want to warn you. So if you ever actually use the global one, you get a warning in death mode that you shouldn't do this. Because the second reason, they have some clever caching logic applied there. So ideally, no fetch request is made unnecessarily. Just saves you time, makes your app a little bit more performant. And yeah, they have quite some clever logic there. It wasn so clever for us but that an us problem And yeah also we want to track fetch for the reasons I mentioned before for timing as well as for distributed tracing So what we do here is we add some additional headers to these fetch requests so that our SDKs on the other side basically can pick up the trace information. Kind of a complicated topic on its own, but let's just say that's one of the reasons we need to do this. And as I said, there's a timing problem. So if we take a look at the initial HTML response that's returned from a server when the browser makes the first request, we see a lot of basically server rendered HTML, but also the script file here or the script tag actually. And this is basically in the initial HTML response. And in here we see that we additionally load some JavaScript. So first of all, we load this start script and then we are going to load this app script. And basically we await them. And then the first one is going to kind of bootstrap the second one, which is, I think, a very elegant way of kind of starting all the framework. And the start script contains basically most of the framework-specific logic. So, for example, I think most parts of the router are in there. And, for example, also like stuff the load functions need. And the app script contains more the user code that's actually necessary. And we'll see this in a second. So start script. This one is responsible for creating this load fetch that is then basically passed into the load functions that we saw earlier. How do they do this? This is, by the way, very much simplified. Obviously, the code is much longer in real life, but it serves a purpose here of demonstrating this. So they first basically store away a pointer to window.fetch because they still use it under the hood. And then they kind of create their load fetch where they add all of their caching logic, this warning logic we saw before. and ultimately they will just invoke window.fetch. So they don't really re-implement this, they just use it. Okay, sounds good. No complaints so far. So let's move on. Now we are in this app script, which we said contains more of the user code. And among other things, it contains the hooks.client file, where if you remember from the first talk, we add some sentry codes to initialize the SDK and basically bootstrap all this auto-instrumentation. And specifically here in our browser tracing class, we kind of try to instrument fetch. And we do this very similar to what SvelteKit does although with one key difference We also store away the original version of window And then we overwrite what is on window currently We add our sentry logic In this case, we just start a span, for example. Again, this is simplified. There's more stuff going on, but it doesn't matter. And then we also just invoke original fetch. The problem here is there's a timing issue because we are coming in too late. Because by that time, StarJS has already been evaluated and native fetch was already stored away. and it's invoked here. So whatever we did afterwards to window.fetch just isn't reflected anymore there. So let's, exactly. So how can we work around this? Well, my first approach, I'm not proud of this, but it is what we did, because we just basically duplicated our entire instrumentation of the global window fetch, which all in all was like 700 lines of code, more or less. So that was definitely a bundle size hit for all our clients. Didn't want to do this, but yeah and then a couple of uh weeks later on after also fighting some challenges with keeping caches valid and all uh we kind of switched to a really really clever hack basically um of kind of injecting a man in the middle handler which is really nice i would like to show it to you it's just way out of like time reason why i can't do it uh credits go to this guy here on github he basically pointed us to this direction if anybody's interested i'm happy to show it to you afterwards but again this was a hack we still had some problems here and ultimately we decided this is not a solution that we want to keep maintaining because it's just very brittle so we said okay we need a proper solution and I also realized that we really can't solve this on our end without actually changing stuff in SvelteKit so I decided to learn some SvelteKit, take a look at what happens with these start files and all of this and basically actually contribute to the fix and honestly the fix couldn't be simpler because this was the original one we had before. It calls this native fetch handler, right? The new one just does this. Okay, I mean, there's a few other things I did, but that's again the essence of the change. And yeah, the SvelteKit authors also said this is a viable change. We do not want to stay in the way of other libraries who do stuff with fetch. So they approved it and this was fixed in SvelteKit 126. Great. So now I thought, finally, I'm done. We fixed

 Everything. But turns out there's another problem. So one of the things we always want to do is we do not want to have any raw URLs in our spans in the Sentry product, because it doesn't really make sense for users if they get specific events to analyze on the raw URLs. So for ID123 and then another one for 567, whatever they want. What we actually want to do is we kind of want to group them all together to the actual routes that was used in SvelteKit. That makes way more sense for us as well as for our users. So we need this parameterized route. And I thought, well, that's very simple to get, because in our load wrapper, we have access to the load event, and we just read routes.id from it. I mean, what could go wrong, right? It's very simple. You do it every day. And yeah, we did this. It worked well for a couple of weeks. And then somebody wrote in, for some reason, their load functions are running now way more often than before. and the only thing that it was at century not great so again took some reading on framework code and what's actually happening but long story short svelte kit tracks the accesses to the properties of load events so they do this basically to keep data valid and in the cache as long as possible but svelte kit assumes that when you make certain accesses to certain properties of the load event, like, for example, the route, but also other stuff, that you might not always return the same data when the load function executes, but actually the data differs. So they can't keep it valid when you access these properties. And since we did this for our users, SvelteKit just said, okay, there was an access. We're going to invalidate the data, and load functions have to run way more often. So we degraded the performance of our users, which is great considering we're a performance monitoring product. Love it. At least they would have seen it, right? Yeah, I guess. So, yeah. Now it's hack time again because we wanted to work around this, obviously. And, yeah, we found a solution how we can get around it, which is we use this get own property descriptor function to kind of get the ID off the route object and just take the value from it. It looks bad. It is bad. And there's a key problem with that. It requires a very special way of setting this proxy object by the SvelteKit framework behind the scenes basically to track these access So they use the proxy API which is another way to kind of override behavior add behavior to certain elements of an object for example They do this in a very special way, and this works on the server side. No problem. I got it working easily until I realized on the client side, they just do it ever so slightly differently. So the hack didn't work. Wonderful. So in a continuation of these efforts, I just contributed this specific proxy usage to SvelteKit. And to my surprise, actually, they just merged this in straight away. And things worked. Yeah, but again, this is not a proper solution. We don't want to keep this in our SDK. It's very brittle. It relies on a very small implementation detail. So ideally, we would like to get rid of this. And here came SvelteKit 2.0, and with it, its untrack functionality, which has been kind of discussed quite long in the SvelteKit repository, and they ended up with a nice solution, I'd say. So what basically, this gives us a native way of avoiding this tracking mechanism. So everything inside this callback of the untrack function will basically not trigger an invalidation. So we're just going to use this and return the route ID from there, and we should be safe. There's still a to-do here. I have to add this to the SDK. It's not yet in there. We're booked out with other tasks, but yeah, it's going to come soon. How does this untrack work? Do we remove the proxy while you're in the callback? The proxy has a flag if it should report stuff or not, and the untrack function basically just switches this flag. Okay. If you have nascent code in that callback, it's going to be messed up. I guess so. I just hope we don't have to deal with this. I still have to look at the details how it's implemented, but I'm confident that we can use this at least. I hope so. All right. So this basically brings us to the last part of this talk. Some takeaway messages, some conclusions. So what does SDK development mean? Well, first of all, it means that especially when you're building an SDK for such a high-level framework like SvelteKit or NextChase or Astro, Remix, whatever, you really rely on the framework itself and the kind of the functionality it exposes. So some frameworks do a good job here I say SvelteKit is one of them Maybe Astro is still a little better but they really good And some of them as this guy in the back might tell you later don't do such a great job here. But you're basically always kind of at the mercy of the framework in some way, at least. And whenever this framework reaches or whenever you reach the limitations of these functionalities, you kind of have to apply hacks, workarounds, Stuff like this build time instrumentation, for example, anything kind of to get to get stuff working. Development also means, educated development also means reading framework code, as we saw it. Like, basically, it's kind of part of the job in a way. And in some way and in some cases, which is actually really a nice experience, I'd say, it means contributing to the framework, trying to make your stuff work with the framework. Yeah. In the ideal way, you always improve something not just for yourself, but also for others. sometimes this works. But mostly, and absolutely most importantly, you don't want to break your users. And this is basically a consideration you have to do, you have to kind of take into account of every change you make. We have to follow semantic versioning, so we can't break anything without making a major version, which is really a lot of work for us. And for example, if we take a look at this untrack function here, we can use this in all the SDKs when they're used in a Svelte Kit 2 application, no problem. But we still support SvelteKit 1 and there the functionality just doesn't exist, so we still have to rely on the old way and introduce this in a backwards compatible way. And that's just one example of a lot of things that we kind of have to consider when we make such changes. And yeah, quick shout out to SvelteKit here. They do a good job. I love the hooks API. It's really in a good state, I think, and it gives us a lot of basically ways to organically use the framework. We don't have to make too many crazy hacks compared to some other frameworks. Also what I really like is basically the open way of how they let you modify the build. So SvelteKit is basically just a set of plugins you add to a build. And just in that way, you can also add your own plugins. And generally kind of the last three things, they go hand in hand. But I think the authors of SvelteKit, they really pay attention to the community. They're open to changes. We've had some great interactions in the repositories, for example. The code base for SvelteKit is I say rather understandable And it very maybe not very but it rather easy to contribute And honestly I can only recommend doing it It a good experience and you get good guidance along the way of what they kind of expect from contributions. Cool, one last thing. Maybe Svelkid is getting a little bit better in the future even, because right now they have APR open for handle load hooks. And if this gets merged, then we can remove our entire build time instrumentation of load functions, which I would really like to do because it's not something I would actively use if I had another way of doing it. And this is coming soon. A small shameless plug here. I proposed this six months ago or something. I opened the initial PR for it. Didn't really receive much attention back then. At some point it became quite stale. So Simon from the SvelteKit team, he closed it and just made a new one. So it seems like this is still happening. so let's just hope it does at some point. Yeah. And yeah, that already brings me to the end of the presentation. I've added some links to the actual source code of SvelteKit and to some changes we made. So if you're interested, feel free to check out the presentation. Yeah, and if you have any questions, feel free. You should. For people like you developing SDKs, how much of the hassle is the switch to Svelte 5 for you? Do you have any feeling about what problems are coming or not coming? I don't think there's going to be that much trouble because right now we don't do a lot of specific stuff for the front-end UI framework of Svelte specifically. So as I said before, like, for example, errors, they usually bubble up to window.on error. We can use this basically to just catch all of them. And what might become a little bit tricky is our way of basically adding component instrumentation. So one thing we also do is you can basically track how long a component takes until it's mounted, for example. So if there's some kind of weird computation going on, you will see that this doesn't take, I don't know, two milliseconds, but maybe like 100 milliseconds. And that's definitely a performance problem. So maybe this is going to be a problem depending on how they change when they invoke the mounted hook. I don't know if there's anything.

 going on in the background there, I have to check. But I don't think it's that much of a problem. Great talk. Thanks. What's the worst framework in terms of ? Honestly, I can't really speak to that because I'm the lucky one who doesn't really have to work that much on NextShare. No, I think, I don't know. For me, probably, I can't really tell you. Our Node SDK is definitely not easy to develop because we made some bad design decisions a long time ago. We're changing this right now. I'd say actually the biggest challenge of developing these SDKs is all of the stuff I mentioned very briefly about keeping data scoped and always kind of applying the right data at the right time. So this works right now in the browser sorry on the server side rather well with some changes we making But on the browser side this is a big problem because we can really isolate um async callbacks for example in the browser which is a huge problem for example with micro frontends and everything that's where we kind of need some sort of true isolation A business question here. How do you decide to work projects, technology, moving, etc.? It's a combination of a couple of factors. So NPM trends. Okay, I wanted to start out with the more data representing ones or kind of do look on download numbers. And yes, in that case, next would definitely be the more logical choice. So the SvelteKit story basically happened because we at some point said, or like a lot of people have been asking for a Svelte SDK This was super simple for us to do It more or less you import the browser SDK we already have and you get this well SDK um and then at some point over Christmas I was kind of playing around with how how can I add century to my Svelte KDEP and I added some instructions to a GitHub discussion and at some point our product product manager said well let's do it and this was basically the beginning of the journey um in other cases it's because of partnerships with the frameworks themselves so for example that's how the astro SDK we built recently kind of came to light and yeah we we are basically kind of in talks with the next community from time to time and so there's I think a guy called Alex Lister he's very active and already like published some guides on how to use century with next but yeah we have just haven't gotten around to kind of packing all of this in the SDK. Yes. You mentioned the server-side instrumentation for which kind of depends on Sentry node What happens when you deploy to Okay So right now basically what happens is that the framework you will get some errors at built-in, I believe, or actually the latest at deploy-time. So right now we're not, unfortunately, fully compatible with Edge runtimes or Cloudflare workers. I believe is something similar. This This is kind of an open to do. It's unfortunately not as easy as just kind of removing the parts where that kind of conflict with the runtime. We have to add some additional behavior. I believe Luca, you know a bit more about the edge runtime, but it's like very limited in what we can do with it. I think we have some problems with source maps still and stuff like this. There we are. So yeah, still some stuff to figure out. And yeah, let's hope it's going to come at some point in time. All right. Cool. Then thanks again. Thank you.