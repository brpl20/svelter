 Hi everyone, my name is Luke Edwards. I have worked as a front-end and a back-end engineer over the last decade or so. Right now I'm working as a freelance contractor and I would like to share with you guys how I am building my Svelte apps. Or specifically, how I am doing server-side rendering with Svelte with Cloudflare workers on a global scale. so workers um workers are awesome you should definitely dive into them if you haven't already this talk is only going to do a brief like introduction for the different types of workers just so that we can figure out how and where cloudflare workers fit into the mix of things web workers are the most common kind of worker you'll run into um that's because they're completely general purpose you can stick whatever you want inside of a web worker and it will run off run in a separate thread which allows your main thread to be completely unaffected by what that thing is doing you know so if you're running canvas animations at 60 frames per second and then doing some like really expensive math in the background or crypto mining whatever you're doing they can run in parallel separately from one another and then you can just pass messages back and forth. Worklets, not at all relevant to this talk, but they exist and they're a different kind of worker. They're just a way for you to plug in directly to the browser rendering pipelines. And then service workers, you may run into them before, you may have had not a great time, or a great time, but they're pretty great and they're definitely very useful. So service workers are basically promoted web workers. They still run a separate thread, but they are in an elevated position where they act as a proxy between the client and the network. They also have the ability to control a separate storage cache, and they can completely control it, and we'll see that in a second. But a client request, as it goes out, the first thing it's going to see is the service worker. And then similarly the network response the first thing it passes through is the service worker So it in this gatekeeper position where it can completely decide which requests go through and if they should be manipulated at all. So, you know, proxy stuff. So we have an example here on the right side. Looking at the fetch event listener, this code gets executed on every single outgoing request. So we start parsing it, looking at what it's doing. If it's not a get request, the service worker code here is going to say, like, return early. We don't care about it. Just go ahead and do what you're going to do. We're not going to change it. But if it was a request to say the old Svelte site, we can rewrite it so that it goes to the new Svelte site. What that means is that the application code can continue to have the outdated references, and it's fine because it's being rewritten on the fly to go to the new site. But the important thing here is this event.respondWith. Anytime we are changing or adjusting how a response is returned, we have to provide that logic here. So our first step for our custom logic is to say, let's look at a cache storage. So we'll open a cache with whatever name we chose and say, with this cache, have we seen a request? Have we seen this request before? And it uses matching logic by path name and all sorts of stuff. And if it's seen it before, it will return the response for that request and we can just stop. Like, we have a response already. We're done. Go ahead. Use this. Otherwise, we're going to go ahead with that fetch request. We're just going to fetch it from the network and get a response back, business as usual. With that response, we can decide if we want to cache it. We're not, but then we return that response to the thing that initiated this fetch request in the first place. Now, the other two things here, there's an install and an activate hook. that's just you can use those and you need to use those to like set up your your your cache environment or whatever you're doing on the browser so you may want to purge old old assets you may you know need to fetch stuff right off the bat so you can prepare a cache storage whatever you doing But it for you to invoke those or listen to those hooks and set yourselves up as needed Now, Cloudflare workers are exactly the same thing, literally the exact same thing. So they use the service worker interface and they are equally positioned on the Cloudflare network. So the difference is really just physical location. But they are still a service worker. They still proxy between the client and the network and the control of cash. So with the Cloudflare worker, you can, as a proxy, you still are the first thing that a client request sees on its way in. And you're the first thing a network response sees on its way out. So you're still a gatekeeper. You still get to decide what goes through, what needs to change, what gets manipulated, and what ultimately gets sent back. So our code on the right here is the exact same proxy behavior with just a couple of differences. So the first is we no longer have to worry about opening caches and working with different cache storages. We are given one by Cloudflare, and it's really all you need. So this is now the caches.default. And we use that below to do the cache.match on the request. The second change here, which is optional, but I've decided that if it's not a get request, we're just going to return a method not allowed. This is just because since it's the proxy and we're assuming or I'm assuming it's like a file server kind of scenario, that we're not going to anything that's not a get request is just not going to be useful anyway. so we just send back a 405. But yeah, that's optional. And then the third request is there is no, sorry, the third change is that there's no install or activate hooks. And that's because it's not our machine or it's not the user's machine. The Cloudflare worker exists on Cloudflare's machines, which are everywhere. Anytime you upload and deploy a Cloudflare worker, because it's the first thing that a request hits as it enters the Cloudflare network, your Cloudflare worker exists everywhere the network exists It has to So you get free you get global deployments for free and instantly for the most part Like just by uploading and using Cloudflare WorkSets you get 200 plus locations I'm sure there's significantly more than that by now, but it's free global rollouts and it's all tied to your DNS layer, your network layer. with that comes another unique product from Cloudflare called WorkersKV so this is a key value data store it's also global it exists at every single network location and it has Cloudflare workers have the ability to read and write directly into these KV namespaces from a front end developer's point of view this is basically you can think of this like a local storage, a session storage, or index DB. It's an extra persistent data layer that your workers can write into and read from whenever they want. So when you have something like that, you can look at the world and everything seems like a key value relationship. Right. So Cloudflare offers a tool called Wrangler. Right. And so Wrangler helps you build worker sites. And with worker sites, they will build your app with Webpack and upload all of your built assets into Workers KB. So, you know, a static file, a bundle.js, the key is bundle.js and the value is the contents of that file. So what happens is with Wrangler, you can deploy a static site. It goes up into the Cloudflare network, and it instantly gets spread around the world, a copy all around the world, along with your worker script. And those worker scripts will contain not exactly the code on the right, but something along the lines of the code on the right. So if we look at it very briefly, we still have that cache storage object. We're still parsing requests as they come in. We try to be lazy and we try to match those requests so we can just be done early. Otherwise, we have to format and make sure our path names are uniform. And then with that, we find

 Take a peek into the KV namespace. So here I've called it all caps assets. This is a binding according to Cloudflare, but this assets is the variable that our KV data store lives behind. And so we asked the data store, do you have content for this file path? And if it does, great. Like we can continue on with it. Otherwise it's a 404 and we go from there. but this is the general flow of how a static site on worker sites works. But we can do a little bit better than that. So we're going to hop into some code here, and we are going to introduce server-side rendering. So worker sites is great, but this is a talk about server-side rendering with Svelte, and we do have to do some custom bits in order to get SSR working within Cloudflare workers. So let's hop in. Okay, so we'll be looking at my Svelte SSR worker repository. It is public. If you've seen it in the past, you may want to revisit it because it's had some changes recently. So let's hop in. First and foremost, the most important thing is this hydrate true. So without that Svelte, the runtime, the DOM side of Svelte won't know that it's trying to rebuild something or it's trying to reuse something. So that's very important. Second thing is you have to know when you are relying on a browser context or a browser variable versus not. So in the SAPR world, we'll have something like if process.browser, but you can also use, you know, more traditionally, you can use things like if type of undefined or if, sorry, if type of window is undefined or if, in this case, location exists. So yeah, in this case, if location exists, we want to use a path name, read from it, or set a default. So we'll see what this means in a second. But the third important thing to know about building a site for SSR is that you have to build your site twice. You have to build it once for the DOM, using document.createElement stuff, the standard Svelte that we all know, but then you have to build it a second time for the SSR output And if you never looked I highly recommend you look at what Svelte doing when you set that toggle Rollup users can just you know it really just comes down to this Generate DOM if it DOM otherwise SSR But you need to build it twice And then for this particular app, we also need to do it sequentially. Having the DOM go first and then the SSR go second is because the DOM will output, let's say hashed file names or in this case it will be building a indexed html file so this particular repo uses string replacement to make our lives that much easier sounds scary but it's not so we're injecting like our cdn locations and then these guys happen at runtime but we have the have insertion points to stick head content or body content later on. So if we look at our index SSR, you'll see it's a very familiar fetch handler. This is literally our entire worker code. We'll be importing HTML from our public, the built index HTML file. And then from that, we are replacing those head and body insertion points with the output that came from our Svelte component. And if you're not familiar with this, it comes straight from the Svelte docs. There's nothing fancy going on here at all. It's just basic Svelte SSR. Definitely check out the docs if you haven't already. So in any event, our output is a string. We'll use that string to create a response object, give it a status code, give it a content type header and then we send that into the event dot respond with because it's our custom response. So with that let's go ahead and build it. We have our build runs our build command sequentially as mentioned. Let's go ahead and run that. So those guys are going that has built our public directory. Yep and then let's go ahead and upload our public directory to a Google Cloud Storage Bucket. Now, it doesn't have to be Google Cloud. It could literally be any static storage bucket. S3 for example from Amazon totally fine I just prefer Google Cloud So I upload that now Oh forgot to mention that my CDN value for this example is static So that got included here as part of the output template. You can see those guys here. And then after we built this stuff, the server code gets put in this build directory. this is our entire worker script including our spell code and we can see the template up here at the top so somewhere in here we can see our static bucket references our bundle CSS our bundle JS, great those things will map because our Google Cloud bucket is being served at the static.workers.ninja location so So re-upload this because I forgot if we had. We did. Great. So now we're going to set the cache control headers on all these files to 30 seconds just because it's a demo. Keep it short. And then we're going to upload our worker. Now, this CFW tool is one of mine. It is not yet released, but it will be released when this talk is live. It's basically a Wrangler alternative. of it. You can do any of this stuff with Wrangler just fine. But here's our cfw config file. Things of note, profiles loading up my cache set of credentials, so it's not on screen. Name is the name of the worker, and then routes is the routes that this worker is meant to be invoked on. So anytime the Cloudflare network sees a request coming in for a matched route pattern it's going to invoke this worker script and you'll notice here that we do not have static.workers.ninja because we don't want it to run there we just want it to do the the main app so let's go ahead and deploy this again deploying the build directory and there's only one so i have the single flag and it's done it uploaded the worker there's the the path that lives on great So let's check out that all lived. Here's our bucket. Let's refresh the page. Wait a second here. There are all our files. Refresh our workers. There our new worker And then let call it So it lives on workers Go ahead and call it And there we go It pulling in don know if you can see this but it pulling in bundle CSS from our static.workers that has real content, our global CSS and our bundle JS. So that's all real. Now, the page source says hello friend, which is the default, and this is all SSR. I can go and do hello Luke ED, and then we see it happen there. Hello everyone, it's there as well. And then we can see it happening in the browser too. So hello Luke ED, whatever, everyone. There we go. And now let's check out the response headers. So these files are coming from our bucket. We can see our public 30 seconds that we have set on this one, too. Again, we did it for all of them. And then if we look at the headers coming directly from our worker, we can see the text HTML that we have set. We only set one right now, but it is our server. We can do whatever we want with it. So let's go ahead and adjust our response to show that it's unique. XFu. Hello. What did I call this? Name. Let's go name. Hello. Name. There we go. Name. Okay, we have to rebuild everything. Our client didn't change so let's not bother doing that. We have to redeploy our worker. So it just overwrites itself and now if we reload the page here it should be updated. And it is. Hello everyone. And then we can go back to our default and we see our header hello friend. So instant updates. This is now available globally. you guys can hit this. It just works. So yeah, CloudFail workers are pretty cool. So the advantages to this approach, well, it's a whole lot more flexible, which means you have a whole lot more control, right? Like it's no longer just a static site.

 Because you are working with your own fetch handler, you get to decide what you respond to, how you respond to it, and basically the entire behavior of your whole worker. You can add new routes whenever you need because, again, it's up to you. You don't have to work around or sidestep anything else. because the bucket itself is a separate component. You have the ability to upload images or whatever assets you want without having to redeploy your worker, right? So if you have user avatars that get uploaded, that can just be shoved inside of an images directory within your bucket, and then that's instantly available to the rest of your worker. You don't have to constantly keep everything in sync. The buckets, as we saw, can set their own cache control headers. What I didn't show was that the Cloudflare config was set up to respect existing cache control headers. In my opinion, that's just the way to go, without a doubt. You can always override it within the worker itself. So if you set a different cache control header on an asset or on its initial body, that takes precedence. but it's just good practice in my mind to have the bucket be in control of its own cash control. And then the final advantage in this regard is the bucket's doing most of the work for us. So while KV, workers KV is great and there's definitely nothing wrong with it, it's just, you know, that's a lot of what Cloudflare itself is already doing for us with their CDN layer. So us having to re-implement it is kind of like, why are we doing this? It totally makes sense. It has its place and you can hook into it because they do have the asset handler abstracted into a package that you can bring in. I didn't show any of that. But having a Google bucket or an S3 bucket, that just takes care of range requests correctly. and you know maps maps the subdomain directly to a url automatically like it's just it's just so much easier and so much better and cost buckets are practically free like storage costs next to nothing and egress which is you know data leaving the bucket is super super cheap and with this approach you only have to pay for that once so if you do have a bundle dot one two three dot js you with excuse me with a like a one month cash lifespan you're only paying for that bundle JS file once in the month. So it gets fetched once and then it gets passed through the CDN. The CDN caches it and you never have to make that transaction again. It's just done. You don't have to pay for it anymore. And this is especially important when you do have a high traffic site and you do have a non-trivial site, right? Every single webpage we all visit is one webpage to probably double digit assets on that page. If your worker is having to be invoked 10 plus times per page just to serve a file, it will work. It will be fast, but you're paying for all of those requests all the time. Now, workers quota is super cheap, but you're still chipping away at your quota and paying for all of those every single time. And again, going back to the bucket advantage is when you completely sidestep Cloudflare workers and just rely on Cloudflare CDN to coordinate with the bucket directly, that's completely free. The bucket talks to the CDN. CDN behavior is completely free. There's no worker involvement. Cloudflare has never charged for that. but there has to be gotchas right um so of course when you control something you're the captain of your own ship you have to do everything you have to be aware of what you're doing you have to be aware of the gotchas and it's you have no one to really run to if if you get stuck or if you don't know what to do which is empowering is great but you you know you are deviating off the path that's been laid out for you. Totally works, totally fine, but it is something to think about. You know, a separate thing is that while it is great to have two deploy units, you still do have two deploy units. So you can totally automate a Google Cloud bucket rollout with a Cloudflare rollout every single time and then that never an issue ever again But you know if you have pieces that are not necessarily in sync all the time those are two different bits that you have to orchestrate. Generally not the case. Generally you can just sync it, synchronize it, and be fine, but, you know, your mileage may vary. And the third thing, but this applies to worker sites and this approach, is that you may have to purge the Cloudflare CDN after every rollout. Again, it depends what you're doing. It depends how long your cache lifespans are, stuff like that. So with control on the mind and having to juggle so many things manually, there should be a way to automate this stuff, right? Let's take a look. Okay, so very much like CFW, this new tool called Freshie is not yet available, but will be once this talk is published. So again, big disclaimer, this is very much a preview and very much a work in progress. I imagine there will be a number of changes between now and the published time of this talk. Anyway, let's get into it. So Freshie is very much in line with many other app frameworks where you may be used to. All of us are somewhat familiar with Sapper. So Freshie is very similar to Sapper, similar to Routify, similar to Next.js, a bunch of these. So what that means is you have a route structure or a file structure that determines the route patterns of those files. Freshie takes care of the mapping of those route patterns to the request. Now, the main thing here is that Freshie works with Svelte, but not only Svelte. So today, Freshie already works with Svelte, works with Preact, works with Vue, works with React, and there might be more. Big difference here is that Freshie is meant primarily to target Cloudflare workers, of course, given the context of this talk. But Cloudflare workers isn't the only deployed target. So you may be able, just through the changing of your dependencies list, can configure your package to use sorry configure your app to use Svelte with Cloudflare Workers Svelte with Node Svelte with AWS Lambda with Google Cloud Functions or do any of that with some other UI library It's really just a mix and match of those dependencies. So in this example project, we have UI Svelte with SSR Worker, which means we will be using Svelte to build our pages in our components and then targeting a Cloudflare worker for the SSR mode. So if we look at something like this, route slash index, this becomes the homepage. Very simple. Again, just a demo. This can inherit the layout sibling next to it as well as anything else beneath it. And so this slash blog slash index becomes slash blog for a route. It has preload functions, which coming from a Next.js land is like get static initial props, or again, very much like sappers preload. This just gives you initial prop data that immediately gets passed into your script. From there, you can take those articles, run them one by one, whatever you want to do. Same thing here, define a dynamic path portion with square brackets. So this is slash blog slash colon ID. And you can access that ID through paramsa ID. And very much the same way, use whatever logic you want to set up the initial props list. Now, if I go ahead and build this, right? Yarn build, no minify, what happens? So you can see it's already done. yes I'm not minifying but the whole double build completed in less than a second we see all of our client output here so client build these are all would be production ready if I didn't minify but all of our client assets are here and then our server asset which again has to run after our DOM as explained in the last demo our server asset has Cloudflare workers code So this is all the Svelte SSR included. Excuse me. Here's some layout code. Here is, what is this? Here's the blog index code. You know, so on and so forth. So this is a file ready to be uploaded for Cloudflare workers. Right? A whole bunch of code gets generated for you.

 And at the end of the day, it spits out a fetch event listener with the designated render function that we need for Svelte. So if I just copy and paste this now, cloudflowworkers.com is like a little preview thing. Again, this is a quick demo. I just want to make this go quickly and not redeploy stuff. So if I update the preview with the code we were just given, ta-da, we have SSR output here. I can click on this. It goes to the article page. This is all SSR. You can notice here on the right side that my client is actually, my client assets are sending 404s. But, you know, if I go back to blog, fresh request, sent to article number one, article number four, five, whatever, you know, this is all completely SSR. And now, you know, the client code is client code. It works. The client code can be uploaded to a static bucket just like before. CFW will do this for you. Again, you can use Wrangler, that's not a problem. The last little bit I want to show for this demo is that we can have the same app suddenly start targeting Node.js. I have to link it up real quick. Actually, excuse me, I have to do this too. again work in progress it's very that I'm working on a bug right now but if we rebuild this again with no minify just so we can see what happening the new build output we still have client but the new build this is now a Node app So we can actually spin this up and run it, but here we have HTTPS, HTTP, like these are Node.js modules, and that kicks through to a start method. If we inspect what's going on, it creates an HTTP server, does what we need to do so that actually invokes SSR. And let's just take a quick look at it. I believe this goes on port 3000. It does. So we can inspect this. Hello world, it's a very plain index page. Go to blog. Get our full list of articles here. Can go to one of the Oops, can go to any number of these things, and we have our SSR content going. And again, we have inherited layout files. Somewhere in here, we have our CSS being injected as well. And yeah, that's Freshie. Yeah, so, I mean, that's Freshie. And just like CFW, Freshie will be public once this talk goes live. If not, something went really wrong. But it's definitely a huge target of mine right now. And in any event, I hope you enjoyed the talk. Thank you very much. If you have any comments or questions or just want to say hi, please feel free to reach out. Thanks very much. Bye.