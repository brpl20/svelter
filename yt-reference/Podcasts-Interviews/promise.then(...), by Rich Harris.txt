 I hope no one is expecting a polished presentation, much less a rehearsed presentation, but I do have slides. This is a photo from Barcelona. A couple of months ago we had our second in-person conference in Barcelona and this is me giving a talk about async await in Svelte and the talk was called What Svelte Promises. This was a really great time. Barcelona is a terrific city. Had a lovely time hanging out with everyone from the community. But also the Svelte team got together for an in-person co-working session for the first time ever. And some of the stuff that came out of that session is the stuff that I'm going to be talking about tonight. Turns out actually being in a room with the people that you work with and having a whiteboard to scribble on really makes a huge difference in what you're able to achieve. so if you've been paying close attention to the Svelte repo you might know that we merged a very big pull request this week we actually had 666 commits when I asked for feedback but we thought maybe that would be bad luck so we added a few more this is one of the most fundamental shifts in what Svelte is capable of we even have documentation and go over here and if you do the command K thing and search for await, it'll take you right to this page. This allows you to use promises directly inside your components. And so now that that promise has been fulfilled, let's talk about what's next. first just to recap because you might not be familiar with this work the reason that we're doing this is like web apps are these fundamentally distributed systems you have people using the software on their own devices which you don't control and they're communicating with your origin server which is communicating with the database which is probably on a different computer and then you have the CDN in between which is handling static assets and maybe you've got some edge middleware and whatever and I'm not telling you this because you don't know it. I'm just saying that this is the nature of building stuff on the web. You are dealing with asynchronicity all the time Like it completely fundamental to what we do And yet components are really bad at async Component frameworks historically have just not been able to solve this problem in any meaningful way Probably shouldn't be surprising, like when components first came out, when the mental model first started to bed in. It was around like 2014, 2015, and back then promises weren't in the language. Async awaits certainly wasn't in the language. and so the old formula UI equals function of state if you've seen that that function is asynchronous function and sorry a synchronous function not an asynchronous function and so what people would do is you'd have some local state indicating the value and the loading state and then an error state and when the state that the async state depended on you would make a fetch request and then if it failed you would populate the error state and if it didn't, you would populate the value, all of that stuff. And you would have these spinners all over the page and it's just a terrible user experience, which is actually very common on the web because we still haven't really solved this problem. And people thought maybe frameworks would save us. Next was probably the first example of a framework that tried to solve this with get server-side props. And the idea is that instead of doing the data stuff inside the component, you do the data in a loader and then you pass the data to the component. So who here has used SvelteKit? Okay, so you're probably familiar with the load function, which looks a little something like this. If I solve this example and hope that it's going to work. All right, so this is what a load function looks like. On a blog page, we have a page.server.js next to the page component, which goes and gets some data and then returns it as an object. and then inside the component, we receive that as a prop, and then we put it in here, and we do some magic to get the types to work. And it's fine. It works, and the framework is able to smartly serialize the data that you've used and parallelize requests and all of that stuff. But it's pretty suboptimal in a lot of ways. If you've built anything large with SvelteKit, you've probably experienced it firsthand. For example, the type thing that I mentioned, That works because we have a plugin for TypeScript that your editor is running in the background that is populating your component with the types that are generated behind the scenes and put in a sibling directory that is hidden from view but configured with the tsconfig root des option And it just like a lot of moving parts that we shouldn really have to fuck around with ideally And the problems don't stop there. You have the coarseness of it. Like you might have multiple different pieces of data that are independent of each other and need to be refreshed at different times, but they're in the same load function and the function has to run in one go. So you have to invalidate everything and you get more data. which means that you're sending more stuff over the wire and you're hitting the database more frequently all that kind of thing maybe you have one small component on the page that is using a specific piece of data but in order to populate that you have to have that requirement in your load function and then that has to get sort of prop drilled down to the component that is using it and particularly if you're using components that are driven by a content management system like you have a component that appears when some condition is met but not when another condition is met, and you can't know that at build time because it is coming from your CMS or your database. You either have to replicate the structure of your component tree inside your load function, or you just pay the cost of always loading it. And then if you delete the component, you have to remember to delete the data because there's no tooling that is going to tell you that you need to do that. So it just kind of sucks in a lot of ways, and this isn't a problem that's unique to SvelteKit. This is a problem that is endemic in component frameworks. generally. So frameworks did not, in fact, rescue us. Can I make this full screen again? I don't know. Do I care? All right, that'll do. So loaders fundamentally do not scale is what we've kind of collectively learned over the years. So we want to try and put the data dependencies back in the components so that we don't need to have this weird separation and all that goes with it. Turns out co-location is good. If you go back a few years, you would find a lot of people who said that you're supposed to put your HTML over here and your CSS over here in a CSS file and the JavaScript that manipulates the HTML in a .js file. And we look at those people as a bit of a historical curiosity now. They do still exist, but most people understand that that is just a really silly way to think about how you combine different concerns. Like you want to have the JavaScript that affects the markup in the same place as the markup. You wanna have the styles that apply to that markup in the same place as the markup It goes for dependencies too Like in the olden days the way that you would manage dependencies is you would either have a script tag at the top of your page and just load it that way or you would concatenate everything and hope that you did it in the right order. Absolute chaos. Nowadays, we use import statements, and everything is declared in a way that is visible to you as you're reading the code, but is also very importantly statically analyzable. And this is just an extrapolation of that trend, having the dependency on the data declared inside the component is just going to mean that your code is much more maintainable and, importantly, much more deletable. The best solution to co-location so far, I would argue, is React server components. And I have some quibbles with the RSC model. I don't know how familiar you are with React server components, I have to be a little bit careful what I say about them because as some of you know, I work at the React server component company and I like working at the React server component company, but I don't think that RSCs are the right way to do this. I think they introduce some trade-offs that personally I'm not okay with. It's a very chatty protocol. If you want to invalidate something on the page, then you're constantly going back to the server and getting a whole bunch of new JSX from the server to put back into your page, even if just a tiny, tiny thing has changed. And that just seems wasteful and unnecessary. But on top of that, there's this mental model between the server components and the client components that empirically is just really hard to think about and to understand. And we've seen that developers in general struggle with this. So we want to do things in a little bit of a different way. and we have a secret weapon Asphalt we have a secret weapon this is a tweet that I think has aged pretty well this comes from late 2018 in a conversation with some people about React hooks are a thing now how can we do something hook-like in other frameworks and it occurred to me that we're a compiler mofos we can do whatever we want we can change the way that that code is interpreted to suit our ends and that phrase we're a compiler mofos, it's something that we say to each other a lot on the Svelte team as we're trying to come up with designs for stuff. Because we are ultimately building a language and we can pick and choose the bits of that language we want to adopt and how we want to adopt them. Syntax and semantics are not the same things. We can use the syntax

 of JavaScript, but give it different semantics. And paradoxically, what we have found is that by changing the semantics of certain pieces of the language, we get a more idiomatic experience, not less. Some people just vehemently disagree with this. They're like, this is magic. I want nothing to do with it. Give me something that I can understand, like a stack trace that I can step through or whatever. But a lot of Svelte users feel differently. and I'm one of them. So an example would be assignments. When you do variable plus equals one, that causes anything that references variable to update. That's nice. You don't have to use a framework-specific API. Function calls, we have adopted the syntax of function calls and we called them runes and given them magical powers. Scope CSS is another example. Like a CSS rule that ordinarily would apply to everything on your page. in Svelte it just applies to the things inside the current component where it's being used and that just makes sense and await is another example of this we can take that await statement and the compiler can see that and say oh they're trying to do something asynchronous here let me compile it slightly differently to help them with that one more example is the using keyword I don't know how many of you are familiar with using there's this proposal called explicit resource management that is at stage three. And the idea is that instead of writing all this code, if you have a disposable resource, like a connection to a database or something, then you can create that at the top of the function. And then when you leave the function, you dispose of that resource. And you don't need to do all of this try finally stuff. The language just does that for you. And so this is the equivalent code using using. And you might imagine that that's kind of useful in a component context because you can create the resource when the component is added to the page and then clean up the resource when it's taken out of the page. But the way that components work is they are functions and they execute once and then that's it. And so if you're being strict about the language, then as soon as the component was initialized, you would destroy the resource. And that's not particularly useful. Here's a little demo of what I'm talking about. we have some state that we can toggle and you can see that oh it actually not showing up in the console for some reason but it is showing up in the real console We clear the interval every time we remove that block And all the code that is required for this is just this. We have a clock class that creates an interval. Once a second, it updates this piece of state. And then we add this thing called symbol.dispose, which is what the using keyword expects to find. When that is activated, we just clear that interval. And so to use it, we just do using clocky equals new clock. And then that piece of state will update itself as long as this component is on the page. And actually, you can imagine if this took a function instead. Let's do... Sorry, Rich, can you bump up the font a bit? I can bump up the font. That was a good call. I'll bump up the font a bit. Yeah. You could imagine that if we did something like this, this dot interval equals that, and then we'll call a function like that. What have I got wrong here? The hash before interval. No, that is supposed to be there. oh it's because I didn't do that alright we'll make that a normal class and then we'll do let time equals I should have practiced this then we'll pass in the function like that time equals t and then get rid of the clock.time reference maybe I need to reload the page oh it would help if I fix the import hmm well I clearly have fucked something up here but you get the idea the point here is that because we're using or abusing the language we're able to create these sort of reactive primitives that in theory could be used across frameworks So by being invasive in how we treat the language ironically we are able to be close to the language and we able to be more framework agnostic And that is something that we hope to land fairly soon. We'll see. But that's not really what we're here to talk about. We're here to talk about await. I have some demos for you. The most basic example of what you would do with await is obviously load some data. Here we have a function called multiply, which you can imagine is running on a server somewhere because we don't trust the multiplication operator. So we need a web scale multiplication API. And what it's doing here is it's after a random delay up to half a second, it's just multiplying these. And when I click this button, it updates. but it doesn't update at random times as those promises resolve because that would be crazy. You would have a very unpleasant user experience if things work that way. But more to the point, this N here, that's synchronous. There's nothing promise-y about that. So if we just updated that as soon as we clicked the button, then you would have things like 2 times 3 equals 3 and stuff like that, which is obviously no good. so there's a few things that we're doing here first of all we are synchronizing all of the updates everything happens in the background and once all of those promises are resolved we then paint the result to the screen and secondly we're doing all of this in parallel like if you had this in a react server component not that you can have state in a react server component but if you did then this would all be sequential have 108 followed by the other ones that one resolved and so on. So this on average this is a quarter of a second. So if you have five of these that would take over a second on average before you saw any updates. But that's not what's happening. It's just gated on the slowest promise. And there's lots of ways in which Svelte is able to parallelize work that would otherwise happen sequentially so that it just does the right thing on your behalf. And again that's only possible because we're kind of abusing the language a little bit. Another demo So abort signals. I'm actually a bit nervous that this one is broken because it didn't work earlier. But we hitting an API here There dummyjason slash products And if I were to maybe if I throttle my network a little bit I make it a 3G and then if I start searching for food or something, is it going to work? Apparently not. This is how you know that this is a real demo and not a recording. turn the throttling off while it's loading alright we'll give it one more try and if it doesn't work then I'll just talk through what's supposed to happen so okay what this demo would show if it was working is that as you type we request new data and that happens for each keystroke and those promises will come back in and so you'll get a response for F and then one for O and then one for O and then one for D. And that's probably not what you want. Like if you're typing and you're still waiting for data, don't show me the incomplete data because I already know that's going to be out of date by the time I get it. And I don't want it flickering as I'm typing, just wait. And this abort signal lets you do that. So inside this derived, we call get abort signal as that fetch is happening. And then if that runs again, or if the component is destroyed, then the abort signal that Svelte created on your behalf, it will then abort on your behalf and you won't get that response. It will just ignore the results. Something else that you can do is you can offload expensive computation to a web worker and then just put that inside a function call. So here we have a little work utility that takes some input code code and then turns it into a worker. And we just have some code for determining whether a number is prime. So I don't know if anyone has any favorite prime numbers. Seven. Okay. Great one. Actually not that expensive to compute it turns out. This can probably just be on the main thread. But you get the idea. You can find all of the prime numbers that you like with this. Note that if If this did take a while to resolve, then, in fact, let's do that. Let's say, make that async, and then await new promise, and then we'll,

 and then we'll do one of these maybe that doesn't work maybe that broke the string stringification so I can't demonstrate that never mind what I was getting out there is the because we have a state change that is driven by an input when you change when the data comes back we we don't then change what's in the input the input is always the source of truth and then the rest of the user interface kind of catches up, because otherwise that would be a terrible user experience. You can also use this for lazy imports. If you have a component that only applies in certain conditions, like it's the little chat widget that pops up when you press the button, or it's something that only appears on mobile or only on desktop, then you can do that. And there's no flickering as this loads. It just loads it, and then it updates the UI. And finally, you can use this to preload images using something like this. This utility here just creates a promise that resolves once an image is preloaded, which means that you don't get that awkward moment of the image flashing in after the component has been rendered, which is a really sucky experience. And obviously it goes without saying that all of the asynchronous stuff that is happening in these three different Pokemon components is happening in parallel. It's not doing Snorlax and then Squirtle and then Stunky. Okay, I'm going to try something that I haven't done before, which is a quick implementation walkthrough. Fire up my sandbox. How do I get out of full screen? So my local host here. This is just a local copy of the demo that I showed you a moment ago. and what I'm going to try and walk through what happens when you press this button so you press the button and ignore this for the minute oh yep so we have this function internal set which gets called when you update a piece of state if it equal to the current state then we obviously don do anything but otherwise we going to capture that old value And after doing some throat clearing we come to this bit This is the new stuff This is what makes all of this possible. We create something called a batch, which is a ginormous class that I'm not going to show you. But when we create it, we also schedule a flush of that batch after the next micro task. If you're not familiar with QMicroTask, then it's basically saying to the browser, I'm going to let you finish what you're doing, but immediately after that, I want you to do this code. Before any set timeouts, before any request animation frames, before you repaint the screen, run this code. And so if there are multiple state changes that happen immediately, sequentially, then those will all be grouped together into the same batch. After that happens, we capture the change. We make a note of the value before the batch was created, and we make a note of the current value. That's important because if you later have multiple overlapping batches, you do one thing that results in some asynchronous work, and then while it's ongoing, you do another thing that results in some asynchronous work. You need to be able to reverse the effects of the first batch before you commit the second one. Otherwise, you will have a partial update applied to the screen, which is no good. So we need to do all this time-traveling stuff. and when we get around to flushing the batch first we see if anything has been made dirty by the state change and by dirty I mean we mark the reactions of every changed piece of state reactions are derived values and effects which includes the expressions in your template and we literally just iterate over the reactions the things that we have noticed read this piece of state as the effects are running. And if it is a derived, then we mark the children of that derived dirty. If it's an effect, then we schedule the effect. Effect scheduling is just going up the tree of effects until we see something that has already been marked dirty. And if we get all the way to the top, then we say this is a dirty component root. Normally in an app, you'll just have one component root. and if we get all the way to the top, we push that component route to the queued route effects. And then once we've got that, we can then flush the batch by processing all of the effect routes here This is the stuff that I was talking about a minute ago with the time traveling. If there are multiple patches, then we need to do some gnarly stuff to undo the batch. Most of the time that's not true, so we can just collapse that. And then we traverse the effect tree. And what that looks like is just a loop that does a, is it depth first or breadth first? I always get them mixed up. Traversal of the effect tree. And each branch in turn, sorry, each effect in turn gets processed. And if it is like a user effect, like the one that you would create with an effect rune, then we put it to one side for a minute. We don't want to run that straight away. The same goes for render effects, which are the things inside your template. We don't want to update the DOM straight away because we don't know if there's going to be any asynchronous work that we need to wait on. So we just put that to one side as well. If it is an async effect, which means an expression that contains an await or a derive that contains an await, then we also put that to one side, but only because we want to run that with the latest values, not the values that belong to the current batch. and then everything else which is block effects like if each key blocks and so on we run those immediately because that might kick off more asynchronous work once we've done that once we've gone through the entire tree and in that fashion we go back inside the uh the process method and if it turns out that there is no pending asynchronous work great we can just commit everything to the DOM. So any new branches that have been created, like any new if branches or something like that, any expressions inside your template that need to be updated, we can do that at this point. If not, then just make a note of all of the things that we're going to need to run again next time and then we bail out. And then once those promises resolve, we end up back here and we just keep doing that until everything is settled. I hope that made some sense and was at least a little bit interesting This is the stuff that has been keeping me up at night for the last several months. It's good to finally unburden myself, I guess. If it made no sense then I sorry that was probably a little bit of a waste of time But that is how asynchronous Svelte works This is just part one of a multi master plan So step one is we make await a thing that you can use in components. Step two is the SvelteKit part, which I'm about to talk about. This is called remote functions, and it's what is hopefully going to make load functions unnecessary in the future. Before that can be truly useful, we need to have asynchronous server-side rendering. at the moment if you have anything awaited inside your component it doesn't get server rendered you just have some fallback user interface which is no good because you don't want to have loading spinners when you first go to a page, you want to have that rendered on the server so that it can hit the database that the server is probably right next to in Virginia get the data and then send it back to you wherever you are we're working on that and hopefully we'll have some updates soon. Part 4, Forking so we want to be able to do speculative renders like hey Svelte what if this URL was different what would happen then and then Svelte will go away and it will try and render it and it's like oh we're going to need to fetch this data we're going to need to do this, that and the other we're going to need to import that component but then it won't actually do it it'll just leave it in a function that you can either call or discard that means that you could hover over a link and it would go away and it would fetch everything that it needs so that if you click on the link, it's an instantaneous navigation. We have that in SvelteKit today, but it's done with load functions and in the future, we might not have that. So we need to be able to do this. And then step five is, who knows? There's going to be lots of things that become possible as a result of this work and we're not totally sure what it is yet. So remote functions. This is a pull request that my colleague Simon is currently working on. Let me try and make this full screen again. Oh my God, I'm so bad at Google Slides. I don't know how any of this works. No, I don't want to start from the beginning. Oh, this one? Thank you. All right, there we go. This is the PR. You can check in on progress here. It is very incomplete. It is definitely some bugs. Even Simon, a.k.a. dum-dee-dum, sometimes has bugs in his code which should make the rest of us feel better. But it's kind of usable. You can play with it and start getting a sense of what it's like. And I'll give you a quick demo.

 demo, I guess. I have a little demo app over here that maybe I can get running. I'm going to need to kill the other dev server back with me. Okay, so I'm going to log out quickly. This is a copy of the load demo that we saw in the tutorial before here. So previously, you remember that we had this load function. We also had a load function in this other page.server.js which loaded summaries for the page. Actually, maybe I'm looking at the... Yeah, it should be on this example here because this data is being used in the layout to populate a sidebar, and we're also doing something similar for the post itself. And we've got a whole bunch of different files here. We've got the page, we've got the layout that goes next to it, and we've got the thing that loads the data, and then we've got all of this stuff down here, and then we've got the data on the server. There's just a lot of stuff, and we can do better. We can make that simpler. So, give you a little tour. The blog page, this homepage here, is just showing the summaries. And it's doing this with a function that is called get summaries that is imported from a file called data.remote.ts. and we can just command click into that and see what it's doing. Not very sophisticated, like we literally just have some hard-coded data and it's returning everything except the content because we're trying to minimize the number of bytes sent over the wire. And if I click into one of these, then you'll see the same data is over on the right-hand side and if we look at the network tab, we can definitely turn off throttling now. and I disabled the cache to prove that there no shenanigans here Ignore all of the warnings down at the bottom There definitely some rough edges here If I click on that then you will see that we make a call to this get summaries function And it's just some lightly encoded JSON. And then if I click into one of these posts, it doesn't get summaries again. And even though it's down here at the bottom, it recognizes that that data is unchanged because we haven't explicitly said, oh, by the way, this is out of date. But we did go and get the post data for this page. And we'll do that for all of the other pages, too, as and when we need them. So getPost is this function here. And this time we have an argument. We're not just getting all of the data. we're getting a specific post, which means that we need to pass in an argument. And because this function is effectively a public endpoint, like it looks like an internal implementation detail, but it's actually a public endpoint, and we're trying to communicate that by putting it in a file called data.remote, and we're trying to enforce good habits by forcing you to validate your inputs. Because if some evildoer were to try and send bad data to your functions in order to trick your system into doing something that it's not supposed to, then all bets are off. So we make you validate it. And v.string here, this is a library called ValiBot. You don't have to use ValiBot. You can use any standard schema validation library. Standard schema, if you're not familiar, is this. No, come on. Where's the website? oh there we go um who's heard of zod okay good zod is another standard schema validation library validbot is another one um built by new york's very own uh fabian hill and it's pretty cool and it basically takes some input data and if it's not the right type it will yell at you and standard schema allows you to use any of these libraries with a consistent interface. And the nice thing about this is that once I specified this type I get the types inferred inside the function itself So without having to add too much ceremony I get a guarantee that I dealing with the right kind of stuff And that also means that inside my post page, if I call getPost, ignore that red squiggly, I think I probably need to update my version of the Svelte extension, it's going to tell me here that this takes a string. So if I were to do something crazy like passing a number, it's going to tell me that's not good. So we get type safety from server to client and it's not fictional type safety because it's actually being validated so you're guaranteed to get the right types on the server which is kind of nice. So we're just finding the data from that array and if that doesn't exist like if you do something like this then it will error but hopefully better than that. Oh, no. All right, it's not going my way. Never mind. So those are queries. That's the most basic kind of remote function. For a thing like a blog post, you might actually want to pre-render it instead. So instead of a query, we could do pre-render. Just pre-render, import that. And then now, if I were to build this, is going to spit out a bunch of stuff up here. You'll see it's actually generated some data at build time. It hasn't generated the right data for the posts because it doesn't know what it's supposed to render yet because we haven't done server-side rendering, so the crawler can't see the function call. But it has managed to do this. And this is cool because that will just go on a static web server and it'll be sent to the CDN that you're using. So when you request some pre-rendered data, you're not going to hit the origin server, you're just going to go to the nearest CDN point of presence, which is probably a few milliseconds away. And everything's going to be super fast and also super cheap to run. And you can, previously in SvelteKit, you can pre-render at the level of pages, but now you can pre-render individual functions, even on pages that are otherwise very dynamic, which is a new capability that I think is pretty cool. So that's query and pre-render. Let's talk quickly about form. If I go over to this login page and bring up my inspector Click on that Good it takes me to the form So we have this login which we're importing from auth.remote and this is a form function. We can get details about the current request that's being made so that you can access things like cookies. So if I type in a name and hit login, it's going to just add that cookie. This is not a very good way to do auth. Please don't take this as a serious example. But now when I refresh the page, it shows me that I'm still logged in. And if I click logout, the opposite happens. It deletes that cookie because it calls the logout. And a nice thing about this all just being regular all functions is that I can do things like find all references and find out where that is being implemented. And you'll see that it's doing this by calling await me, which calls get user, which reads the cookies. And this is all like behind layers of stuff, but we can always get access to the request event. So you can have these helpers like get user anywhere in your app, and you can use them anywhere in your components, and you don't need to have this duplicated inside your load functions. You don't need to pass an event object around. It's really composable and really nice to work with. Now that I'm logged in, or now that I was logged in, I can go to the blog page, and I can create a new post test. Yeah. and it will see it's added the, it's redirected me to the new page, and it's also refreshed this query because that is now out of date. So form is the main way to send data from the client to the server. It's the one that works, whether or not JavaScript is enabled, which is cool, although obviously without JavaScript, since there's no server-side rendering, it won't work today, but it will soon. We also have something called command. If I click on this, it's gonna increment that count. It's taken a while. Let's take a look at why. Bring up my inspector, click on the button. Looks like it's doing some...

 something here in this event handler. It's calling something called increment clicks, and then it's getting some data from get clicks. Increment clicks is, ah, that's what's happened. Some idiot putting a wait sleep in there. Just to illustrate that sometimes you need to deal with slow states. Like, this is no good. So we can make this a little bit better. In fact, there's two things that's wrong with this. First of all, if I clear the network queue and press this button, then you can see it's calling increment clicks and then once that function comes back it's then calling that await me function again and it's calling get clicks. So it's making three network requests and the reason that it's doing that is when you run a command or a form action it doesn't know what needs to change as a result of that. Like if you log out then you might need to rerun all the queries in case they have access to some data that you no longer have access to because you're logged out. So it's just going to preemptively rerun everything. But if you don't want to do that, and most of the time you don't, you can tell it what's going to change. Either inside increment clicks, you can do await get clicks.refresh. And then now it's actually crashed because of some bug that we're still figuring out. If I click on this now, then it's not going to make multiple net requests because the payload includes data about which queries just got refreshed. So that's pretty cool. You get, we call them single flight mutations. But in case you don't want to do it from there, you can also do it from the front end with updates. Oh, I guess I just gave the game away. Same thing as before. It just does the one request. But even better than that, we can add this override, which lets us do an optimistic update. I probably going to need to kill the tab again So now if I click it it updates immediately It a little bit buggy right now If I spam it multiple times then it gets a bit out of whack Work in progress. But you get the idea. And if an error were to happen, it would automatically roll back that optimistic update. So this is a pretty nice way to deal with all of that stuff. And compared to React server components, like this payload, 0.3 kilobytes, compared to getting an entire page of new components. It's different. How are we doing some of this stuff? We had to break a few rules in order to implement this. If you've worked with VeeP plugins before, then you'll know that you can transform code from one form into another. And that's what we're doing with the remote functions. If you call the remote function from the server, then you're just calling the function. but if you call it from the client, you're actually calling like this thin wrapper around fetch. And that involves a transformation from the code that you wrote into the code that runs in the browser. And normally you would do that by actually looking at the code and doing some static analysis on it and then turning it into something else. But that doesn't work because there are different kinds of remote functions and we need to be able to distinguish between them. So we need to actually run the code in order to find out what is in the module. But in the dev server, how can you run code that you haven't yet transformed and you need to do some pretty ugly stuff in order to make that work and this is one of the great things about V it gives you structure and a way to do all that but it also gives you the latitude to really kind of go nuts with some of these things and break the rules and that's handy more to the point though you probably, if you were looking at that expression you're like, okay, so await get likes get likes is returning a promise but then we're also doing get clicks but we're also doing get clicks parentheses dot with override and you're passing that to command parentheses dot updates and command returns a promise how is that working also how do you have a promise inside your template that is updating automatically when some state changes and the answer is we need to get into some criminal mischief who here knows what promises a plus is does anyone here Okay, I see you. So back before promises actually existed in the language there was this thing called Promises A which is basically a description of how promises should work And there were a bunch of different libraries that implemented this contract like Bluebird and Q and When.js and all of these things. And the promise that you interact with in the browser is really just an implementation of that. But we can... This joke works better in the UK where they know who Terry Venables is. So we can make our own venables, which are treated similarly to promises by the browser. Got a little demo of that here. So this is a query. It has a ven method. And we have just some stay and a sleep boilerplate just to make it visible. And we are logging await query. and surprise, surprise, it logs query zero. Even though this is clearly not a promise, it is a venable. If we click the button, nothing happens. Does anyone want to stab a guess as to why nothing happens when we click the button? Anyone? Bueller? Bueller? Okay. Okay. You're now returning sleep that bit? that's a very good guess. It's actually not that. The problem is that here, this gets turned into a function, right? A wait query gets turned into a function that we can see down here. And the way that reactivity in signal-based frameworks like Svelte works is that you run those functions and then you make a note of which pieces of state were read during the execution of that function. But when we run this, we're not reading any state because we don't read the state until we've finished doing the other work that happens beforehand. So we sleep and then we read the state. So maybe we can fix it like this, const value equals count so that we read it immediately and then we just resolve the value. Does that work? It does not. And it turns out the reason for this is that even though we read this function immediately, we don't call it immediately. The browser waits a minute before calling that so that anything inside a then callback is a micro task after the statement And there good reasons why that the case but it makes our lives a little bit difficult. And the way that we've fixed it is we make the then itself the reactive bit. So we turn this into a get, and then we do... One of these. And now when we click this, hopefully it works. Kind of filthy. I think it was Paolo who figured this out. He's the Italian member of the Svelte maintainers team. He was just like, you need to get the then. And the problem was solved. And because of that, we now have remote functions. is you can just await stuff inside your template and it works fully reactively, which is the sort of thing that you can only do if you're prepared to break the rules a little bit. All right, now that we have this foundation, what can we do with it? We have some ideas around caching. There's caching on the server and there's caching on the client and those are two different things. You could imagine something like this. This is not a real API. This is something that we might add. We're still trying to figure out the details. You can imagine if you're building something like Product Hunt and you have products that are being upvoted by users. You want to grab some data from your database. And then based on how recently it was submitted, you might want to cache that for a second because upvotes are coming in thick and fast. Or if it's been around for a little bit longer, maybe it's okay to cache that stuff for a full hour. and if it was posted longer ago than that, then you can cache it for a lot longer to ease the strain on your database. So that's something that you can't know until you actually run the query. Like a lot of systems that have this sort of thing, you have to specify how long you cache something without actually running the code, which doesn't make sense, but we're experimenting with an API like this. We could go further. We could say instead of having a period during which you cache the data, We could say, after a certain amount of time, any client that reads this data needs to re-request it. It needs to go and get some more data. And that way you can have live updating stuff

 driven from the server, which I think would be pretty cool. In the client, things are a little bit easier because you don't have multiple different users to worry about. You just have the one current user. So whereas here, we have to think about, if this is a serverless environment, what does it mean to cache something? Do we need to use some kind of KV store? And that's going to be platform-specific, so we need to have an adapter API for that and it probably needs to be opt-in because KV stores are the sorts of things that you normally need to pay for and we don't want to opt users into paying for something if they don't want it. So we'll start with HTTP cache control headers and then upgrade from there but we don't exactly know what that's going to look like. But in the client it's way, way easier. You can just keep stuff in memory. So already if you have a query that is referenced multiple times on the same page it will just use the same data until you say this needs to be refreshed. so you can just call queries without really thinking about it and it will just do the right thing but even for stuff that isn't currently on screen if you know how long something should be cached for then you can just use the cache object not all people know that this exists this is a really cool API that lets you have an origin scoped cache that is available to both your service worker and your main thread so you could have a deployment scope cache that takes everything inside takes the result of your query and then puts it in this cache and then if the user comes back to a page or they close the tab and they come back another time if the cache data is still valid we can just reuse it and for pre-rendered data that can be cached immutably there's no reason that you ever need to evict that until there is a new deployment so we can get really nice offline support just basically for free without thinking about it and we can really avoid needing to send people back to the network and to hit your database over and over again just using the stuff that is available in the browser. Batching is something else that we want to add. If you have, say, a get-to-do query like this, maybe you've got a whole list of to-dos and if you request those individually, then you're gonna be making a bunch of different requests to your database and that wasteful It be better if you could have the same API from the caller perspective like you still just calling with an individual ID but as long as you make those requests at the same moment it will come to the server in a single request and the function can make a single database request get all of the data and then send it back That way more efficient We also want to have some kind of real-time capabilities. Who here knows about service and events? Okay, server-sentence events are like the unloved cousin to WebSockets. WebSockets are how people normally think about real-time data. But a lot of the time, you don't need to be sending stuff from the client back to the server. You just want to get some real-time data from the server. And for that, server-sentence events are a really good choice. They work everywhere in all serverless environments, although you need to worry about max duration and so on. Just way, way simpler than WebSockets. and what we'd like to have is something like this. You can have a generator function on the server, query.stream, that just returns new or yields new data as long as something is connected to it and then from the client, you can just call that, oops, we can just serialize the yielded data and then deserialize it in the client and you can use that as an async iterable in the client and if you do hit the serverless function max duration, we can reconnect on your behalf and stuff like that, which could be a really nice API. But of course, in a CIDA component, you probably don't want to be using the for await loop. You probably just want to have whatever the latest data is. So down here at the bottom, we're just using it like a regular old promise. So in the same way that we were making our own Venable before, now we're making our own Venable async iterable, like this monstrous chimera of different things. So this is what an async iterator looks like. You have the symbol.async iterator method on it and it returns one of these objects. And then if I, so I can await this stream because it is thenable, it has a then and a catch. But I can also for await it and we can open the console and click go and you see that it awaited and then it opened the stream and then it ran this logic a few times We never got to the end because we called break and then we closed the stream because we invoked this return method In the context of remote functions that would be you know we don need this data anymore We closed the tab or whatever, broke the connection. On the server, we can be like, oh, they don't need this anymore. We can stop pumping data. But you haven't had to write all of that logic yourself. you're just using the things in the language and it just does the right thing on your behalf which I absolutely love you can also do the generator version of this if you put a star in front of a method then you can yield stuff works basically the same except I haven't figured out how to get a notification that the break happened I don't know how that translates to something inside a generator function if anyone knows please tell me This is stuff that breaks my brain every time I try and fuck around with it. Other languages look at that sort of thing, and they're like, what are you people doing? This is absolutely monstrous. It's crazy that we work in a language where you can mutate object.prototype and do stuff like that, but at the same time, it's really, really fun. You can dig yourself out of these kinds of holes. So yay JavaScript! I love it. with all of these things together we can start to explore some of the adjacent possibles I'm particularly interested in whether we can use embedded databases in our apps when we're developing them locally so your production app is probably hitting a Postgres database somewhere and when you're developing locally maybe you're hitting a staging database or something but if I'm on the train I want to have all of that stuff running on my machine and I don't want to fuck around with the Postgres CLI myself. Like, what if we could use PG Lite, which is a WASM build of Postgres, inside the framework? That'd be pretty cool. Maybe we can start to have opinions about auth and all of those sorts of things now that we have this kind of async foundation for working on some of these problems. Another one is internationalization. Normally when someone says, how do I internationalize my Svelte app, I send it to Paraglide, which is a fantastic library. It's cross-framework, which is its greatest strength, and also I would argue its greatest weakness, because it has to be framework agnostic. And I think it possible yet to fully explore this that we can do even better than paraglide by using these primitives so here t is um it a proxy that the types for which are have come from the framework knowledge of which translations and locales exist in your application and then when you call await t.greet it's actually hitting a remote function and getting some data and you can have a whole bunch of these at once and they could be batched up or they could be pre-rendered. We don't know. And then you could change the language and it would just automatically go back and get the translations for the language that you are currently using, for the exact messages that you are currently using and nothing else, which I don't think any other framework is currently capable of doing. You always need to have some kind of trade-off. Either you get all of the messages or you get all of the languages or you need to do some crazy static analysis which doesn't work if you want to change the language from a drop-down or something like that. And I think we could finally solve this. So that would be pretty cool. I've been waffling for far too long. Thank you for putting up with me. I would be very happy to take any questions that you might have. Thank you. Yes? With the weight of all of this abstraction is lost, do you have any control over in-pro-est state? You do, yes. So we have the ability to, maybe I can get out of full screen and give you a little demo. If we go back to the first one, where's my list of demos? and here we can add pending effect dot pending like this and I don't know why that keeps popping up. All right, so you can actually see how many promises are outstanding. This is scoped to the current boundary, so if you had some UI that you want to control independently, you could have the effect pending inside that instead and it wouldn't affect this one here, but you can use that for progress bars or like a loading message or whatever it is. So yeah, you can. The batch function is that, are the batch classes then both on a component basis or is that a goal? So the question for anyone who sees this online was...

 Is the batch function per component or global? So rendering is, like as far as Svelte's concerned, components aren't really a thing. They do have a presence in the runtime, but components are really just functions. So it doesn't care about component boundaries for this stuff. As far as it's concerned, you can have a component over here that is making a request to a batch query and a component over here that's doing the same thing and a component over here. Different components, maybe they appear together frequently, maybe they don't. It would all get batched up in the same way unless they're being requested at different times. But as long as they're being requested simultaneously, it's one request. Yes? What happens on errors? On errors, that is a terrific question. We have a boundary around this. we can create a failed snippet and do something like e.message. And then we can have a button which tries to render the boundary again. and then suppose this multiplication API didn't always work let's do math.random is less than 0.1 will reject otherwise will fulfill So we would expect to hit errors about 50% of the time. If I click on that, it's broken. Ah! In theory, that would cause the failed snippet to render, and then you can fix whatever broke, and then you can invoke the boundary again. And it should just work. work. And then in SvelteKit, we would have error boundaries added for you automatically that use the contents of your plus error component to populate them So yeah it just doesn work yet So in this case the component is like there's only single boundary, so any of those awaits fail. Exactly. So this boundary, basically everything that is inside here is considered part of this boundary. So anything that goes wrong inside here should in theory invoke this snippet. We can also define some pending UI here. Snippet pending. And then in here we'll do loading dot, dot, dot. And then when that is first created, that's what you see until the promises have resolved. Yes? I'm trying to understand the magic behind this and what it would replace for my own code base. And for my own, I use React and then switch it to as well for most things. And so this sort of replaces mostly like a TRPC plus, like this kind of query monster mashup. But the main thing I'm trying to wrap my head around is this like the source of truth for caching such like invalidating which seems to be the function that they're calling magically saying here's where it needs to like invalidate like rerun again based on like some speaking happening which again i'm trying to understand that method but like one thing that you know i see myself thinking a lot is having like a query that happens somewhere in the code base with like you know it has that query like you know method where i say here's a key and that's somewhere that's fully separate from where that would be. I say, you know, just know that this key exists, fetch this, and then it's got like an infinity, like, you know, stale type. And now it's like, you know, I'm using a client cache to say, proof magic happens, get this, you know, query again from the set application. I turned on this and how I could basically say, query this somewhere, but then get the exact same query without having to refetch into the same function, this remote function methodology? How could I do this to you? Like a small.ps file fix that? How can I say here's a key for that, I mean key clearly? So at the moment we don't have key based invalidation. Our hypothesis is that it not actually necessary That having query based invalidation which means you create the query by calling the query function like get clicks or whatever it is and then dot refresh. If you do that, then you're saying anywhere this query is being used on the page, that is now invalid. So we're going to get some fresh data for that. If it's not being used anywhere then we don't even need to do that or if you call refresh all which is a function that will be provided everything is going to get refreshed and then if you run a command or a form function by default refresh all is going to get called but if you specify which queries are going to get updated then it won't call refresh all it will just call those queries that might not be enough it might turn out that we we need to have a key-based or tag-based invalidation And if that happens, then it'll be a fairly straightforward API to add. But I'm not a big fan of using tags for this. It's a lot harder to understand how things are connected in your app if you can't right-click and find all references and stuff like that. So actually having a reference to the query function and calling it and then refreshing it is, I think, the better way to go. But it's early days, so try and find out. So if I have a query remote function in one place and it calls, it's called before the exact same function being called in a separate component, would the second one just reuse the first one and that's it? Or would the second one rerun a refresh entirely? So if it's currently on the page, it's cached in memory, and then if anything else calls that query, it's going to use the same thing. If it's not on screen, like if it was in a component and then it's gone off screen and then it comes back, then at that point, we will request the data again, but maybe it would be cached in your origin scope cache. But the default is if it's not on screen and then it comes on screen, we fetch new data. Yeah. I noticed both Svelte and Max define, and maybe it's actually React Server Components, define what is server-side function or remote function explicitly. The developer needs to define it I thought you had a compiler and you could figure it out without a developer doing that Like why is there like a reason why this is not just compiled Like oh we know this function could be on server and that would be better, what better for the application. Like, can't that be, can't it, or there's something fundamental? We definitely could, but we don't want to. We don't think it's a good idea, and there's two reasons for that. Number one, it's a security hazard. Candidly, if you have a function that is defined alongside the code that is running in the browser, it is so hard to remember that that is not just an implementation detail. That is a public endpoint that anyone can access. And we have seen examples of apps in the wild where people have been hitting server functions with data that the developer thought was a private implementation detail, and it turns out was not. so the kind of mistakes that people have made is using a user id as an argument to a function instead of getting that from cookies and by having that layer of separation by putting it in a separate file and giving it a name like remote our thesis is that you're more likely to remember that you should not do that and the other problem is around lexical scope when you have a function like a server function in a react component it inherits the lexical scope around it that that scope the closed over state needs to get serialized and sent over the wire but then inside the function it looks like you're dealing with the same stuff that was used to render the markup initially it looks like there's referential equality there isn't because you're receiving a deserialized version of something that was previously rendered and human brains just aren't built to cope with that sort of thing if you have it in a separate module and you have to import it there are just no gotchas with lexical scope and so we're pretty adamant that having inline server functions it's a cute trick and it's straightforward to do but it's a bad idea and to React's credit they don't let you call server functions directly from client components but it's still something that people have been confused by alright I think we're out of questions

 Oh, one more. Are there any current gotchas with generators and async generators in awake components right now? Like, especially if, like, say, a generator doesn't return a break at any point, would that actually just freeze the rest of the state update waiting for that? Yes, I mean, so that is a gotcha with async generally, is that if you await a promise and that promise never resolves, then the state change that precipitated that await will never be applied. And because it's global, if you have something in a component down here that somehow has access to some state that was changed over here, and those could be written by different teams in different buildings, and this person over here could really fuck up this person's day by awaiting some state and then never resolving the relevant promise. Our hunch is that that can be solved by tooling to identify where that's happening so that it's very easy to find out why that happens so that you can find the person to yell at when that happens. But it is a real thing. Other frameworks make you wrap state changes in something called a transition. because of that. But because you need to use that for basically every state change that involves asynchronous work, we think that's a bad default. So it remains to be seen who's right. All right, I think we should probably wrap up and call it a night. But I really appreciate everyone paying attention for so long. It's kind of hot and stuffy in here and this is a long talk. But this was fun and I appreciate all coming out. Thank you.