 We have to be extremely careful because one instance of this intelligence knows a lot more than any of us will ever learn in our lifetimes, can think much faster than us, is capable of increasing more things over time. And if we aren't careful, like life is extremely fragile and there's a very small range of conditions under which we exist. If we break any one of those conditions by accident, we may not be able to reverse it. Here's a quick word from our sponsor. Vercel is the platform for front-end developers, providing the speed and reliability innovators need to create at the moment of inspiration. Founded by the creators of Next.js, Vercel has zero configuration support for 35 plus front-end frameworks, including SvelteKit. We enable the world's largest brands like Under Armour, eBay, and Nintendo to iterate faster and create quality software. Try out Vercel today to experience the easiest way to use Svelte. welcome to svelte radio hello everyone welcome back to another episode of svelte radio today we have video amazing i'm joined by the full crew full gang yeah sean britney anthony what's up hey how's it going go ahead hey everyone today we we are going to talk about ai and what it means for for developers like ourselves where are our jobs going but yeah so so the person that's that probably knows most about this here is Sean. You've been diving deep into the AI ML space, as we heard last week. You quit your job and you're doing all things AI. What's that been like? How deep down the rabbit hole have you gone? Something I enjoyed about this podcast is that you can slowly trace my descent into over time. Sometime in August, I think we're talking about stable diffusion, And then sometime in December, I was like, AI is the future. And then I disappeared for a few months and now I back and I jobless So AI has taken my job and I have moved to San Francisco against my will because it is a terrible city but it has the best AI events and network So yeah I have definitely gone down the rabbit hole and happy to answer anything and everything. I have started, I have been cheating on the Svelte Radio podcast by starting a different podcast that is- So you should all go subscribe to? Yeah, latent.space. I'm very proud of the domain name. Was it actually free? No, it wasn't free. I actually had it on a separate domain. And then the guy who wrote the book, the O'Reilly book on natural language processing, emailed me and said, do you want latent.space for $500? And I said, yes. I think he made a deal there, right? I think he saw that I was going to do something good with it. So I think he knew that it was a sort of friendly handover. And anyone who was writing books about AI four years ago, I'm sure, is doing fine financially. Fair enough. Was it just like you thought AI was the future? Is that kind of what dove you down the rabbit hole? Or what started the AI drive for you? Okay, right. So there is a longer running thread. It is not just like I saw a thing somewhere and then decided to pivot my whole life. When I was an options trader, a lot of, and this was when I was in London trading currency derivatives in Standard Chartered. I actually wrote my first NLP application, which was taking prices and quotes from my brokers in Bloomberg and then pasting them into a pricing machine and parsing those text fields. and it was just a simple syntax. Part of those text fields into option prices that I would then use to update my volatility surface. And there was a lot of, and I did it entirely through a regex. It was a cursed, very, very cursed regex. Why? There was no test because I had never heard of a test at the time because I wasn't a professional programmer. I was a trader that learned to code, right? And it was a lot of fun, but all my traders used it. the entire global team managing hundreds of millions of dollars. Wow, that's pretty cool. So I should have had a clue that NLP was going to be a thing, but I never saw it as more than that. I was just saying oh it the simple text parsing right And then I think the other thing that has always been on the back of my mind is the progress in image generation There this very famous chart about the state of the art in image generation or face generation from year to year to year. And you can find one, I found one yesterday from 2012 to 2022. So 10 years of image generation progress. You can see 12, 13, 14, like it's very fuzzy not very good not even recognizable as a human face and then 2015 16 17 it starts to get good and that's how you start to get websites like this human or this person does not exist and now of course generating photorealistic stuff is free done locally on your machine or available through mid-journey for eight dollars a month and so i think this is i've always basically just regarded this as the Moore's law of our time. And there's a doubling effect or exponential growth effects. And yes, I'm late to it. Yes, many of us are late to this. But because something like a Moore's law does tend to last for a few decades, you are still in the grand scheme of things not that late. And so I'm just more interested in this. Yeah. So if we looked at the adoption as an S-curve, we're probably very early, right? Still? It depends what scale you're looking at, right? As far as very early, meaning the rest of the world doesn't think it's important, that is very early to me. So we are past that stage now. Now it's extremely obvious to everybody. So now we're maybe still kind of early. That's where we're at. We're at that stage, by the way, where Nat Friedman, the former CEO of GitHub, basically calls this a capabilities overhang. There's been so much research done over the past five years, especially with Transformers, that essentially has not been productized by builders, by developers, builders, founders, whatever you call it. And that's why it's time to build. There's shockingly few people trying to do interesting things with AI, even now. I think a lot of people might consider me a relatively fast mover and early adopter, but it took me six months to say, all right, I'm quitting my job. And there are a lot more people who are still waiting in the wings, not sure if they want to commit, not sure if this is like a Web3 thing that will be gone next year. And these are all reasonable concerns, and I can deal with each of them individually. But on this side of the spectrum it looks like there a ton of opportunity sitting around waiting for people to pick it up I was at a dinner yesterday This is kind of like an AI founder dinner And with people from OpenAI, DeepMind, Google, Facebook, the two co-founders of Dropbox, the three co-founders of Notion. And there were so many ideas that were being tossed around that just nobody was working on. And we were like, all of us were like, yeah, that's going to be very important. Each of us already had a thing. So we weren't just, it was just not going to work on that. But I would love to encourage more people to explore. I'll offer one more thing, which is something I've talked about in a previous episode, but I will bring it up here just so that everybody has context, which is, I think that you should view this as an extension of regular programming. So the kind of programming that we do, which is regular sort of if then else programming, You have a spec from a product manager, and then you translate that spec into code, which is a very well-defined thing. A lot of software engineers view that as their job. You have a spec translate to code, you have a design translate that to code, and then that's your job. But I think if you think about things as an iterative cycle, which is you have a spec translate to code, and then you instrument with analytics, and a product manager looks at the analytics and then makes a decision again to change something and then makes another spec and then you translate that to code. That is a cycle that is essentially learning more from data and then eventually surfacing that in your code somehow. And the ultimate expression of that is going to be some form of multivariate process that is more like machine learning, right? I'll tell you like, okay, so like if you ever write an if statement or if you have like branching logic, right? and it's conditional upon one variable, then you're like, okay, I need two variables. Then I need three variables. I need four variables. At some point, machine learning is essentially 175 billion variables, where you have run through an enormous amount of data, something like a few hundred terabytes. And that is an interesting, very interesting foundational use case, a foundational building block for a new set of applications. And I kind of consider that to be a reasoning engine is one of the terms that's kind of thrown around. It is fundamentally non-deterministic. So we have to figure out new patterns and design patterns and UX affordances to wrangle it. But I think it's enormous.

 exciting. And I feel like software engineers should not be apprehensive. They should figure out how to use it to solve their problems. You said it's a time for builders, Sean. I think the way that I know it's time for builders is if I go on Vasell domains and try and type in AI. There is nothing left. There is not a single TLD other than the country-specific ones that com.af or whatever that is free. So it's definitely time for builders. I wonder how many of those are actually in use. No, it's a time for domain squatters, for sure. Yes. Yeah, so the domain that I have got and I will be building is small.ai and that costs a little bit of money. But yeah, I'm interested in model distillation, which we can talk about later. I think it's in line with SWOT philosophy, by the way. The current trend towards larger and larger models, longer and longer chain, bigger and bigger context, is very much react-y if I'm going to make a hot take of have a giant footprint. And I think there's room for a svelte of AI. So when you're talking about the largeness of these things, is that when you're training the AI, basically? Are people throwing more and more information into the training sets? I'm not sure how it works. How much foundational knowledge do you want to cover here? Make a second. Explain it like I'm five. No, that's probably way, way too much. Can we make it a good basis? I'm sure all of you have read introductions and stuff. So I also don't know how to calibrate for what I should assume people know already. Yeah. Assume no nothing. Assume no knowledge, yeah. Okay, fine, fine, fine. So just to directly answer your question, it is not just for training. It is also for inferencing. So there's essentially a two-stage process, which is that there's an initial pre-trained phase. Like GPT stands for generative pre-trained models. So the pre-training phase is a large, expensive one. And then the inferencing is when you freeze all the weights of the training and you're just making predictions based on your existing prompt. And so that is... Sorry, just interject here. So when you were talking about millions and billions of variables, those are basically, they result in the weights. Is that kind of how it works? Yes weights and biases And so these are all individual neurons and together they called weights and biases And there a startup by that exact same name that is doing extremely well because OpenAI publicly endorses them. And the summation, there's a simple function you can call in PyTorch that gives you the summation of the total number of weights and biases. And that is the parameter count that everyone talks about. Oh, I see. Yeah. Yeah. For a very accessible introduction, everyone should be aware that the best introduction right now is Andrei Karpathy's Zero to Hero course on YouTube, where he builds it from scratch. Just start from a blank file on Python. Don't use any frameworks. Build the whole thing from scratch. And he builds a very simple GPT generator of Shakespeare solids. And it's still not very good, but it gives you the mental framework. And I really like that because you don't pull in anything else. You have to explain everything from complete scratch. Okay. The other thing, and then just to finish out the training versus inference, inference is comparatively cheap. And it is what you do when, for example, you download stable diffusion onto your laptop and you give it a prompt and you run it on your machine. There's a fair amount of people also working on model optimization, pruning, distillation. And that's the field that I'm playing in. Okay. And then let's talk about the rough progression in terms of history. The fascinating thing is that each domain, each modality in AI used to have different architectures. So you would have convolution nets for images, and then you would have RNNs and LSTMs. It doesn't matter. You can Google these names for text. But they've essentially all converged to using some kind of transformer in the last five years. And this is a fascinating phenomenon. And it's also why I actually wrote a post that it is not too late to pivot into AI because this recent transition into Transformers for Everything has essentially been the components era of AI, right? Like you now no longer need to catch up on the previous 15 years because they don't matter anymore. Because we now know that we have a better abstraction that we call the transformer that is much more scalable, is much more able to generate and focus on things that we want out of it. And it has grown a lot. So the basic paper that everybody should be aware of is attention is all you need. It came out in 2017 And it was a relatively low thing for a year kind of like React and maybe Svelte Like when it launched like not that much hype Like people were just kind of like it's one out of many papers. And then it took about a year to really pick up. And then Google really led the development of this with BERT, which is, I think, bidirectional encoding representational transformers or something like that. And these are still like relatively small in terms of the grand scheme of things, like a few hundred million parameters. There was a family of models that was all Sesame Street characters, which I think the parents will love. So Bert inspired Ernie, and then Elmo, and there was Grover, I think, or Grouch. And then obviously, you know, these are all really, really fun. Oh, I would love a Swedish chef model. So the Google brain team loved Sesame Street. The DeepMind team loves animals, so they do like Flamingo, Chinchilla, Gopher. there's the whole model zoo of really cute animals and I think people have to entertain themselves whenever they're staring at billions of numbers all day long. It's like the like the these things that go into the US Congress. They all have these super long names and then they end up becoming called something like the Reduce. Jedi. Yeah, yeah. That is definitely marketing. Okay, so and then OpenAI comes out with GPT. Another fun fact, the lead author of GPT is Alec Radford, three years out from his PhD. Not that much experience. Oh, wow. That's pretty cool. And so this is why I'm saying, like, if you're willing to do the work, you don't have to have a PhD. I mean, obviously it helps. But like, if you're willing to do the equivalent work and you have good ideas, I still think it's an early enough field that you can relatively get to the top of the field in a very short amount of time. Similar, so that's OpenAI and Alec Radford. Another similar person that I've been tracking is another countryman of mine, Yi Teh from Singapore. graduated from NTU, a local university in Singapore. Not a famous one. Three years later, he's publishing UL2, which is the top of the field model from Google. There's so much opportunity. And my point is, I think that this kind of opportunity exists when a field is extremely early. You do not see this in medicine physics astronomy math you know yeah like because all of those disciplines have had their sort of FUM periods FUM is that exponential takeoff period All those disciplines had those periods centuries ago, right? Like, only Albert Einstein was able to publish three papers in a row in 1905 that defines everything. But like, you could not do that today, because all the low hanging fruit has been picked up. And I think definitely we're in that period for something like this discipline. OK, so as you just jump back and forth into history and model stuff, GPC 1 and 2 came out within a relatively short order of time. By the way, GPT-2 is runnable as a Python package. You can import GPT-2 and just generate it. It's so ridiculously easy and funny. Yeah, the basic package that you should look at is GPT-2 Simple from Max Wolf, MiniMax here on Twitter. And then obviously GPT-3 comes out and actually makes zero impact. They actually, there was a little bit of kerfuffle around the safety of these models and OpenAI refused to release them publicly because it's too dangerous for your benefit. And ultimately they released it and everyone could easily tell between generated and non-generated stuff. So I think that's ultimately okay. And it took a few years. It actually, most people don't remember, but it was released in, I think, 2019, 2020, that timeframe, and didn't really take off until last year. Right, yeah. To me, looking in from the outside, it kind of feels like GPT 3.5 was like the inflection point. But then there's probably mid-journey and stuff earlier. Yeah, yeah. I would say that the infection point was really stable diffusion, which is counterintuitive because stable diffusion is a text-to-image model, and GBT is generated text. But I think stable diffusion got everyone inspired because it's open source running on your laptop and trained by a comparative outsider. Again, another outsider, Imad Bostak, a former finance person like myself, but took four years to go from finance to AI. It's not too long, right? I mean, he definitely got lucky and there's definitely stuff he doesn't know, but also he learned enough. So, yeah, I think people started hunting around because the stable diffusion went from zero to zero.

 you know, a billion dollars extremely quickly. Jasper AI, another top startup, went from zero to $80 million in revenue in 18 months, which is absurd. I heard that one yesterday. Yeah, there's a lot of money in this. Midjourney, which is a humble little Discord server of 5 million people, is a team of 12 making $50 million a year, right? Holy shit. Bootstrapped, no VC. because the founder founded a previous VC company and he was like, I'm not doing that again. So there's all these interesting characters and I think if you strike it rich, you're sitting pretty. It kind of feels like you would think that this all would trend to zero at some point, like the revenues, like they're going to become better and better and better. Yes. The B2C options have been very, very spiky Or, yeah, there is significant churn. So the best example of this is the Lenza AI team, which used to do the face lens. I think if you remember a few years ago, there was this trend of uploading your face and then seeing how it ages or de-ages or if you're the opposite gender, all that stuff. So Lenza actually pivoted to a face generation app using stable diffusion. and there's this amazing revenue chart of them going from like kind of nothing to earning two million dollars a day on the apple app store a day a day and then and then fading after two months back to nothing right because it was an extreme fat like everyone was like oh i'm just gonna you know spend a few dollars and see what my my face looks like in ai and that's for most people that is the way that they get involved in AI, right? They're like, I'll try out a new app. And so it's extremely fabby. I would say the really good builders keep building and find new features to offer their users so that they keep coming back. But otherwise, people will try things once and then they'll leave. And I think that is the natural way of these things. Because people just want to kick the tires. Another person to follow here is Levelsio, Peter Levels on Twitter. He had a similar... Yeah, he was the NomadList founder. He now... So he started NomadList, started a movement around remote work and a really dominant brand around all of that And I think he was making something on the order of one to one and a half million a year based on that By the way he works by himself with a few contractors He now makes more from his AI apps than all the Nomad stuff That's pretty scary. Good for him, though. But he's an extremely creative guy and a very good hacker. And he also has an audience as well, right? Yes. It's not like it helps, of course. Yes. Yeah. Yeah. Yeah. A lot of people are like, can you do it if you started over? And he's like, and all of us are just like, why would you? Like, I worked very hard for this. Also, he was mentioning that, you know, people were saying that the interior, interior AI thing he did, they were saying, yeah, you know, could you build it without this audience? And he basically countered it by saying, yes, you could, because he didn't advertise it by the time it got to X amount of traffic. You know, he basically told a few friends and they did word of mouth. So yeah, this is the answer to that. Yes, you could. Yeah, exactly. And this is only to prove to people who need some inspiration and motivation, but I or any other people with an audience don't owe anything to those people. I had to bootstrap myself the same way anyone else did. Of course. I'm somewhat defensive of this whole, oh, your success doesn't count because you already had an audience previously. I mean, that's not really what I meant. is what they have. I didn't get my audience. No, no, no, not at all. You guys are friends, obviously. I'm just hearing how it feels like, how it sounds like to us when people say, oh, you're already starting an audience. All your advice is completely irrelevant. No, I didn't get my audience of 2,500 spam bots and 500 real people on Twitter without any effort. It took a lot of work that people think I'm a footballer. You're talking too much about bike lanes in London. exactly exactly exactly that's that's that's the 500 real ones it's probably about half of those actually all right sorry so so okay so so okay so maybe i'll cover one more thing which is um people should you should be aware of the the main modalities that people are playing with so we covered generative image generative text generative images there is also audio which essentially is two directions, right? Like audio, audio to text and audio to text is probably the more promising one And that is um okay I whisper which is a fantastic state of the art model And we use that we use that for transcriptions for the podcast Yeah And I talk about a few issues there For text to audio the leading one right now is 11 Labs which does voice synthesis. I haven't personally tried that. And that's, I think, a lot of... I tried it. How do you like it? So I played a couple of clips for Brittany and Anthony, and it doesn't sound like me. like you can hear that there's some some inspiration of me in there but it what did you call it anthony it's it's it sounded like it has your tone but it's missing your accent so there's no authenticity in your voice like it doesn't sound exactly like but it does sound like a person yes yeah it does like a midwestern u.s person midwestern u.s whose balls haven't dropped basically yeah it honestly sounds like every podcast that i've listened to it recently They all have that voice, and I don't know why. Yes, yes. Oh, geez. Non-regional, non-specific. Very much so, I think. Sorry, continue. I was going to say, it makes me wonder if they do that, but if they do use AI tools, who knows? Sorry. Maybe. Yeah, well, I think it's just the state of the technology, and obviously it will improve. Google actually has a project where it does match the voice tone and accent much closer. But this is a very common phenomenon with Google. They'll announce that they have something and then not release it. So you can't even try it out yourself. You just have to take them at their word that the results or samples that they produce are representative of the models that they've trained. And so Google, you know, there's this whole issue between the big war and a proxy battle between Microsoft versus Google via OpenAI. I think very much Google is on the back foot. And they've essentially been the Xerox park of our era, where they funded a bunch of research. And then other people that they funded essentially have left and all started their own amazing companies. And Google is left with declining revenues in search and complete chaos of a house. I do think that Sundar Pichai, there's nothing he can do. He will be fired in a short amount of time. He has completely mismanaged the biggest revenue engine on earth. Yeah, they pretty much just coasted, kind of feels like. Yes, yes. This is a very common phenomenon, right? You know fat times make weak men and weak men make hard times hard times make strong men So there other modalities So we talked about images text and audio And then I think code is a very interesting subset of text. I can talk about code a bit, but I want to finish out the modalities. I definitely track all of them. For those who are interested, I actually have a public GitHub repo where I track all this stuff. So if you go to AI Notes on my GitHub, you'll see all of this. So there's other modalities, like text-to-video is something that a lot of people talk about. I'm completely uninterested in text-to-video because I think that it is so far away that it is just not useful. Then there is math, solving mathematical equations and a related problem with that is physics. Sam Altman's stated goal for what AGI is, is that it is able to independently discover new rules of math and physics. because then it has essentially gone from symbolic and probabilistic generation of text that is plausible sounding to actually true things. Right. Yeah, because you can actually prove stuff with math, right? Yeah. And then there's also a couple other fields of AI UX, which is the meetup that I started in San Francisco, and it's going to be starting in New York City pretty soon. And we can talk about how all UX developers have a lot of opportunity in AI. And actually, I think you have more job security than back-end developers. And then we can also talk about agents, which are sort of language models that are run in an infinite loop. And we can also talk about medicine, semantic search, robotics. It starts to get more and more and more speculative the further out you go. But the core modalities you should be on top of, which is images, text, audio. Be familiar with all the main tools and startups and companies in those fields. If you want to build with them, try to figure out the main tool chains and tools. I have a list that I can send along, but it's also always changing every single day. So it's really hard to record on a podcast. But okay, I'll come back to code. So yesterday, I released my interview with Replit, which released and trained their own code model. And it was my top performing post of all time. It was on Hacker News for an entire day. Like I woke up this morning, I was still there. That's pretty cool. Yeah, it was crazy. And it's very hard to get a podcast to rank on Hackadews, because people, they don't want to listen. They just want to read, and then they start mouthing off about some opinion they have or another. Just read a title and go comment.

 directly. Yeah. So there's an interesting correspondence between code and language because the way that you train them is very similar. And I think that's my internal discovery from doing this interview and doing this podcast with all the AI founders and builders in this space. So code, why is what? So there's an interesting phenomenon where the typical corpus of language models is that you take text from the web. So like Reddit posts website scraping, restaurant reviews and all that. So it's not intuitive that adding code to that mix would actually improve its ability to reason and to generate plausible sounding text. And I realized after talking to the Replic guy, I realized why this is. Code is just very highly structured natural language anyway. And like comments, the way that we write comments and then prepare them without code. Actually, it's very good training data for the model to learn what... After I saw that, I was like, oh, code is actually the way that we communicate extremely clearly because it communicates precisely what we want if we're not vague enough, we get punished for it. If we're too vague, we get punished for it. And I just think it's such a fundamental insight. So what Replit did was very interesting. They only trained their model on scraped code from GitHub and Stack Overflow and then from Replit's own data. And they were able to beat the other models on common sense reasoning tasks. These are, when I say common sense reasoning tasks, they're established benchmarks that explain what common sense would be for a human to interpret things, right? Like when we interact with things physically. So my example of this would be, for example, there'll be a multiple choice question and it'll be something like, the tree's shadow grew longer in the grass, right? And then the question would be, why did the tree, why did the shadow grow? And the answer would be the sun rose or the sun was setting. And nowhere in the prompts or the question mentioned the sun, but you had to infer, the model had to infer from the context of the shadow growing longer and the tree being vertically present that there was movement in the sun and to conclude that. And so that is the kind of common sense reasoning benchmark that this code model trained purely in code was able to do all that That very interesting because I sure not many people have written code that is even remotely, well, I guess maybe, like code for that thing. Included in code is also a lot of markdown, right? Yeah, that's true. Yeah, yes. Some documentation on code too. Yeah. So what is interesting, just to broaden out a little bit, because I think code models and copilot is super interesting, as well. But just to broaden out a little bit, what we're doing with pre-training is essentially building foundation models that other people can build off of. Meaning that what's beautiful about this new form of open source, which is not just open source code, but open source data and weights, is that teams of people at Facebook and Google and OpenAI are spending millions and millions of dollars. GPT-3 costs something like $50 to $100 million to train. And essentially, you can buy them for something like $2 per 1,000 tokens, or they open source it and it's free. And so then you can take it and fine tune it and do the last mile thing for your use case. But someone else has already done the hard work of trading the big core thing that costs millions of dollars. And I think there's an interesting correspondence between this and the way that we build frameworks. There's always a core team that takes on the hard job of maintaining and building the core thing. And then us as developers take that thing and then build the last mile for our applications. The actual applications. Yeah. Before we continue with the episode, here's a word from our sponsor, Vercel. Vercel is the platform for front-end developers, providing the speed and reliability innovators need to create at the moment of inspiration. Founded by the creators of Next.js, Vercel has zero configuration support for 35 plus front-end frameworks, including SvelteKit. We enable the world's largest brands like Under Armour, eBay, and Nintendo to iterate faster and create quality software. Try out Vercel today to experience the easiest way to use Svelte. So if we go from one of these models that is like, I guess, more general, and then say we wanted to build like a Svelte documentation bot, like how would we go about doing that with, for example, like GPT-4? Yeah, you don't need GPT-4 for that. You just need GPT-3 or 3.5. So the best way that we know how to do it right now is that you embed all your documents So there a process called embedding which is essentially translating all the text into code into numbers that represent both the tokens and the words that are being presented and the positions of those words so that you sort of store the meaning of your sentences. So you embed all those things. Embidding is extremely cheap. So everyone just embeds willy-nilly. Store them in a vector database, whether I've been working out of the, I'm currently in the offices of Chroma, which I'm an investor in. Or you can use Pinecone, which is a popular one that just raised a $700 million valuation, which people think is extremely overhyped, but whatever. Or you can store it inside of a regular database like Postgres, which also has extensions for vector storage. And essentially what you do with every query then is you type in a query for what you're looking for. You embed that query to translate into a series of numbers again. You punch that, you put the number into the vector database and look for the top five most similar strings of numbers that are also in that neighborhood. It's kind of like a zip code, right? Like you're translating a series of addresses into a zip code and you just look for the nearest neighbors of the query. Then you take those queries that you, the results, those top five results, put those as context into your prompt and then ask your question again. And that will generate the answer that you're looking for as the process. So that is the rough process of retrieval augmented generation. It looks like Anthony has to go. Yep. There are steps to that, and there's tools that you can use like Langchain, but you don't have to use them. I've just described everything that you need to know to do that. You can do that in raw JavaScript, raw Python, and it's completely fine. Yeah. So it doesn't sound too hard to do something like that. Yeah. Because I saw Astro had some kind of thing where they did it. Oh, it's called Houston AI? Yeah, I just met Ben Holmes, who actually did that project or was involved in the project somehow. That's the whiteboard guy, right? That's the whiteboard guy. Yes, he brought a mini whiteboard to San Francisco for the conference that we're at. It was just so cute. So he started posing with his whiteboard. Yeah, so there's tricks to that. I just described the basic tier. If you want to get really good, you should look into hypothetical document embeddings, hide for short. And what that does is it improves the embeddings and the quality of the answers And so there a lot of research out there that improves things but usually it just a bag of tricks that you just apply and just kind of learn these tricks over time That is not that interesting that is not that hard or interesting to be honest So now things have definitely moved on towards agents and like, you know, more interesting applications. I think sort of better document search or generated search, generated answers from your documents is kind of passe now. But still, I think it's a very good starting point for most people to actually start playing around with these applications. The one thing that you have to worry about is context length, right? So the default GPT-3 context is 4,000 tokens. A token is essentially a set sequence of words. So for example, in the word like Brittany, Brittany might be two tokens, Brit and Ni, right? But you just got to serialize them into specific numbers. So like maybe it's represented by five and 403, right? And those things always represent Brit and Ni. So, and by the way, there's a, you can actually see this for yourself. I think if you go to platform.openai.com, and then you look for tokenizer, you can actually just punch in words and see those numbers for yourself. And so there's a vocabulary of about 50,000 tokens. And there's also very fun tricks that have arisen based out of the corpus of data that this tokenizer was trained on, which is that if you punch in space, the leading space is very important, and solid gold magic carp, that is one token, not 10, not five or 10. Yeah, and that's just because that came up a lot in the training data because of Twitch Plays Pokemon. This is very, very, yeah, it's very super random. It's wild. There's a lot of very interesting niche discoveries that actually break the illusion that you're talking to a real AI. This is a simulation of the thing, not the thing. But we get better and better over time. Okay, what was I going to say? I think there's a lot of interesting discoveries that make sense. But I think it's just very fascinating on one hand. I think I'm more excited by tech than I have been in a while. And it just feels good to be... In the middle of it? Yeah, and all this is in public. Everyone's freely discussing it, trying to figure out what they can do with it. And they are doing useful things with it. I would say that there's actually real use cases. So speaking of use cases, as a Svelte developer or a web developer in general, back in front than anything really. What kind of tools are there out there right now that you can use? Are there any?

 Obviously, like ChatGPT, you can ask questions, but are there more fine-tuned ones for web development? For web development specifically, I mean, I think it's going to be Copilot or Replit or Codium, which is another copilot alternative that is free and faster and just has different training data. I think there's also this set of tools that essentially are code review bots or AI commit, like GitHub Git commit description writers. They're super interesting. There's a project called Wolverine that actually starts to write code and that is self-healing because of the Wolverine mutant capability. Oh, right. Yeah. But these are all relatively newer. We're not actually sure which one of them is actually going to do a great job. I think AI commits is a really fun one. Like basically, you want to basically hand over small problems that are a lot of boilerplates. And I think personally, I'm quite interested in test generation because people, as we well know, don't write enough tests. And, you know, so as long as we can generate a suite of tests, right? Because like, why is it that we write some code and then we write one test and then we're like, fine, we'll ship it. And then we discover a bug and then we're like, all right, fine, we'll fix the bug and then we're going to test with that bug and then we ship it. And so we accumulate tests linearly, but actually we should just add thousands and thousands of tests because if it costs nothing to generate the tests, then why don't we just fuzz everything, right? Like just have a bot run through all the possible scenarios, all the usual testing strategies that are just copied and pasted from a previous project. We all do this, right? Let's not kid ourselves, right? Like this is all not the most fun part of our jobs, but it actually does help. So yeah, let's employ AI to do that. And there's a company called Codium without the E. This is really stupid. I know. There's Codium with the E, and that's the co-pilot alternative. And it's Codium without the E. That is a test generation company that is based out of Israel that raised the $11 million seed round, which is an absurdly high amount. That's a lot. Yeah. Anyway, so there's all these companies. There's other people working on this problem, which I think is super interesting. But at some point, that will reverse. I actually do think that will reverse. At some point when we confident enough in code generation we will write the test and the AI will write the code because we only really care about the test passing as as people who make products So we, we actually need to make the, make the, you know, whenever I want to make a change to my code, instead of changing the code itself, I will just change the test and just let the AI figure it out. Yeah. That makes sense. And then the final tier is, yeah, the final tier is instead of writing the tests or the code, I'll just write the Jira ticket. Yeah. Yeah, which when that would be kind of a spec, right? But more in natural language, I guess. Okay, so basically, for now, generate tests, handle PRs, like review code, stuff like that. That's probably what it's good for right now. Yeah, I think everyone should also, so this is not widely available to everybody yet. But I think if you try to contact someone at OpenAI, they'll give you access or just wait a few months. you should also be on top of chat gpt plugins i think that is a big avenue of potential that is essentially the new app store if you if if you remember the iphone when the iphone came out and they started they launched the app store there was a big rush for for developers to try to take advantage of this platform chat gpt itself is is still insanely primitive as powerful and as as and it's world-changing as it has been it's still very primitive the way that it uses plugins still very primitive. But the way that you code plugins with a mix of English and code in an open API spec, I think is a new programming paradigm that I really struggled to get around in my first day of coding with it. And then you're like, oh, okay, this is how all plugin systems should be. So do you have an example here of what a plugin could do? Yeah, you can just look at the ChatGPT plugins blog posts and video, and they demonstrated. So, for example, if you enable the Wolfram plugin, it would give ChatTBC the ability to call out to Wolfram and do math or look up scientific data and not hallucinate them because it's just kind of reporting from an API. Or you can search hotels or flights and book them through chat and do all of them in the same session. And I think the most interesting effects will happen when plugins can talk to other plugins through a central chat interface, which is very interesting. Because I saw some videos on something called Auto-GPT. Yes. I don understand quite how it works because it kind of like GPT talking to itself is a little bit yeah uh it it doing it doing its own uh reasoning so auto gpt is a different class of application called agents that is not chat but it's it's uh it looks like chat i i can see yeah i can see why you're thinking about yeah because it also has the ability to do tools yeah go ahead yeah so sorry I was thinking like, so auto GPT, so an agent, I guess, could then talk to GPT, I guess, that would have some plugins enabled and do stuff there or something. Yes. I don't know. Yeah. Okay. Yeah. So yeah, exactly. So the components of an agent, I actually had a blog post about this that did pretty well. It's called the anatomy of autonomy, which I really liked. I was very proud of myself for coming out that name. By the way, I live streamed the entire writing of that blog post. So if you want to see me write for six hours, you can see my YouTube. Oh, yeah. I think I saw that on YouTube. Like, not the whole thing. I just saw you streaming. I know. Nobody sticks around for the whole thing. But sometimes people drop by and I'll chat with them for a bit. Also using StreamYard, by the way. So the anatomy of autonomy starts with the base layer being language models. Second layer being memory. Third layer being web browsing for memory that it doesn't have yet. And then fourth layer being tools, connecting it up to Twitter, to GitHub, to your file system, whatever. And obviously, the web browsing is already a kind of tool, except that web browsing is read only and then tools are read and write. And then finally, the fifth layer, which is the most important and unknown layer, is planning and prioritization, which is that, hey, I give you an objective, go figure out how to do it by yourself. And that is actually an area that we know GPT-4 and all its predecessors are still bad at because it doesn't plan. It just predicts the next token. And so that's fascinating because we have now found an area that we want to improve. And therefore, a lot of the research going forward is actually going to focus on planning and prioritization because we know that this is the next component in terms of building an autonomous agent. And I think that is useful to try out because even though we know it does badly today, if you try out Baby AGI or AutoGPT, you can see how it might work if it was a lot better. Yeah And that what a lot of people are giving credit for these days which is dreaming rather than being practical which means that we definitely in the mania phase of AI where completely trivial projects that were done in a day get hundreds of thousands of GitHub stars Yeah this AutoGPT so for those who don know if you go to AutoGPT repo they have more stars than PyTorch, which is the machine learning framework that it's based on. It will probably overtake React at some point pretty soon. And it's absurd. For the amount of value that it actually does, it is absurd. So people definitely want to dream, and they're very interested in the AI future. and more power to them. But for the rest of us, either you want to get on the hype train and sell dreams to people or you figure out practical usage in your day jobs and apply that. And I make no value judgments as to which of those activities is more valuable to spend time in because definitely the people who help people dream are getting a lot of VC funding right now. Right. I guess it's more of a couple of years down the road. kind of value rather than right now. Yeah. Cool. So that was a very good, nice primer on what the heck is happening in AI. I don't know if Brittany, you're muted. I don't know if you had. Yeah, I was going to ask if you had a take at all on Jeffrey Hinton's and leaving and saying about the dangers of AI and that kind of stuff. Who is Jeffrey Hinton? One of the co-founders of deep learning. Godfather of AI, they call him. Okay. I think, so the famous moment that everyone was kind of deep learning pilled, as opposed to traditional machine learning, where you have a lot of understanding of the variables. In deep learning, you have so many hidden layers. GPT-3 has 96 layers that you have no idea what they represent. They just kind of represent abstract concepts that are in the latent space, as they call it. So Jeff Hinton was Alex's advisor for AlexNet in 2012 when they solved ImageNet as a competition. And that started the tenure cycle that has now led to deep learning for everything. And by the way, so Jeff Hinton, Joshua Bengio, and Jan LeCun were the three Turing Award winners of 2018. They all got awards for deep learning. And so two out of the three of those Turing Award winners are now warning against the dangers of AI. And Yann LeCun is always the odd guy out because he likes to be extremely contrarian every single thing. So AI safety debates, first of all.

 I think developers don't have a monopoly on them. And I actually try to spend less time on that, because this is discussed a lot in the political domain by a non-technical podcast. And so I don't think it's super, like, we don't have particular insights on safety. Even though we work on technology, we don't have particular insights on the social societal impact of technology. So I think we should be circumspect there. I will say that, yes, I am worried. The evidence of history points towards every time a native population encounters a more advanced civilization, the native population gets wiped out. It's extremely brutal. And it's not even like, sometimes it's intentional from the invading population, but sometimes it's unintentional. We just show up and we're just like, oops, like, oops, we cut off all your food. Brought you disease. Brought you diseases. Yes, exactly. And what we are encountering, if you take this to this logical conclusion, is we are actually giving birth to a new life form, which is artificial intelligence. And you need to think about this in terms of the span of hundreds of years, not our lifespans. And so we have to be extremely careful because one instance of this intelligence knows a lot more than any of us will ever learn in our lifetimes, can think much faster than us, is capable of increasing more things over time. And if we aren't careful, like life is extremely fragile and there's a very small range of conditions under which we exist. If we break any one of those conditions by accident, we may not be able to reverse it. And with that, we're done. Ending on a happy, fun note. Super happy note. I mean, it's worth discussing and putting our awareness. So this is fundamentally, okay, I'll end it this way. Like this is like AI safety is fundamentally at odds with individual freedom, capitalism and democracy. Because there is no such thing as unilateral safety. We all have to agree because it takes one person to disagree, to pursue money, to disregard safety in pursuit of money for the prisoner's dilemma to break. And then everyone pursues money. And that's essentially what OpenAI has done. Anthropic has now also gone from non-profit to for-profit Illicit has also gone from non to for as well and it is pretty alarming because this train doesn stop until you nationalize Google and Microsoft And there no standards and there no groups that federate it right There's no standards and no groups. No, no, not right now. So at some point, there will be some kind of commission that regulates these things, but they may be too late. and the secret is out such that China will do it before the US. Yeah, I was going to say, if a country bans AI, or I don't know, that's probably... It just moves to a different place. Yeah, exactly. It's kind of like cryptocurrency in a sense. It just moves to where it's still legal and whoever can make money from it can make money from it. AI, crypto, handshake, and then tokens. like yeah honestly i mean i mean if if you think about it like cryptocurrency is the payment systems for ai right because no one can control it really yeah i i would i would think they would start making transactions at some point with each other to buy services but yeah i don't know i guess we'll Anyway, so yeah, we have got to the do we end democracy and capitalism part of the conversation, which I think is a good stuff. Cool. All right. So I guess we still have two sections that we always do. So first one, unpopular opinions. I don't have one again this week. And Anthony is not here, so he doesn't have one. What about you guys? Do you have one? I don't. Yeah. Yeah, I don't. I just dropped this whole, you know, the only way to end democracy and capitalism. And it's, yeah, that's my unpopular opinion. That was kind of a hot take for the episode. For those who want more of my writing on this, look up AIMOLOCH, M-O-L-O-C-H, which is, that is the description of the race that we're in. A system that we're in that nobody particularly designed, but we're all trapped in. And there's kind of no way out unless we all collectively decide to stop playing. Yep. That's hard. okay i guess i guess we get to pick something nice then for for our picks yes do you have any picks britney i almost wrote in there night agent we watched it a few weeks ago but um the last week i picked the diplomat and i didn want to pick another tv show but i don know oh i really want to see that I a huge fan of Keri Russell It was really good I picked that last week and like it was from the writers of Homeland and I really enjoyed the series. Night Agent was also of a similar kind of style, like government agent does stuff and it was cool. I liked that too. So what's your pick then? Or is that your pick? but you didn't want to pick that's my pick i didn't have another pick i just didn't want to pick another tv show and i didn't have another one so by the way like i think you know the parents in the audience would always appreciate like a parenting pick in case you had any yeah my calendar like putting everything on my calendar is the only other people can't pick your calendar well no but like putting everything on your calendar like just whatever calendar app you use or whatever thing use just anything like picking up kids like their their classes taking the garbage out like everything goes on everything literally everything so that i know like when i have to because i can't keep it in my brain yeah i need space for other stuff wouldn't you like an ai assistant that did that for you right yes i i need that yeah i saw i i think i think it was called lindy ai it's like yes uh flo curvella actually i need to interview him from your podcast he's a good friend So Lindy AI is like Actually, I'll pick that It's like a I haven't used it, I don't know if it's out But it looks cool There's a very good series of videos Very short videos where he introduces it I think it's very well produced I don't think I've seen those Unless it's those on the website I'll pick Lindy AI, it's like a personal AI assistant Did we talk about Opus Pro? No You picked that too? Yeah, that's true, I'll pick that I'll pick that. I'll pick both. Opus Pro is another, I think, AI that does, you link it YouTube videos and it automatically generates YouTube shorts for you out of that longer video. And I actually used it and I've posted two clips to the Svelte Society YouTube channel. I don't think anyone has noticed. So I assume it's doing a good job. I looked them over and it looked fine. So yeah, that's a good tip. Yeah, I'm actually quite impressed with the short stuff that you've been doing on YouTube. So, big kudos for that. I actually need to learn how to do this. I can show you. It actually very very very easy It doesn take a long time Any tool that you will shout out The one I been using is called Capwing I need to try that. If you are loading in ChatGPT by navigating to it on a tab in your browser, you are doing it wrong. You should have a menu bar app. My menu bar app is ChatGPT Mac. It's an open source app. I have it on my GitHub. And literally, I do command shift G, and it opens up in a very tiny window. I type in my question, and it generates there, and I dismiss it right away. And it just shows up. Zero latency. It just shows up. Oh, that's great. I need this. Yeah. What was it called? Sorry? ChatGPT Mac. I don't know. It's on my GitHub. I'll drop it in, too. Okay. The links. Awesome. But you can write your own. It's not very hard. Literally, this is an embedded browser window that is a Mac app, right? that it's a Tori app because electronics are extremely heavy. Which means you can also customize it with file if you want, but that's not strictly necessary. And then the other one I'll shout out just because we're doing two picks per person today. If you're feeling overwhelmed, you're not alone, right? I do think that there's too much, especially if this is not your day job, you just kind of want to dip your toe. So first of all, my newsletter is, I try to do that for people, But the one that I use is Andrew Yang's newsletter from The Batch. It's called The Batch. It's from deeplearning.ai, which is his company. All right. I think that's it for us. It was a very high signal podcast this week. I liked it a lot. I'm definitely going to explore AI a bit more after Svelte Summit. Well, Svelte Summit's already been when this goes out. Talking in future terms here. Yeah. Unless we release this now on YouTube. Up to you. Who knows? For the subscribers. For the subscribers. I recently paid for my first YouTube channel. Oh, interesting. All right. So, yeah. Thanks, everyone, for listening. Sean, I guess the latent dot space is the place they go for your podcast. and yeah i'll see you all next week bye bye see you next week hey it's cover if you like the show please drop a review on your favorite podcast player it would help out a lot thanks

 Thank you.