 Hi, in this episode we get to talk to Penguin about Gradio AI and what he does at work. But before that, here's a word from our sponsor. Enjoy. brands like Under Armour, eBay, and Nintendo to iterate faster and create quality software. Try out Vercel today to experience the easiest way to use Svelte. Hello. Welcome back to Svelte Radio. This time, we're very calm and happy. No, we're always happy at Svelte Radio. Welcome. We're back again, and we have a guest this time. Say hello. Hello. Hey. We're not going to introduce. Yeah, I might need some names there. Yeah, yeah. Oh, yeah, you're right. But he's so well known in the Svelte community. His name is like a penguin emoji. Yeah. Yeah. There's a penguin showing up everywhere. So, yeah. Yeah. So welcome to another episode. That was a very long, weird intro, but we're here. And we have all of the hosts this time around. Say hello, maybe. Hi. Hi. I don't know if we want to do like, you know, names and voices because this is like five people. But hi, I'm Sean. Hi, I'm Anthony. Hi, I'm Brittany. I'm Kevin. And then our guest, Mr. Penguin, or maybe not Mr. Well, what's the title there? Whatever. Overlord. Overlord Penguin. That's what you can roll? We just went for it. So, Penguin, you're the creator of MD Svex, right? That's true. It's the small little thing that we've all used a bit. And you've been around in the Svelte community for a good while. Maybe you can introduce yourself? Yeah I am a penguin on the internet I been involved in Svelte for I don even know how many years like four years or something five years I create for MD Svex. I work at Hugging Face on Gradio. And I'm here to talk about whatever anybody wants to talk about. Yeah, so we thought we would talk about Gradio and AI and I guess Hugging Face in general and why you use Svelte, what Gradio is and all that good fun stuff. Yeah, yeah, all this interesting stuff. but yeah so uh penguin you've uh you've uh done a bunch of talks uh that are pretty worthwhile to watch one about building your own REPL which is uh mind-blowing to me and uh recently at Svelte Summit you also did a talk on uh yeah what was it about it was it was a talk without slides on storytelling right yeah storytelling yeah yeah i thought it was a nice breath of relief from like the tech technical talks like just to have something that was more about just how to have a good talk and a good story yeah it was a it was a lie i think uh i was just after sean so it's kind of the strange meta talks section of uh of the conference but uh Yeah, I felt like doing something a little bit different. I think it can be difficult to do non-technical talks at a technical conference, depending like who you are. And I think that, you know, sometimes, you know, I thought it was an important talk, you know, the way we kind of tell stories and encouraging people to tell their stories. but it can be, you know, if a stranger to the community gets up and does a non-technical talk, everyone's like, why is this person not talking about Svelte? What has this got to do with tech and with Svelte at a Svelte conference? So it's kind of, there's an element of, I was in a position where I could do a talk like that, and I felt it was important, and I felt I should kind of use that platform, because you say I'm pretty well known in the Svelte community, So no one going to question whether or not I should be on stage speaking So it kind of gets that out of the way just because of Not that that correct of course That's a whole discussion in itself. The Boo Crew is not going to boo you off the stage. No. I was the Boo Crew apparently. Did you not feel that you might disappoint people by not following on from your previous Bristech type talk? that's heavily technical yeah so what one of the reasons I wanted to do it was because of the expectations that I knew there would be I knew like I've got a bit of a track record of doing pretty deep technical kind of you know dives into topics or kind of live coding things and and I love doing those those things but part of it was kind of it's our first in-person and conference it would be nice to do it's the kind of talk that does well when you've got an audience in front of you you've got kind of people that you can kind of talk to it kind of felt more intimate because of you know it's a nice nice nice size kind of group and stuff but yeah part of it was actually people are going to be expecting this so i'd like to kind of uh mess with those expectations i think that was part of the it helped with the impact to a degree but i was definitely nervous about the talk it's a risky talk I'd kind of joked to Rich um I met Rich in New York uh a couple months ago and I kind of joked to Rich that the most kind of radical thing you can do in a in a tech talk is be sincere and so I was kind of like and there was an element of I'm if I'm going to go on stage and ask people to kind of to tell their story and to kind of to be honest and to kind of take risks in that way then I have to do the same myself so it was there was kind of an element of kind of i don't know kind of following my own advice on you know if there's something you actually want to talk about you something that you feel is important then you should kind of talk about it using whatever platforms you have so it was quite a you know in some ways it's a kind of like it echoes some of my reasons for being involved in open source and involved in tech in the first place uh so as someone who does talks and as someone who watches a lot of talks. I just wanted to compliment you. That was one of the bravest and also it's very raw and definitely expectation breaking talks I've ever seen. So well done on that. I think everyone was somewhat dubious Everyone staring at the black screens expecting some slides to show up at any point And you just kept not delivering on that I thought at the end the name of the talk was I Told You My Dog Wouldn't Walk or something like that. And then I expected at the end there to be some big thing about the dog not walking. No. That was more of a red herring, the title. Clickbait. Just clickbait. It was clickbait. How to fill a room. I'm going to do a talk called How to Fill a Room, and it's all about the title of Penguin's Talks. I have a sense that you are one of the more, you're one of the people that think about code in a more holistic fashion. Like, even though you're very technical, you know, you're on the Svelte Core team, plus you maintain empty specs, and I don't know what else. You definitely view it as, like, code plus humans. I don't know if you have any thoughts on, like, how community and code intermix. you seem to care quite a bit yeah I do and I don't like I just view technology as a kind of a means to an end really like it's a great enabler I'm very conflicted for example and you know I often joke that the internet was a mistake half joke and it's you know it's true you know it's exacerbated a lot of the existing kind of injustices and prejudices. It's kind of amplifying some of those. But in other ways, it's kind of access to information. If you look at things like, I don't know, as a kind of very popular example, something like Khan Academy, making a high quality education available to a huge amount of people worldwide and has been kind of really successful in democratizing, in the true sense, not in the investor sense, education. and I think that like was when so when I first got involved in Svelte I was mostly focusing on community that's kind of how I got my start there was 30 people in the discord and people like Rich and Conjurty were really generous in terms of kind of helping me understand this is back kind of Svelte two time you know now we have what 45,000 members on discord and obviously no one person can manage that. But, you know, I found it very rewarding kind of helping people out and stuff. But I think what's more interesting is when, you know, maybe someone that you've helped, and then someone that that person has helped this kind of chain of helpers goes on to build something incredible.

 or something impactful. And I don't think tools can be successful without a strong community. I don't think without the people to build the things, to write the content, to present new kinds of, I don't know, whether it's tutorials or documentation, whether it's kind of novel uses of a technology. I think those things kind of prove out a technology, but they also kind of, I don't know, they communicate with us the possibilities of a specific tool or a set of tools and so on and so forth. And Svelte has very much been successful because of the community. The tech honestly hasn't changed that much. We've seen huge growth probably over the past 12, 18 months since Svelte 3 or a little bit after the launch of Svelte 3. And Svelte hasn't changed. There's more hype. There's more people building. There's more people doing interesting things. And it is because of that community. And one of the things that sets maybe the Svelte community apart is it's, you know, it's very friendly. It's very kind of very welcoming to people. But it's also the people are very engaged. I get this feedback a lot that people like the Svelte community, not because not just because it's welcoming. There are other welcoming kind of tech communities out there. There are other knowledgeable tech communities out there. But because people are still willing to kind of engage in conversation and try hard to keep it kind of civil and friendly and welcoming and help newcomers and experienced people alike. And that kind of that dynamic is, in my experience, relatively unique to keep that kind of almost small community feel as a community grows exponentially. Like it's grown enormously in the past couple of years where at first the growth was slow. but it is this idea of ecosystem, this idea of Svelte as an ecosystem instead of Svelte as a library. It's something that we're thinking about at work. How do you go from library and a couple of integrations to ecosystem? And when you start thinking in terms of ecosystem, that phrase specifically, when you think of ecology, it's about our relationship to various things. And the humans are at the center of that. It's like, what is our relationship? How do all of these things to relate together and getting the most out of your community and you know almost empowering your community to to do the work is you know to build the interesting things to find those new use cases to find those new applications is for me the difference between a success and a failure There are many open source libraries that have existed for eons and they got no usage Playing devil's advocate here, do you think that there is some element of the community being very friendly and welcoming and helpful because nobody's being forced to use Svelte for their job yet? There's no disgruntled React developer that's been forced to use Svelte, that's come turned up to the Discord with a chip on their shoulder and gone, you know what, I hate this framework, I hate these people, I don't want to use React, but my job demands it, therefore I'm just going to abuse you all until I get what I want. Is there a notion of maybe we're still a bit lucky in that respect? Absolutely. You know, you have the, when you're not forced to use something for work, when it's all personal project, you have the, you know, the liberty of choice. If you're working with a tool, you know, you don't have that choice. And as soon as you take choice away from someone, you know, they feel trapped. And I think we'll see that in satisfaction surveys, you know, being pragmatic. It's like, you know, we celebrate these kind of satisfaction surveys and stuff. But at the end of the day, it's because people are going to be happy with the tool that they've chosen to use for a pet project that may only have existed for three months. When people are forced to adopt a legacy Svelte, you know, pick up a legacy Svelte code base and figure out what on earth the previous developers were thinking for three, four, five years, they're going to be a lot less happy about some of the design decisions. And, you know, you're likely to see questions around, you know, why is this a thinking Svelte? You know, who thought two-way bindings were a good idea? You know, those kinds of questions when it gets abused. In the same way that when React patterns get abused, people question the actual design of the feature itself rather than the usage. And that's totally valid. And we'll see that in the next few years, if we're successful. That was Sean's talk from Svelte Summit. He talked about that, right? That was a lot of things. I'm going to insert a call to action here. It just so happens that the State of JS 2022 survey just started. So if you want to voice your dissatisfaction with Svelte, go ahead. Also, mention Svelte Radio as the podcast that you're listening to. And mention Svelte Radio, please. Write it in, because they're not going to write us in until we force ourselves onto the regular list. Exactly. That's right. I call this a second framework syndrome It a good thing in a way that everyone comes here by choice It one of the things that I shouted out when I wrote about why I enjoy Svelte So yeah I strongly agree And it's pretty interesting that, you know, I think I call back to Sophie Alpert, the former manager of the React core team. You know, she was doing a keynote for React Conf, and she talks a little bit about like, you know, React is the first framework that a lot of people know, sometimes even before JavaScript. and that imposes a huge level of responsibility on React to be accessible to beginners that most libraries do not. And it's not necessarily a good thing, actually. It's just different. It's just qualitatively different. It means that everyone who chooses Svelte chooses it as a second framework and then the community that we get is more enjoyable for some people as a result. I do think we should celebrate it whilst we can, but we have something to celebrate. We are in that position. So I think we should celebrate it. I definitely don't think that we should go, oh, we know this, that and the other. I think there's a lot of new frameworks and Svelte is still doing really well comparatively to them. And I appreciate Pete's perspective and how you connect everything back to kind of the underlying ideology of how the community makes the framework a little bit. And I love that. I often kind of joke that Svelte isn't a technology, it's a philosophy. And you see this quite a lot in terms of, it's frustrating sometimes when people say, where's this library, where's this integration? But there's this kind of minimalist kind of approach, this use the bare minimum. If the library is doing too much, then maybe write something simple for yourself. And there's a whole, there is an element of that side of things as well. that it and i think what's interesting actually uh sean talking about the the kind of attracting beginners is we attract a different kind of beginner because one of the way that svelte is framed is um it's very similar to job to just html so people often come later because it's an easy to use framework you know air quotes we we do attract people with maybe limited experience and then when they actually want to start doing more complex stuff they don't necessarily have the the kind of like that heavy JavaScript backgrounds to kind of apply to their Svelte. And so we kind of have like a different kind of beginner problem I guess but it because of the nature of the framework And I guess this is how you know there a whole thing around the design of your framework the philosophy behind your framework will dictate what kinds of users you attract and what kinds of challenges they have when they want to go from beginner to intermediate to advanced. But that kind of minimal approach maybe doesn't work well for those users. They're not as comfortable kind of like writing their own kind of simple libraries as maybe a more experienced developer. Maybe not for this podcast, but I would love to get your thoughts on how to do that transition from beginner to intermediate to advanced and get a course layout. I would love to do a course like that. Yeah. So, I mean, nowadays, Svelte is more popular than React, as we've seen on NPM Trends, right? You just ruined my unpopular opinion. Oh, sorry. I was saving that. Thank you. Celebrate it. Celebrate it whilst you can. Celebrate it. Yes. So for those of you. Yeah. Okay. I was just going to say like there's someone somewhere is using some build tool or I don't know, some automation that it's just like downloading Svelte like crazy. So I asked Laurie Voss about it. He's the co-founder of NPM. and he said that Theo was right in that tweet that the CI is like messed up. So something somewhere is just. Like the Svelte CI? I think Theo said that the NPM or somebody's CI. Oh, he said some Svelte dev CI. So like you said, like somebody's CI is messed up downloading stuff. Yeah. I mean, Svelte's a compiler, right? It should see fewer downloads. Gatsby and Next had similar bumps recently too. So they had like a huge spike and then it went back down. It's weird. It's a conspiracy. Maybe it's one of these unpackaged type tool, whatever. Yeah. I wanted to mention, like we talked a bit about, like we had a different kind of beginner and I just wanted to shout out the kit documentation that has a section on web standards, which is very nice to see. It's basically about how to use fetch form data, stream APIs, and stuff like that. Which I think a lot of people, they don't know how to do it.

 how to actually use web standards. They know some stuff. But yeah, just a shout out. I think we could actually expand on that even more. Using the platform? Yes, yes. I think one of the earliest, I think the first Svelte Summit or maybe Svelte Society Day, we had people from a few governments, right? like I think Norway and Mexico that they were putting it in curriculums. So yeah, I definitely don't want to give the impression that this file is not suitable for beginners. Actually, it's easier to learn just because it's closer to HTML. But yeah, that's beside the point. You don't have to learn functional programming or some fork of JavaScript to do that. So anyway, I feel like I've gone on this rant. Did we want to spend any time talking about MD specs before we move on to the radio? Yeah. I'm thinking maybe we do another podcast episode on just MD Specs. Okay. Add into Gradio and Hugging Face maybe. Yes. What is Hugging Face? Sounds all right. Sure. What is Hugging Face? Hugging Face is a company that is building a, basically we build libraries, platforms, and services to make AI as accessible as possible. The context around this is, you know, and sometimes when people who aren't familiar with the AI ecosystems hear this, they're like, you know, what's the big deal? But like, it's genuinely the Wild West out there. You know, there's a lot of code that gets, I mean, a lot of code isn't released for some kind of research. A lot of code is, you know, very difficult to make use of to get to work yourself. So having a kind of a consistent set of libraries and platform where we can, you know, it's easy to use state-of-the-art machine learning models is a bit of a game changer. So the core, I guess, the heart of Hugging Face is the Transformers library. That's kind of what everything is built on top of. And it's a, you know, a consistent Transformers is an architecture in machine learning, but it's also a library that you can use. And we make available lots and lots of state-of-the-art models that you can use relatively easily. And we've got a bunch of, you know, We got a whole you know we building an ecosystem so it not everything kind of works together We got a GitHub we got a hub where you can host your models and your data sets and even your little kind of Python apps That our spaces which we come to shortly But also, you know, we've got a series of libraries. We've even got APIs where you can easily, you know, models that are hosted on the hub can easily be deployed to an API and you can then just like make predictions using an API instead of needing to kind of write your own code. So it started off as just focused on NLP, but now it's just pretty much anything goes. NLP being natural language processing programming? Yes, not neuro-linguistic programming. I was going to say. I have my friends also into that. Yeah. Mostly consistent of looking at yourself in the mirror and telling yourself that you have confidence today. You love me. I'm very sad. Yeah. No, but actually one of my smartest friends does that and it works. So I'm actually very hesitant to be skeptical about it. That's kind of what we were saying before we started recording. We're going to have smiles on our faces and be happy. We just made ourselves happy. Yeah, and I think it worked. You have to manifest. One analogy that I've heard is hugging faces GitHub for machine learning. didn't make sense to me two years ago, makes a little bit more sense to me today. It seems like that is the way that, for example, stable diffusion distributes model weights. And basically, is it just GitHub on steroids? What does Hugging Face do differently that GitHub doesn't do? I mean, so I guess the biggest thing is kind of Git LFS is free. So when you're dealing with, which it isn't on GitHub for reference. so when you're dealing with like you know models are huge checkpoints are huge you know these things are very large so you need you need some large file storage and that could get very expensive on github whereas that's that's free on hugging face so it is a git host and that's our kind of in terms of the public facing kind of part of hugging face from a product point of view it looks like it's just like a git host and it's definitely very good for hosting your your models and your data sets but there's a bunch of kind of i think one thing that Hooking Face does differently is, for example, you can buy compute. You can buy compute from GitHub GitHub isn a way to host your code It very general purpose so obviously it can be but because we focused on machine learning it like if you need compute for example on whether that's we've got inference APIs, so more kind of production-focused, you could upload a model to an inference API and use one of our APIs to run your productions. But we've also got this idea of spaces, which is a way you could think of it like GitHub pages or something like that, except it's, you know, it's an actual like Python app with a server running behind it. And you can, if you need a larger GPU, then you can buy a larger GPU. If you need an A100 for your predictions, then you can buy that directly from, you know, you can just upgrade your space in the GUI. And then you can, potentially you could use that as an API if you wanted to, but, you know, we would encourage for production use cases going to one of our dedicated production services. It's going to be more performance. But I think that's the, you know, we have a set of, because we're focused on a, it's a pretty broad vertical, but it's a vertical machine learning that, yes, it's good for hosting, but yes, it's also good for production APIs. It's also good for prototyping apps with spaces. We've also got the libraries that kind of the power all that, but you can also use as well. So it's more of a, I would say it's more of a kind of a rounded kind of solution to the, to a kind of a kind of vertical. It's just a very, very wide one. Yeah, yeah, very cool. Yeah, I got nothing. That explains it so much better to me. I was so confused about what it does, but like having like the GitHub face for like the models and then you have the spaces to actually host the thing that you need, right? You have physical servers, are those like located, are they more like a CDN or are they located in specific areas? They are in specific areas. I think everything's just AWS. Are they built on AWS? Okay. Yeah, as far as well, yeah. I mean, the spaces things are kind of, like I say, you're more likely to hit the limits of what those resources give you, but we've got more production-focused products as well. Gotcha. I wanted to give a little bit of context. Oh, okay. Do you need me to stop now? Go on, go on. I'll do it after. Okay. I wanted to give a little bit of context so A100s are the it looks like they the chip of choice for machine learning people are measuring their AI capacity by the amount of A100s they stockpiling Like literally there a chart out there going like number A100s per company and the people that have more win. And that's it. It's kind of like a nuclear arms race to me, which is pretty cool. But like one of the most magical experiences for me, like when I started looking at Hugging Face differently compared to GitHub was you host Gradio UIs on Hugging Face, on Spaces, and people can just run the models for free, which is not my normal experience for machine learning. You normally have to download it somewhere and run it yourself. Doing this for free must cost a lot. Yeah, it's not cheap. But in terms of making AI as accessible as possible, for example, making papers reproducible, which at the minute is like really, you know, just got some code. It's like, yeah, exactly. So, you know, encouraging people to build, you know, a Gradio demo for the paper, which, you know, we've had a lot of success with is, you know, game changing. So like for us, it's the important thing is to build this ecosystem is to make sure people are using spaces. And you're right. You know, it's obviously it's a whole machine. It's a dedicated machine for these kind of these spaces apps. They don't necessarily have GPUs, so the GPUs are upgrades that you can pay for. We also have community grants that people can apply for. So if they've got an interesting kind of space that we think the world should be using, they can apply for a CPU grant and we can award those temporarily as well. So it's certainly a cost, but it's a measured one in terms of making machine learning as accessible as possible, whether that's making it easier for researchers and ML engineers or whether that's kind of opening the door to software engineers, which is obviously the biggest part of kind of tech, is software engineers who, you know, maybe have some familiarity with machine learning. They know what it is. Maybe they don't know how they would integrate it into their, you know, their workflows and how they would use it. But these kind of Gradio demos, for example, is a good way to, you know, build a proof of concept to, you know, to show to stakeholders to get some buy-in so that they can maybe actually invest some serious funds into that. Is A100 the Bitcoin miner of AI, or is it the graphics card of AI? Are people going to be, you know, big-saving?

 building all this hardware and then it goes obsolete and you have to get the latest hardware because you want to do some specific task. It's probably the kind of reference GPU of choice at the minute. There are cheaper ones. There are, I think, more expensive ones. You know, there's innovations in hardware all the time, especially for machine learning, and it will, obviously. There will be a newer, shinier version in 12 months. Before we continue the conversation, And here's a word from our sponsor again. Vercel is the platform for front-end developers, providing the speed and reliability innovators need to create at the moment of inspiration. Founded by the creators of Next.js, Vercel has zero configuration support for 35 plus front-end frameworks, including SvelteKit. We enable the world's largest brands like Under Armour, eBay, and Nintendo to iterate faster and create quality software. Try out Vercel today to experience the easiest way to use Svelte. So we talked about Hugging Face and A100s and all that cool stuff, but where does this all tie into Svelte? What does this have to do with Svelte? Nothing at all, in honesty. So end of conversation? No. Svelte is used across all of Hugging Face. So pretty much a lot of what is kind of public-facing, almost everything, is kind of written in Svelte. So the hub is all Svelte. It's a relatively custom setup. We've got a couple of SvelteKit apps. So we've got our Inference Endpoints kind of landing page is a SvelteKit app. We've got a Hugging Face store. Go buy our merch. That's a SvelteKit app. Gradio that I work on, which is a library, which I guess I'll explain that in more detail in a moment, is also all of the front end is written in Svelte. So pretty much everything uses Svelte, but obviously, you know, machine learning itself requires no UI. There is no necessarily no Svelte involvement. There does seem to be a trend of, it seems to be a trend I've noticed over the past 12 to 18 months that Web3 and AI companies use Svelte I don know why that is I don like They just like new things so they just using the shiniest thing It an interesting one because when I first started off in Web3 no one was using anything The only thing that was available was the Ethereum SDK, and it was written in this dodgy JavaScript that was shipped through Browserify, and it barely worked at all. It was terrible. But I started building things called truffle boxes in Svelte, and so there was a few ways to build a blockchain app, and one of them was using Svelte, and it was one of probably five ways to do it at the time. But then suddenly when I sort of exited Web3 in 2017 or so, React took over and React became the de facto way to build, well, you know, anything but also Web3 apps. So it's interesting now that the tide's turned again and Svelte's become a good way to build them. And I think it's probably the kind of company, it's modern, it's faster in my mind than React. And I think it's also just kind of, you know, it feels like it's, I don't know, a modern company I think will look at Svelte as a good option for getting a front end up and running I mean it's easy in the AI kind of like sector I know that Coher are using Svelte Coher are another kind of AI startup more kind of following the kind of open AI model I think where they're kind of closed source models with APIs to use them but they're using Svelte and they donated like $10,000 to the open collective about six months ago so thanks um but i know it was as well i use themselves so there was a protocol i was quite involved with um back in the day called melon protocol and it was uh by two two people and one interesting the reason stuck my mind is because the lady was called mona elisa one of the ones who owned it and i thought that's the best name i've ever heard in my entire life um and so but but the guy and unfortunately i've forgotten his name sorry but um he he sort of when i was uh early days as a maintainer on Svelte, he appeared in the Discord and he was rebuilding Melon Protocol's website in Svelte and I was like, well, that's interesting. That's sort of unexpected. Also, you know, the guy designed the protocol also writing the front end, but there you go. Just a tidbit, that one. I want to offer some thoughts on this, like why people are using, or just investing in UI. Essentially, you know, both machine learning and Web3, there's a bunch of opaque APIs that are not super usable to the general population. Like everyone's interested in mass consumer usage of that And for that you need user interfaces I very much think there a movement in machine learning of there a lot of research being done on foundational models but it's not super accessible. Stable diffusion itself is not super accessible. You kind of have to build the UI around it. And that's kind of what people are investing in there. I think that's the opportunity for front-end developers to get involved with the AI as well, to essentially reinterpret it for regular people to actually make use of this stuff. And I'll point out two more things, which is a lot of these are Python ecosystem things. So Gradio itself was an acquisition. It was a startup independently and then was acquired into Hugging Face. And Streamlit is another one that was acquired by Snowflake for $800 million. And these are basically Python to UI interfaces where people just write Python and a UI is generated. and that's kind of the context, which is I know Python, I have my machine learning thing or my data thing or whatever my thing is, and I want to make a user interface without being a UI expert. And essentially what Gradio is, from my point of view, is it's a bunch of svelte experts creating components that are accessible in Python. Correct me if I'm wrong. Yeah, that's pretty much it. Python people want to write Python. So, you know, the whole JavaScript ecosystem is totally inaccessible to those people. So Streamlit and Gradio are two different approaches. There are differences. There are things they're good at, things that they're not as good at. Do you have a opinion? I would love to know what's the similarities and differences. They're getting more and more similar. I'll say that much. I mean, the big difference is that Streamlit has its own custom interpreter, which kind of allows for this very, very kind of clean, line by line kind of, you know, you can build up a UI kind of line by line. It's very kind of intuitive. But the way they do that is with a custom interpreter. We have a, and Gradio, we have a goal that we need to run in like Google Colab. We want to be able to run anywhere without, you know, basically being more portable. So we want to kind of stay as a, you know, this is kind of, very kind of interestingly, the kind of React Svelte kind of, One of the old arguments was this kind of compiler is this really heavy abstraction It basically Svelte isn a library it a language which of you know arguably true And it kind of a similar sort of thing where Streamlit to a degree is its own language. It has its own semantics outside of Python, whereas Gradio is just a plain kind of Python script that you can run in any context. But obviously, the mechanics of the way they work, this will probably change over time. Like over the past kind of nine months, Gradio has become more similar to Streamlit. Gradio used to be just this simple, you know, here are your input components that are going to pass some data to a predict function. And here are the output components that, you know, the output of that predict function, you know, function is going to take those outputs and display them. Whereas now you can build more complex UIs as we've added more APIs. So kind of becoming more similar to Streamlit. But the way in which they run is at the minute, like Streamlit kind of runs top to bottom. So it kind of reruns when you change things pretty much completely. You can cache some things and it knows when things haven't changed. So it can kind of optimize. But fundamentally, that's kind of how it works. It kind of runs top to bottom with some kind of caching, memoization sort of tricks. I think that will, you know, they've published a roadmap recently that's really interesting and that will change. Gradio is a bit more kind of selective, and you can say, I only want these kind of things to update when this predict function runs. But you've got to kind of manually define those dependencies. That's something we are also hoping to improve in a future version as well. So they are kind of getting more and more similar. But that whole custom interpreter, just pure Python, remains true and probably will remain true for both of those tools. it's interesting uh that the rendering philosophy matches uh react versus as well you know rendering top to bottom versus partial updates um so what what are some some cool uh like i guess gradio apps is how what would you call them yeah apps i think the most popular ones So what is now Crayon was Dali Mini, and that was kind of probably the most popular, even to this day, even with stable diffusion kind of taking over the world. Dali Mini was on a different level. We were getting like 50 million generations a day. The kind of the mass usage of Dali Mini was was absurd, you know, probably.

 machine learning genuinely at scale, in ways that only certain organizations have had to do before. So that was definitely huge. Crayon is its own product now, and that's no longer using Gradio and Spaces. But that was the big one. That was very, very popular, and that was everywhere on Twitter. And that had the unique element of people who knew nothing about machine learning, people who knew nothing about tech, were having fun and playing with machine learning en masse for maybe the first time in a long time. So that was huge. I guess we could kind of explain what the Dolly Mini actually is. It's like an image generation tool, right? Yes. These are all text. These have become very, very popular. I think partly because they work very well on Twitter. They're text-to-image generation models. So you give it a description, and the AI will generate an image based on that. It will often generate a selection of images based on that. And there's a really great Twitter account, like WeirdDaliMini, which kind of posts really strange generations. And DaliMini kind of lended itself well to this because it was quite stylized. It had a very specific look to it. So it often came out with some very bizarre images. Stable Diffusion does as well, but Stable Diffusion is incredibly realistic. So in some ways, it has less novelty effect than Dali Mini. Yeah, you want different art styles. One thing, yeah, so I linked, I do, I have actually been following Weird Dali Generations, the Twitter account, because it's so, it's funny. There's often a little bit of a social message involved. and I just saw that they reached a million followers, which is absurd to me. Wow. Yeah, so one thing I wanted to be very clear about, was Crayon or Dolly Mini created by Hugging Face or like a third party and you were just the host of it? Yeah, third party. We collaborated with Boris Daima and the folks that were building it. And it was open source. You know there was a lot of kind of I don know it feels like sometimes this stuff is made open source almost as a response to OpenAI very aggressively closed source nature which has kind of changed recently Closed AI Yeah yeah It a ironic thing But you yeah So it was this kind of open source model and we collaborated with the folks that built that model. It's not an internal Hugging Face tool in the same way that Stable Diffusion. Again, the initial demos that were hosted and the models were hosted on Hugging Face, but that's just a collaboration with another organization as well. And then kind of Boris and the team wanted to take, you know, to try and build a product around Darley Mini, so they kind of created Crayon, which is what is now Darley Mini. And, you know, that became self-hosted, and they did their own UI, and they did their own thing. And for those listening, Crayon is, well, the regular word Crayon with AI in it. So C-R-A-I-Y-O-N. Yeah, Crayon. Crayon. I just like, 50 million generations, that's a lot of money. and I'm just trying to really go, all right, who paid for that? I know there's a queue. Yeah, so I don't know the details on this. We definitely... I'm just asking this just because that's a really good way to host things and I'm like, what's the limit on this? Yeah, so Darley Mini was a pretty custom setup. So typically when you create a Gradio app, It spawns a fast API for you, and it gets built into this Docker container and so on and so forth. But you can also, if you want to, you can call external APIs and stuff if you're hosting elsewhere. And that was the situation with Dali Mini. It had its own custom backend, and there was, I think, various... I don't know if we sponsored that or only we sponsored that or if other people were also sponsoring that as well. but there was definitely a bunch of, the backend was like a totally custom backend and the Gradio app was actually a static app essentially hosted on spaces that called out to this API that had its own queue and it did like a bunch of batching and stuff on its own. So we didn't actually enable our queue because then it would have meant that they couldn't use their queue. So they had their own queue. It was its own kind of custom set of infrastructure that we provided. We definitely provided a lot of support around that. But in terms of who actually fought the bill, I'm not 100%. Yeah, I don't mean to pry. I'm just like, this might be one of, I would love to make something like that And I just I have no idea how much effort or money it takes to run something like that It pretty crazy It so fun It really is so fun Any other kind of applications that you want to shout out that are fun to play around with? How do you get started with Gradio? Right. Yeah, I think the... I mean, you can go and browse our spaces. So if you go to huggingface.co slash spaces, you can actually go and browse spaces. We have lists of trending spaces. So if you wanted to explore the different kinds of things that people are doing, then you can take a look at that. I think the most popular one at the minute is obviously stable diffusion web UI. So this is a pretty complex web UI around stable diffusion, which is, again, another text to image generation model. very, very kind of like high quality image generations. And the web UI allows you to kind of tweak the parameters. It's a pretty complex model. You can make lots of kind of like tweaks and things. And that has become very, very kind of popular. You could, you know, you can create a Google Colab and kind of fork and take a look at that. You can run it locally. And what's interesting about stable diffusion now is, of course, people have started to fine tune, you know, with Dreambooth. So they've started to kind of make their own kind of, you know, you can fine tune on a relatively small set of data to create like different kind of styles and stuff. And they've become, you know, I guess they've kind of kind of viral in a much smaller kind of sense. They're a bit more specialist. It's a little bit more technical to do that. But that's been an interesting kind of offshoot. And, you know, interesting, Sean, you were talking earlier about community and ecosystem. Again, like entire mini communities are built up around these things and they're setting up their own kind of sites to share all of the different models that they've generated so people can play around with them. You know, everyone's frightened. Is Disney going to sue me because I've trained my model on a lot of Disney images and stuff? All those kind of questions start opening up. But yeah, Stable Diffusion has kind of, it became popular, but what's been impressive is how people have kind of continued to play with it, continued to kind of find new and interesting use cases. And even today, it's still pretty constant. It's still pretty popular with people using it. And that definitely worth checking out if you like image generation models anyway Yeah so the perspective I would give there is you said it was less popular but I'm not sure about that because the dream booth fine-tuning is where I saw it cross over on YouTube because people, and the way that I'll frame this is people are most interested in themselves. And so there's a qualitative difference between you being able to type any text and it generates any image and you being able to type any text and it puts you in that image. Puts your friend, puts your loved one, puts your pet, whatever it is, right? Like people are very interested in themselves. And I think the video that went viral was from Corridor Digital where they like told a story with their coworkers and inserted themselves in that story. And it just became that much more interesting just because, hey, that's a face I work with every single day. And some of the more interesting productized businesses would be Avatar AI, which is the same thing. And so what I would qualify there is there's these foundational models like stable diffusion. Fine-tuning is kind of that last mile thing that people add on on top of that that requires a lot of UI work and, yes, additional machine learning training. But that actually makes it more useful to the end user who is ultimately interested in their use case and their own specific constraints and needs. Well, I mean, if we're ending off on the radio thing, I wanted to ask, I think just the general sense of UI generators, or not many people work on this, essentially what you're working on, which is you're interpreting some intention of a developer and then creating in a sort of a low-code fashion UI. And I think that's a very interesting and rare use case of front-end frameworks that you probably stretched Svelte in some interesting ways. And I thought that there might be an opportunity to comment on some lesser-known APIs that provide you a lot of value that people may not know about. Yeah, I think sort of at a very high level, you can kind of see something like Gradio as it's a framework fundamentally. And we often talk about this, that when we're looking for new people, we're more interested in people that got experience building frameworks than experience in machine learning because Gradio is very much positioned as a make web UIs for your machine learning kind of models, but you can build anything. You can build normal web apps with it. And...

 The big difference is instead of like the DOM being our primitive, like it is in Svelte or React, like we have these kind of components that are our primitives. So you can't render, you know, this H1 or that, you know, paragraph tag. You can render our image component, which itself is a very, very complex thing. So most of our work, especially in the front end, is, you know, we spend a lot of time with relatively low level APIs, maybe with canvas APIs, with audio APIs, with video APIs, with, you know, So who knows in the future with WebGL is something that we'll be utilizing in the future as well. So a lot of our work is spent just doing kind of web API stuff. In terms of the Svelte, it can get a bit tricky sometimes to process all of this, to take this essentially the way it works in Gradio is we have a configuration that gets generated by the Python backend and gets passed down to the front end. And that, you know, you want to see it as like almost a virtual DOM representation or a virtual component representation. than you can. It's a tree of components that Svelte will then render. And I mean, you know, dynamic components, Svelte colon components is your friend in this case. So it's rendering all these components. But I think the difficult thing is having an architecture that supports kind of managing all of that state. So there's all of this states that you have for your components, and that might be props that are being set at the very kind of like high level that you need to passed down but then those props can potentially change throughout the life cycle of the application and you need to ensure that your kind of config reflects that you need to be able to you know if you were to show and hide something can you rehydrate with the same state but you also kind of start to face challenges where because we're kind of because the the kind of the code you know all of our kind of event handlers what would be an event handler in svelte like that's written in python and that that involves a kind of like a server round trip to a degree so we have for example events on we have certain like change events on on certain components so if the value changes that event is triggered and we have a handler for that and that's a function written in python so you can almost see this it's a little bit like it doesn't work in the same way at least not at the minute as elixir live view but it's that same kind of you know cycle we do use we do use WebSockets and stuff for various reasons. And maybe we'll go more granular with updates in the way that kind of LiveView does in the future But it kind of that process where this manage some state or something up here do some make some changes You want to pass that down to a component and that you know request response cycle So you do have a problem though when say you got some internal state for a component, if you're going to dismount and remount that component, you're going to lose the internal representation of state, which you might need to say, if you're working with canvas, you might want to send just images up to your API to do something with, to, you know, run a prediction on. But internally you might have like a bunch of paths. You might have some, you know, mathematical representations of like vectors that you're drawing onto a canvas and stuff, and you could potentially lose all of that internal state. So having a way to serialize both the state that your API cares about and the state that your front end cares about is, you know, really important. And we've had issues in the past where maybe we were, you know, our kind of like state mechanisms were a little bit too naive. And in some ways they still are, and they need to be kind of improved as you want to do more with the framework. And maybe it's performance optimization, so you're only kind of sending partial updates and stuff. Maybe it is the idea of mounting and dismounting, but it means you need to think kind of carefully about how you're kind of front-end and your back-end are talking to one another because we have this hard requirement that users write Python. and you know there are escape hatches for javascript but that means anything that you potentially want to do hiding and showing a button you should be able to do that in python so that's you know it poses interesting challenges when you need to work kind of try and work across languages and it also you know introduces ux challenges like if we want people to be able to show and hide a button in python and that involves a server round trip is that going to deliver the performance that we need? Are there some new APIs we can add to support this use case, some shorthands that can, you know, make the UX, you know, faster. So it's, it definalizes a number of challenges that you just don't, you know, you don't have to face in, and a lot of hard constraints that you simply don't have to face in, you know, building a typical product, for example. Yeah. Cool. That's a great explanation. Thank you. All right. So yeah, and you're still hiring, right? Yeah, we are hiring. So we are looking for a front-end engineer. So it's advertised on our Hugging Face website as a front-end engineer. It only remote Our whole company is remote And you know we looking for someone You know a Svelte person would be good but really someone who really has some experience with those core web APIs I was talking about, someone who's comfortable on MDN and implementing things at a relatively low level is ideally what we're looking for. Yeah, that makes sense. All right. So I think that's it for all of the topics, unless you have something else that you want to add. Well, I was going to mention SvelteKit. You have some SvelteKit apps. For those listening and who are not on Twitter, there are eight issues left, apparently, on SvelteKit 1.0's roadmap, which means maybe soon. We don't know. But I just wanted to leave some opportunity for people to comment on the maturity of SvelteKit and how people are excited about it. Yeah, I'm sure we'll be getting this Vulgate pretty soon. I feel like it's going to happen. It's going to happen. Feel it. All right. We're getting the side eye. A lot of silence from the two maintainers on this call. We're definitely in the last stretch, right? Like we're feeling kind of positive. Obviously, there's still a lot to do. You know, we feel very strongly that the other stuff, the docs and the tutorials and all of that sort of stuff needs to be there when we release. Like it's not 1.0 without like a really great kind of, whether it's, you know, adoption story, whether it's kind of how you integrate, how you deploy, you know, the whole end to end, you know, the tutorials and all of that sort of needs to be there. Partly because, you know, you're nothing without your documentation, but also partly because you only get one chance to launch and if you screw it up you don't get another chance especially with the hype that's been building around SvelteKit for the past, oh I don't even know how long it's been Two years probably Yeah it's been years, literally been years but we need to make sure that everything's like in the right place when we launch so we're taking care of that so there's no time scale but it's not things are going well Yeah What a tease I'm seeing one issue being merged right now so hopefully maybe seven by the end of this podcast. Exciting. So let's move on to the fun part of the episode. No, I'm just kidding. Unpopular opinions Do you guys have any We did tell Penguin to prepare one but we leave him to the end But Brittany you want to go first Kevin ruined mine No, mine was just that Svelte will stay on top of React based on the NPM surveys, like, or download numbers that were, I was just giving people shit. It's fine. i think sean sean stole mine i mean didn't know it was mine to care and then he's changed it and it's even worse now because like i have another one no go for it sean do you want to do you want to go with you because you said it first anyway do you want to go with your original one as well um well no i i like so uh yeah i think last last week we had this conversation about you know is twitter dying or or uh you know or will it last um and i think my my evolves you know my my thoughts over the past week have been twitter as you knew it is already gone um and primarily you know there's just a lot of discussion about like how twitter will run like you know the uptime and downtime but like just the the community and nature of twitter uh is is seems to be uh permanently gone. And let's just say the ownership changes again and it goes back to normal. I think just the illusion that this is a space that you can invest in permanently is gone now. And people are definitely diversifying. And I think definitely Mastodon usage is picking up. I've tried it out recently. It seems to be more developed than I thought. And in particular, I think the data science and developer community are converging on two servers, sigmoid.social. I think, Penguin, you're there on sigmoid. I just created an account as well. And then the general tech community, I think it's on Hachiderm or Hackiderm. And I think that's going to be it going forward. There's just going to be diversification of tech community from Twitter to Twitter and Mastodon. Obviously with other existing like TikTok and LinkedIn, the text-based ones, people are definitely diversifying. Even as of last week, I would have agreed with you, but after seeing the movement, I feel like it's just a small percentage of people. It seems like my circle is kind of moving towards Mastodon, but I don't know if the bigger, greater Twitter ecosystem

 of developers is really moving that much. It's enough that people are clicking that backup button on Twitter, right? That is happening, yeah. The trust is gone. You just don't default to believing that everything that you have on there will stay up, will be accessible at all times. You don't default to believing that there will be decent moderation on the platform. And you don't believe that the timeline will not be taken over by some main character energy that is completely distracting and irrelevant to the things that you actually want to spend time on. So for that reason, I think there's just a number of people who are just permanently off Twitter. There are a number of people who are not permanently off Twitter, but at least significantly diversified away. And therefore, as a content creator, that matters as someone who... I put a lot of my public thinking online for me to search later on. It's specifically for me. I have to start thinking about moving somewhere else I just cannot risk putting it on there anymore That's the conversations that we're having a lot too I'm on Mastodon but companies are starting to think about coming to Mastodon Mastodon is not a place really for companies right now I think they would get kicked off basically We should share all of our Mastodons on the show notes too just in case anybody's interested Well hang on, so Anthony's Anthony's against this. So you go ahead. Well, no, so I'm confused now because everyone's read out my unpopular opinion and I didn't even say it. But, and that was the one that I took because Sean saw my first one and now Sean's first one that I had originally has now disappeared entirely. So I'm so confused, but I will respond. My only thing is I just don't think Mastodon's usable for anyone outside of tech, really. I think it's just, you know, people have struggles. You know, the regular people have struggles handling a user and password and i don't think that mastodon is really accessible for them um so i just don't think it's gonna it might it might be where textivity goes but i think that'll be it which is probably what kind of what you're saying really i just don't think it's got usability and and even the name's not that appealing it's you know some kind of random i don't know what it relates to actually what mastodon is but it's something sci-fi i assume and um what yeah no it's a big elephant is it a big elephant? it sounds sci to me yeah sci knowledge is not great yeah sci elephants they extinct right they extinct they creatures of elephants yeah, out of the five Megazords Master's on with the Black Ranger Megazord wait, hang on a minute and this is not sci-fi are we sure this is not sci-fi? no, it's not dinosaurs Megazord, are you sure? Megazord I don't know, I think you're all trolling me share your other unpopular opinion because it needs to be said it needs to be said yeah it's kind of short sean and mine and it sounds like it's a few people's and it's not unpopular at all but uh md specs should be part of svelte and the only reason i sort of thought the other day is because um you know setting up md specs you've got to follow some instructions and stick it in there and i feel like i would actually want projects to be able to like add a folder add a file with let's say mds you know and a more a more acceptable file name penguin um mds or something and then um and it just and it just worked out the box and i think that would be something a language should have because i see a lot of people's real when everyone mentions jsx on twitter they they always in the same sentence uh mentioned mdx right it's almost like they go hand in hand and we don't have um jsx for obvious reasons but i think if we had like mds or whatever it's going to be um you know as as part of the core i think it's a huge win i documentation absolutely true and i i think that would put us up a little bit on astro too because astro has like that mdx support out of the box and even though you can use felt in it you can kind of use felt along with mdx but it's i think it should be integrated at this point i don't think it needs to be a core package for that to be the case. You know, to have a really easy experience with SvelteKit, you know, it could easily be pre-configured. But I'm probably the barrier to it becoming core. Like I'm probably the only person who thinks that that shouldn't be the case. So that's interesting that you think that it shouldn't be the case. With Svelte add command though, it is very easy to set up. So I guess I will say that it is very easy to add in and you don't necessarily need it to be, but it would be nice to have just access to it out of the box, I guess. Megasword commands you. How about that? Yeah, I make it required in all my templates. I think it just a better way to author most pages by default Unless you really really need to write HTML then go ahead and do that But otherwise most people were better off choosing MD specs I mean I also configure it with a lot of like Remark plugins and stuff So there will never be zero config MD specs. It's just a question of how much config and how much setup. I wonder that too. Like if we could get like actually a package to render the markdown built into it also, that would be nice. Ah, okay. Like you said, you use Remark and stuff and you have to add more configuration to it. That would be... Yeah, that's true. Cool. I'll go quickly on my one. So I think every developer needs to be AI literate. I think this is not a fad. I think everyone needs to know how to leverage AI as part of their jobs because it will increasingly be part of knowledge work. And yeah, that's the long and short of it. I picked Copilot last time. But this is just more general. play around with these things because you will be using more and more of them over the next 10 years. Absolutely agree. I agree. Valid, and now I have something else to learn. There's always something else to learn, Brittany. Yeah, so I have a repo going. If you want to learn along with me, I have a repo for prompt engineering, which is what people are calling, let's call it, for people who are unaware, the progression of software 1.0, 2.0, 3.0. So 1.0 is us writing code manually. Software 2.0 is data defining code from specific machine learning cases. 3.0 is using large foundational models and understanding how to interface with it, but not training your own models. So all of those are levels of AI to which I think the developer needs to understand because these are new forms of software. 3.0 is cryptography. Come on, Sean. I think there's a space for Penguin if you have an unpopular opinion you want to share. So leading off, I have two, just like as a riffing off some of the things that have been spoken. The first one is that if the destruction of Twitter, whatever happens, does lead to fragmentation of communities, that's probably, I think, a good thing. And it's one of the best things that could happen to the Internet is if these communities started to build up in a space that made sense for them rather than defaulting to some generic platform that might not actually be the best environment for them to actually communicate You know maybe artists going back to a more art platform Maybe engineers and tech folk going to a platform that better facilitates communication about tech in whatever way that makes sense. And other celebrities can go to TikTok or something. You know, where maybe platforms where rage is not the most valuable currency isn't a bad thing for discourse online. um but yeah my second one is basically leading off what you've just said sean is that i think that ai companies are not doing a very good job of reaching outside of the ai bubble not reaching outside of existing ml ecosystems to software engineers and figuring paths for and i think there's an element of a meeting in the middle, like you say. Software engineers need to do the work to understand what's available, what the ecosystem looks like, what the current state of the art is, and what's happening. It moves incredibly quickly. Month by month, you don't know really what's going to be going on. But on the same token, all of these AI, ML companies building these tools and services and platforms need to do a better job of reaching out to software engineers, which is, of course, a colossal market that absolutely dwarfs the kind of like the ML ecosystem. There's still more software engineers than there are ML folk. And I think there needs to be more work to reach out to those people, which is obviously conversations that we at Hug and Face have all the time. But I'm sure it's a conversation other AI companies and startups and stuff are having. But it has to happen. And whoever does the best job of that is going to win at the end of the day. if they can bring those people in early before they've, you know, become super literate in AI, then they will kind of like win out in the end. All right. Cool. On your first point, I just wanted to say the only thing that I worry about with that diversification is I do think it's good that communities are breaking up. I just wonder if it's going to make them kind of shallow and in their bubbles and not get outside viewpoints. And for politics, especially like that worries me that I guess it doesn't spread outside the bubble, but it worries me that people aren't seeing other people's viewpoints and things. That's a good point. All right. So I don't have one, an unpopular opinion. Well, I have many, but not today. I don't have time.

 Yeah, picks. What do you guys have? Brittany? Mine is just a TV show. I've been binging, and I hate that it comes out once a week because it's so good. I want to actually binge it and just watch the whole thing. It's the peripheral. Double agreed. And I just got the book, so I'm going to download it and put it on my Kindle and spoil the ending for myself because I need to read the book now. There's a book? I need to get that as well. It's a book series, I think. Yeah. i know yes yeah it's really it's really nice i i've been binge watching it as well uh anthony all right uh yeah i'm gonna get kev to pronounce mine that's the one so what's this anthony it's a show from the 80s that i discovered well a film from the 80s where i was like a bunch of sketches together from the 80s uh from sweden that i discovered randomly on netflix it decided that it was the kind of thing i would like it was to a good extent right to be fair i think my dad would like it more but yeah it's it's basically like it's actually restored and this this scared me a bit because we're now restoring uh footage from the 80s i mean i was alive then that terrifying but um yeah it just a very very strange the guy seems to ask for the telephone which is even worse uh very strange it like a sticky a collection of uh comedy sketch stuff right yeah yeah like like a film made out of a bunch of a bunch of sketches that are very very clearly defined actually so it's uh it's not like a a contiguous sort of uh contiguous sort of uh line but um but yeah it's very strange and i just entertain me maybe maybe laugh for a bit so I just thought I'd write that down so maybe someone else could get exposed to it. Yeah, everyone should watch it. It's funny. It's funny. Every the esoteric picks. Yeah, sorry. It's definitely esoteric. As we said, the one sketch that actually was really probably cracked me up was the last one in that film. So if you decide it's not a view and skip the rest, you should watch the last sketch where they sat at a restaurant because I think that one was great. if it's on YouTube you can try to link it up well mine's very simple one of the more interesting companies other than Hugging Face would be RunwayML I think they recently raised the Series B and essentially it's a video AI toolkit if you're thinking about I think After Effects or you know some kind of other video editing tool they basically applying the entire every single advance in AI they sort of reproduce it and offer it as a product so you can sort of use to edit your videos And their demos are super cool. So if you haven't seen this, I linked a video in the show notes. All right. Penguin, do you have a pick, sir? A pick could be a movie, could be a film, could be something you enjoyed lately. Something you like. The thing is we like to spring these on guests without any preparation whatsoever yes i don't know why we like that it's quite it's quite bad okay we we don't really like that yeah so uh there's a i'm gonna just go with a really local choice but there's a restaurant here in amsterdam called terra zen and it does this like japanese kind of caribbean fusion kind of food and it's it's incredible so if you're ever in amsterdam go to terra zen and and eat at this restaurant that's my prop pick swear you have told or you're the second person that i've heard this from in like two weeks and i've never been to amsterdam and this restaurant must be amazing because like i now need to go to amsterdam just to go to this restaurant it's really good it was it was featured in a youtube video a couple of weeks ago or something actually so i think it become more popular uh recently we even had to it like a tiny it down some random side street It a tiny little place and we have to wait at lunchtime to get a table So it definitely worth a visit Is it Japanese Rastafarian? It's kind of hard to place. It's very fusion-y. The menu is pretty weird, but they do have Japanese people who work there. I don't know if one of the founders is Japanese and one is Rastafarian or from the Caribbean or something. But obviously it's a very strange kind of fusion, but it's like the food is very, very good. So, it comes to Amsterdam. It says, we serve Caribbean and Japanese soul food according to Rastafarian principles. What the hell is Rastafarian principles? I don't know. I can't speak for that. I can't speak for that. It's great. Okay. All right. I think that's it for this week. And thanks for joining us, Penguin. Thank you for having me. It's been a pleasure. We'll see you in a bit when we do an episode on MD Specs, maybe. Yeah. Should be fun. And thanks, everyone, for listening. And we'll see you next week. All right. Bye. Later. See you next week. Bye. Bye.