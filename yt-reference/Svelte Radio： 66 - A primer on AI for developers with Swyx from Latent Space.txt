 Hello, everyone. Welcome back to another episode of Svelte Radio. Today we have video. Amazing. I'm joined by the full crew. Full gang. Yeah. Sean, Brittany, Anthony, what's up? Hey, how's it going? Go out here and then. Yeah, hey, everyone. Today we are going to talk about AI and what it means for developers like ourselves. Where are our jobs going? But yeah, so the person that probably knows most about this here is Sean. You've been diving deep into the AI ML space, as we heard last week. You quit your job and you're doing all things AI. What's that been like? How deep down the rabbit hole have you gone? something i enjoyed about this podcast is that you can slowly trace the my descent into over time um sometime in august i think we're talking about stable diffusion and then sometime in december i was like ai is the future and then and then i disappeared for a few months and now i'm back and i have i'm jobless so ai has taken my job and i have moved to san francisco against my will because it is a terrible city, but it has the best AI events in network. So yeah, have definitely gone down the rabbit hole and happy to answer anything and everything. I have started, I have been cheating on the Svelte Radio podcast by starting a different podcast that is- That you should all go to this one. Yeah, latent.space. I'm very proud of the domain name. Was it actually free? No, it wasn't free. I actually had it on a separate domain. And then the guy who wrote the book, the O'Reilly book of National Language Processing, emailed me and said, do you want the end-of-space for $500? And I said, yes. Wow. I think he made a deal there, right? I think he saw that I was going to do something good with it. So I think he knew that it was like a sort of friendly handover. And anyone who was writing books about AI four years ago is I sure is doing fine financially So fair enough Was it just like you thought AI was the future Is that kind of what dove you down the rabbit hole? Or what started the AI drive for you? Okay, right. So, there is a longer running thread. It is not just like I saw a thing somewhere and then decided to pivot my whole life. I, when I was an options trader, a lot of, and this is when I was in London trading currency derivatives in Standard Chartered. I actually wrote my first NLP application, which was taking prices and quotes from my brokers in Bloomberg and then pasting them into a pricing machine and parsing those text fields. and it was just a simple syntax. Part of those text fields into option prices that I would then use to update my volatility surface. And there was a lot of... And I did it entirely through a regex. It was a cursed, very, very cursed regex. Why? With no tests, because I had never heard of a test at the time because I wasn't a professional programmer. I was a trader that learned to code, right? And it was a lot of fun. But all my traders used it, like the entire global team managing hundreds of millions of dollars. So I should have had a clue that, you know, NLP was going to be a thing, but I never saw it as more than that. I was just saying, oh, it's a simple text parsing. Right. And I think the other thing that has always been on the back of my mind is the progress in image generation. there's this very famous chart about the state of the art in image generation or face generation from year to year to year and you can find one i found one yesterday from 2012 to 2022 so 10 years of image generation progress you can see 12 13 14 like it's very fuzzy not very good not even recognizable as a human face and then 2015 16 17 it starts to get good and that's how you start to get websites like this human or this person does not exist. And now of course generating photo realistic stuff is free, done locally on your machine, or available through MidJourney for $8 a month. And so I think this is, I've always basically just regarded this as the Moore law of our time And there a doubling effect or exponential growth effect And yes I late to it Yes, many of us are late to this. But because something like a Moore's Law does tend to last for a few decades, you are still, in the grand scheme of things, not that late. And so I'm just more interested in this. So if we looked at the adoption as an S-curve, we're probably very early, right? Still? I don't know. It depends what the scale you're looking at, right? As far as very early, meaning the rest of the world doesn't think it's important, that is very early to me. So we are past that stage now. Now it's extremely obvious to everybody. So now we're maybe still kind of early. That's where we're at. We're at that stage, by the way, where Nat Friedman, the former CEO of GitHub, basically calls this a capabilities overhang. There's been so much research done over the past five years, especially with Transformers, that essentially has not been productized by builders, by developers, builders, founders, whatever you call it. And that's why it's time to build. There's shockingly few people trying to do interesting things with AI, even now. I think a lot of people might consider me a relatively fast mover and early adopter, but it took me six months to say, all right, I'll quit my job. And there are a lot more people who are still waiting in the wings, not sure if they want to commit, not sure if this is like a Web3 thing that will be gone next year. and these are all reasonable concerns and I can deal with each of them individually but on this side of the spectrum it looks like there's a ton of opportunity sitting around waiting for people to pick it up I was at a dinner yesterday this is kind of like an AI founders dinner and with people from OpenAI, DeepMind, Google, Facebook the two co-founders of Dropbox the three co-founders of Notion And there were so many ideas that were being tossed around that just nobody was working on. And we were like, all of us were like, yeah, that going to be very important It just like each of us already had a thing So we weren just we were just not going to work on that um but i would love to to encourage more people to explore um i offer one more thing um which is something i've talked about in a previous episode but i will bring it up here just so that everybody has context which is i think that um you should view this as an extension of regular programming so um the kind of programming that we do which is regular sort of if then else programming, right? Like you have a spec from a product manager and then you translate that spec into code, right? Which is a sort of very well-defined thing. A lot of people, a lot of software engineers view that as their job, right? You have a spec translate to code, you have a design translate that to code, and then that's your job. But I think if you think about things as an iterative cycle, which is you have a spec translate to code, and then you instrument with analytics, and the product manager looks at the analytics and then makes a decision again to change something, and then makes another spec, and then you translate that to code. That is a cycle that is essentially learning more from data and then eventually surfacing that in your code somehow. and the ultimate expression of that is going to be some form of multivariate process that is more like machine learning, right? I'll tell you like, okay, so like if you ever write an if statement or if you have like branching logic, right? And it's conditional upon one variable, then you're like, okay, I need two variables. Then I need three variables, I need four variables. At some point, like machine learning is essentially 135 billion variables. Right. Where you have run through an enormous amount of data, something like a few hundred terabytes. And that is an interesting, very interesting foundational use case, a foundational building block for a new set of applications. And I kind of consider that to be a reasoning engine is one of the terms that's kind of going around. It is fundamentally non-deterministic. So we have to figure out new patterns and design patterns and UX affordances to wrangle it. But I think it's enormously exciting. And I feel like software engineers should not be apprehensive. They should figure out how to use it to solve their problems. Do you know, you said it's a time for builders, Sean. I think the way that I know it's time

 builders is if I go on the cell domains and try and type in ai.there is nothing left there is not a single tld uh other than the country specific ones that uh you know like com.af or whatever that is free so it's definitely time for builders I wonder how many of those are actually in use no that's a it's a time for domain squatters for sure um yes um yeah so you know the domain that that I have got and I will be building is small.ai and that costs a little bit of money. But yeah, I'm interested in model distillation, which you can talk about later. I think it's in line with Svart philosophy, by the way. The current trend towards larger and larger models, longer, longer chain, bigger and bigger context is very much react-y, if I'm gonna make a hot take of, have a giant footprint. And I think there's room for a spelt of AI. So when you're talking about the largeness of these things, is that when you're training the AI, basically? Are people throwing more and more information into the training sets? I'm not sure how it works. How much foundational knowledge do you want to cover here? Because I can explain it like I'm five. No, that's probably way more. I'm sure all of you have read introductions and stuff. So I also don't know how to calibrate for what I should assume people know already. Assume no knowledge. Okay, fine. So just to directly answer your question, it is not just for training. It is also for inferencing. So there's essentially a two-stage process, which is that there's an initial pre-trained phase. Like GPT stands for generative pre-trained models. So the pre-training phase is a large, expensive one. And then the inferencing is when you freeze all the weights of the training and you're just making predictions based on your existing prompt. And so that is... Sorry, just interject here. So when you were talking about millions and billions of variables, those are basically, they result in the weights. Is that kind of how it works? Yes Weights and biases And so these are all individual neurons and together they called weights and biases And there a startup by that exact same name that is doing extremely well because OpenAI publicly endorses them And the summation, there's a simple function you can call in PyTorch that gives you the summation of the total number of weights and biases. And that is the parameter count that everyone talks about. Oh, I see. Yeah, yeah. For a very accessible introduction, everyone should be aware that the best introduction right now is Andre Karpathy's Zero to Hero course on YouTube, where he builds it from scratch. Just start from a blank file on Python. Don't use any frameworks. Build the whole thing from scratch. And he builds a very simple GPT generator of Shakespeare solids. And it's still not very good, but it gives you the mental framework. And I really like that because you don't pull in anything else. You have to explain everything from a complete scratch. Okay. The other thing, and then just to finish up the training versus inference, inference is comparatively cheap. And it is what you do when, for example, you download Stable Diffusion onto your laptop and you give it a prompt and you run it on your machine. there's a fair amount of people also working on model optimization, pruning, distillation, and that's the field that I'm playing in. Okay, and then we'll talk, let's talk about like the rough progression in terms of history. The fascinating thing is that each domain, each modality in AI used to have different architectures. So you would have convolution nets for images and then you would have RNNs and LSTMs. It doesn't matter, you can Google these names for text. But they've essentially all converged to using some kind of transformer in the last five years. And this is a fascinating phenomenon and it's also why I actually wrote a post that it is not too late to pivot into AI because this recent transition into Transformers for Everything has essentially been the components era of AI, right? Like you now no longer need to catch up on the previous 15 years because they don't matter anymore because we now know that we have a better abstraction that we call the transformer that is much more scalable um is much more able to uh to to to generate um and and focus on things that we uh that we want out of it um and it has grown a lot um so the the the basic paper that everybody should be aware of is attention is all you need it came out in 2017 um and it was like a relatively low-key thing for a year kind of like uh reacts and maybe Svelte, you know, like when it launched, like not that much hype, like people were just kind of like, it's one out of many papers. And then it took about a year to really pick up. And then Google really led the development of this with BERT, which is, I think, bi-directional encoding representational transformers or something like that. And these are still like relatively small in terms of the grand scheme of things, like a few hundred million parameters. There was a family of models that was all Sesame Street characters, which I think the parents will love. So Bert inspired Ernie and then Elmo. And there was Grover, I think, or Grouch. And then obviously, you know, these are all, yeah, really, really fun. Oh, I would love a Swedish chef model. So the Google brain team loved Sesame Street. The DeepMind team loves animals. So they do like flamingo, chinchilla, gopher. There's the whole model zoo of really cute animals. And I think people have to entertain themselves whenever they're staring at billions of numbers all day long. It's like these things that go into the U.S. Congress. They all have these super long names. And then they end up becoming called something like the reduced. Jedi. Yeah, yeah. Yeah, yeah. That is definitely marketing. Okay, so and then opening eye comes out with GPT. Another fun fact, the lead author of GPT is Alec Radford, three years out from his PhD. Not that much experience. Oh, wow. That's pretty cool. And so this is why I'm saying like, if you're willing to do the work, you don't have to have a PhD. I mean, obviously it helps. But if you willing to do the equivalent work and you have good ideas I still think it an early enough field that you can relatively get to the top of the field in a very short amount of time So that OpenAI and Alec Radford Another similar person that I been tracking is another countryman of mine Yitay from Singapore Graduated from NTU, a local university in Singapore. Not a famous one. Three years later, he's publishing UL2, which is the top of the field model from Google. There's so much opportunity. And my point is, I think that this kind of opportunity exists when a field is extremely early. You do not see this in medicine, physics, astronomy, math. You know, yeah, like because all of those disciplines have had their sort of FUM periods. FUM is that exponential takeoff period. All those disciplines had those periods centuries ago, right? Like only Albert Einstein was able to publish three papers in a row in 1905 that defines everything. But like you could not do that today because all the low hanging fruit has been picked up. And I think definitely we're in that period for something like this discipline. Okay. So as you just jump back and forth into like sort of history and model stuff. gpt1 and 2 came out within a relatively short order of time by the way gpt2 is runnable as a python package you can import gpt2 and just generate it it's it's so ridiculously easy and funny yeah the the basic package that you should look at is gpt2 simple from max wolf minimax here on twitter and then obviously gpt3 can comes out and actually makes zero impact they actually there was a little bit of kerfuffle around the safety of these models and OpenAI refused to release them publicly because it's too dangerous for your benefit. And ultimately they released it and everyone could easily tell between generated and non-generated stuff. So I think that's ultimately okay. And it took a few years. It actually, most people don't remember, but It was released in, I think, 2019, 2020, that timeframe, and didn't really take off until last year. Right, yeah. To me, looking in from the outside, it kind of feels like GPT 3.5 was like the inflection point.

 point? But then there's probably mid-journey and stuff earlier. Yeah. I would say that the inflection point was really stable diffusion, which is counterintuitive because stable diffusion is a text-to-image model and GBT is generated text. But I think stable diffusion got everyone inspired because it's open source running on your laptop and trained by a comparative outsider. Again, another outsider, Imad Bostak, a former finance person like myself, but took four years to go from finance to AI. It's not too long, right? I mean, he definitely got lucky and there's definitely stuff he doesn't know. But also, he learned enough. so yeah I think people started hunting around because the stable diffusion went from zero to you know a billion dollars extremely quickly Jasper AI another top startup went from zero to 80 million dollars in revenue in 18 months which is absurd I heard of that one yesterday actually yeah there's a lot of money in this Midjourney which is a humble little discord server of 5 million people is a team of 12 making $50 million a year. Right? Holy sheesh. Bootstrapped. No VC. Because the founder founded a previous VC company and he was like, I'm not doing that again. So there's all these interesting characters and I think if you strike it rich, you're sitting pretty. It kind of feels like you would think that this all would trend to zero at some point, like the revenues, like they're going to become better and better and better? Yes. This has been a, the B2C options have been very, very spiky or they, yeah, there is significant churn. So the best example of this is the Lenza AI team, which used to do the face lens. I think if you remember a few years ago, there was this trend of uploading your face and then like seeing how it ages or de-ages, or if you're the opposite gender, all that stuff. And so Lensa actually pivoted to a face generation app using stable diffusion And there this amazing revenue chart of them going from like kind of nothing to earning $2 million a day on the Apple App Store. A day. A day. And then, and then fading after two months back to nothing. Because it was an extreme fat. Like everyone was like, oh, I'm just gonna, you know, spend a few dollars and see what my face looks like in AI. And for most people, that is the way that they get involved in AI, right? They're like, I'll try out a new app. And so it's extremely fatty. I will say the really good builders keep building and find new features to offer their users so that they keep coming back. But otherwise, people will try things once and then they'll leave. And I think that is the natural way of these things because people just want to kick the tires. Another person to follow here is Levelsio, Peter Levels on Twitter. he had a similar he was the Nomadlist founder he now started Nomadlist, started a movement around remote work and a really dominant brand around all of that and I think he was making something on the order of 1 to 1.5 million a year based on that, by the way he works by himself with a few contractors he now makes more from his AI apps than all the Nomad stuff that's pretty scary crazy good for him though yeah but he's extremely creative guy and yeah very good hacker and he also has uh he has an audience as well right it's yes yes i mean it's it's not like it helps of course yes yeah yeah yeah a lot of people are like can you do it if you start it over and and he's like and all of us are just like why would you like i worked very hard for this well i think also he was mentioning that um you know people were saying that the interior interior ai thing he did they were saying yeah you know could you build it without this audience and he basically countered it by saying yes he could um because he didn't advertise it by the time it got to x amount of traffic you know he basically told a few friends and they did word of mouth so yeah this is the answer to that yes he could yeah exactly like and and this is only to prove to people who like you know need some inspiration and motivation but i don't i or any other people with an audience like don't owe anything to those people, right? Like I had to bootstrap myself the same way that anyone else did. And so yeah I somewhat defensive of this whole like oh your success doesn count because you already had an audience previously Like no I mean that not really what I meant It just what they have I didn't get my audience. No, no, no, not at all. You guys are friends, obviously. I'm just hearing how it feels like, how it sounds like to us when people say, oh, you already started an audience. All your advice is completely irrelevant. but no i didn't get my audience of 2500 spam bots and 500 real people on twitter by you know without any effort took a lot of work that's all those unpopular opinions yeah you're talking too much about like bike lanes in london exactly exactly exactly that's that's that's the 500 real ones it's probably about half of those actually all right sorry uh so so okay so so Okay, so maybe I'll cover one more thing, which is people should you should be aware of the main modalities that people are playing with. So we covered generative image, generative text, generative images. There is also audio, which essentially is two directions, right? Like text to audio, audio to text. And audio to text is probably the more promising one. And that is opening a whisper, which is a fantastic state of the art. model. We use that for transcriptions for the podcast. Yeah. And I'll talk about a few issues there. For text to audio, the leading one right now is 11 Labs, which does voice synthesis. I haven't personally tried that. And that's, I think, a lot of... I've tried it. How do you like it? So I played a couple of clips for Brittany and Anthony. And it doesn't sound like me it like you can hear that there's some some inspiration of me in there but it's what did you call it anthony it's it's it sounded like it has your tone but it's missing your accent so there's no authenticity in your voice like it doesn't sound exactly like but it does sound like a person yes it yeah it does like a midwestern us person midwestern us whose balls haven't dropped basically yeah it honestly sounds like every podcast that i've listened to it recently they all have that voice and i don't know why yes yes oh geez non-regional non-specific uh very much so i think sorry sorry no go ahead i was gonna say i wondering if they do that but um if they do use ai tools who knows Maybe Well I think it just the state of the technology and obviously it will improve Google actually has a project where it does match the voice tone and accent much closer. But this is a very common phenomenon with Google. They'll announce that they have something and then not release it. So you can't even try it out yourself. You just have to take them at their word that the results or samples that they produce are representative of the models that they've trained. And so Google, you know, there's this whole issue between the big war and a proxy battle between Microsoft versus Google via OpenAI. I think very much Google's on the back foot. And they've essentially been the Xerox park of our era where they funded a bunch of research. And then other people that they funded essentially have left and all started their own amazing companies. And Google is left with declining revenues in search and complete chaos of a house. I do think that Sundar Pichai, there's nothing he can do. He will be fired in a short amount of time. He has completely mismanaged the biggest revenue engine on earth. Yeah, they've pretty much just coasted, it kind of feels like. Yes, yes. This is a very common phenomenon, right? Fat times make weak men, and weak men make hard times. Hard times make strong men. So there's other modalities. So we talked about images, text, and audio. And then I think code is a very interesting subset of text. and I can talk about code a bit, but I want to finish out the modalities. I definitely track all of them. I do have a, for those who are interested, I actually have a public GitHub repo where I track all this stuff. So if you go to AI Notes on my GitHub, you'll see all of this. So there's other modalities like text to video is something that a lot of people talk about. I'm completely uninterested in text to video because I think that it is so far away that it is just not useful. Yeah. Then there is math, solving mathematical equations and related problem with that is physics. Sam Altman's stated goal for what AGI is, is that it is able to independently discover new rules of math and physics, because then it has essentially

 it gone from symbolic and probabilistic generation of text that is plausible sounding to actually true things. Right. Yeah. Yeah. Because you can actually prove, prove, prove stuff with math. Right. Yeah. And then there's also, there's also a couple other fields of AI UX, which is the meetup that I started in San Francisco and it's, it's going to be starting in New York city pretty soon. And we can, we can talk about all how all UX developers have a lot of opportunity in AI. And actually, I think you have more job security than back-end developers. Then we can also talk about agents, which are sort of language models that are run in an infinite loop. And we can also talk about medicine, semantic search, robotics. It starts to get more and more and more speculative the further out you go. But the core modalities you should be on top of, which is images, text, audio. So be familiar with all the main tools and startups and companies in those fields. If you want to build with them, try to figure out the main tool chains and tools. I have a list that I can send along, but it's also always changing every single day. So it's really hard to record on a podcast. But OK, I'll come back to code. So yesterday, I released my interview with Replit, which released and trained their own code model. And it was my top performing post of all time. It was on Hacker News for an entire day. Like I woke up this morning, it was still there on the front page. Yeah, it was crazy. And it's very hard to get a podcast to rank on Hacker News because people, they don't want to listen. They just want to read and then they start mouthing off about some opinion and they have another. Just read a title and go comment directly. Yeah, yeah. So there's an interesting correspondence between code and language. because the way that you train them is very similar. And I think that's my internal discovery from doing this interview and doing this podcast with all the AI founders and builders in this space. So code, why is what? So there's an interesting phenomenon where like the typical corpus of language models is that you take text from the web. So like Reddit posts website scraping restaurant reviews and all that So it not intuitive that adding code to that mix would actually improve its ability to reason and to generate plausible sounding text And I realized after talking to the Replic guy, I realized why this is. Code is just very highly structured natural language anyway. And the way that we write comments and then pair them with our code actually is very good training data for them for the model to learn what what that makes sense yeah yeah so i was like after after i saw that i was like oh like we like code is actually the uh the way that we communicate extremely clearly because it communicates precisely what we want if we're not vague enough we get punished for it uh if we're too vague we get punished for it and i i just think it's such a fundamental insight so what what repli did was very interesting they only trained their um their their model on scraped code from GitHub and Stack Overflow, and then from Replit's own data. And they were able to beat the other models on common sense reasoning tasks. These are, when I say common sense reasoning tasks, they're established benchmarks that explain what common sense would be for a human to interpret things, right? Like when we interact with things physically. So my example of this would be, for example, there will be a multiple choice question and it will be something like the the tree's shadow grew longer in the grass right and then and then the question would be why did why were the tree why did why did the shadow grow and the answer would be the sun rose or the sun the sun was setting and nowhere in the prompt or the question mentioned the sun but you had to infer and the model had to infer from the context of the shadow growing longer and the tree being being being being vertically present, that there was movement in the sun, and to conclude that. And so that is the kind of common sense reasoning benchmark that this code model, trained purely in code, was able to do well at. That's very interesting, because I'm sure not many people have written code that is even remotely, well, I guess maybe, like code for that thing. So included in code is also a lot of markdown, right? Yeah, that's true. Yeah yes So documentation on code too Yeah So what is interesting just to broaden out a little bit because I think code models and copilot is super interesting as well but just to broaden out a little bit what we're doing with pre-training is essentially building foundation models that other people can build off of. Meaning that what's beautiful about this new form of open source, which is not just open source code, but open source data and weights, is that teams of people at Facebook and Google and OpenAI are spending millions and millions of dollars. GPT-3 costs something like $50 to $100 million to train. And essentially, you can buy them for something like $2 per 1,000 tokens. Or they open source it and it's free. And so then you can take it and fine-tune it and do the last mile thing for your use case. but someone else has already done the hard work of trading the big core thing that costs millions of dollars. And I think there's an interesting correspondence between this and the way that we build frameworks, right? There's always a core team that takes on the hard job of maintaining and building the core thing. And then us as developers take that thing and then build the last mile for our application. The actual applications. Yeah. So how does, so if we go from one of these models that is, I guess, more general? And then say we wanted to build a Svelte documentation bot. How would we go about doing that with, for example, GPT-4? Yeah. You don't need GPT-4 for that. You just need GPT-3 or 3.5. The best way that we know how to do it right now is that you embed all your documents. There's a process called embedding which is essentially translating all the text into code, into numbers that represent both the tokens and the words that are being presented and the positions of those words so that you sort of store the meaning of your sentences. So you embed all those things. Embedding is extremely cheap. So everyone just embeds willy-nilly. Store them in a vector database, whether I've been working out of, I'm currently in the offices of Chroma, which I'm an investor in. Or you can use Pinecone, which is a popular one that just raised a $700 million valuation, which people think is extremely overhyped, but whatever. Or you can store it inside of a regular database like Postgres which also has extensions for vector storage And essentially what you do with every query then is you type in a query for what you looking for You embed that query to translate into a series of numbers again. You punch that, you put the number into the vector database and look for the top five most similar strings of numbers that are also in that neighborhood. It's kind of like a zip code, right? Like you're translating a series of address into zip code and you just look for the nearest neighbors of that uh of that of the of the of the query then you take those those queries that you uh the results those top five results put those as context into your prompt and then ask your question again um and that will generate the answer that you're looking for uh as the process so that that is the rough uh process of retrieval augmented generation it looks like antony has to go right um there there are there are steps to that And there's tools that you can use like Blankchain, but you don't have to use them. I've just described everything that you need to know to do that. You can do that in raw JavaScript, raw Python. And it's completely fine. So it doesn't sound too hard to do something like that. Yeah. Because I saw Astro had some kind of thing where they did it. It's called Houston AI? Yeah, I just met Ben Holmes, who actually did that project or was involved in the project somehow. That's the whiteboard guy, right? That's the whiteboard guy. Yes, he brought a mini whiteboard to San Francisco for the conference that we're at. It was just so cute. So he started posing with his whiteboard. Yeah, so there's tricks to that. I just described the basic tier. If you want to get really good, you should look into hypothetical document embeddings, hide for short and what that does is it improves the embeddings and the quality of the answers and so there's a lot of research out there that improves things but usually it's just a bag of tricks that you just apply and just kind of learn these tricks over time that is not that interesting that is not that hard or interesting to be honest so now things have definitely moved on towards agents and like you know more interesting applications I think sort of you know docs better document search or generated search, generated answers from your documents is kind of passe now. But still, I think it's a very good starting point for most people to actually start playing around with these applications. The one thing that you have to worry about is context length, right? So the default GPT-3 context is 4,000 tokens.

 A token is essentially a set sequence of words. So, for example, in the word like Britney, Britney might be two tokens, Brit and Ni, right? But you just got to serialize them into specific numbers. So, like, maybe it's represented by five and 403, right? And those things always represent Brit and Ni. so and by the way there's a you can actually see this for yourself i think if you go to platform.openai.com and then you look for tokenizer you can actually just punch in words and see those see those numbers for yourself and there's also and so there's a vocabulary of about 50 000 tokens and there's also very fun tricks that have arisen based out of the corpus of data that this tokenizer was trained on which is that if you punch in space this the leading space very important and solid gold magic carp. That is one token, not 10, not five or 10. Yeah. And that's just because that came up a lot in the training data because of Twitch plays Pokemon. This is very, very, yeah, it's very super random. It's wild. There's a lot of very interesting, you know, niche discoveries that actually break the illusion that you're talking to a real AI. this is a simulation of the thing not the thing but we get better and better over time okay what was I going to say I think there's a lot of interesting discoveries that make sense I think it's just very fascinating on one hand I think I'm more excited by tech than I have been in a while and it just feels good to be in the middle of it. Yeah, and all this is public. Everyone's freely discussing it, trying to figure out what they can do with it. And they are doing useful things with it. I would say that there's actually real use cases. So speaking of use cases, as a Svelte developer or a web developer in general, back in front and anything really, what kind of tools are there out there right now that you can use? Are there any like I like obviously like chat GPT, you can ask questions, but are there more fine tuned ones for for web development For web development specifically I mean I think it going to be Copilot or Replit or Codium which is another Copilot alternative that is free and faster and just has different training data. I think there's also this set of tools that essentially are code review bots or AI commit, like GitHub, Git commit description writers. They're super interesting. There's a project called Wolverine that actually starts to write code and that is self-healing because of the Wolverine mutant capability. Oh, right. Yeah. And so like, but these are all relatively newer. Like we're not actually sure which one of them is actually going to do a great job. I think AI commits is a really fun one. Like basically, you want to basically hand over small problems that are a lot of boilerplates. And I think personally, I'm quite interested in test generation because people, as we well know, don't write enough tests. And, you know, so as long as we can generate a suite of tests, right? Because like, why is it that we write some code and then we write one test and then we're like, fine, we'll ship it. And then we discover a bug and then we're like, all right, fine, we'll fix the bug. And then we're going to test with that bug and then we ship it. And so we accumulate tests linearly, but actually we should just add thousands and thousands of tests. Because if it costs nothing to generate the tests, then why don't we just fuzz everything, right? Like just have a bot run through all the possible scenarios, all the usual testing strategies that are just copied and pasted from a previous project. We all do this, right? Let's not kid ourselves, right? Like this is all not the most fun part of our jobs, but it actually does help. So yeah, let's employ AI to do that. And there's a company called Codium without the E. This is really stupid. I know. There's Codium with the E, and that's the co-pilot alternative. And it's Codium without the E. That is a test generation company that is based out of Israel that raised an $11 million seed round, which is an absurdly high amount. That's a lot. Anyway, so there's all these companies. There's other people working on this problem, which I think is super interesting. But at some point, that will reverse. I actually do think that will reverse. At some point when we confident enough in code generation we will write the test and the AI will write the code Because we only really care about the test passing as people who make products So we actually need to make the, you know, whenever I want to make a change to my code, instead of changing the code itself, I will just change the test and just let the AI figure it out. Yeah, that makes sense. And then the final tier is instead of writing the tests or the code, I would just write the Jira ticket. Yeah. That would be kind of a spec, right? But more in natural language, I guess. Okay. So basically, for now, generate tests, handle PRs, like review code, stuff like that. That's probably what it's good for right now. Yeah. I think everyone should also, so this is not widely available to everybody yet. But I think if you try to contact someone at OpenAI, they'll give you access or just wait a few months. You should also be on top of ChatGPT plugins. I think that is a big avenue of potential. That is essentially the new app store. If you remember when the iPhone came out and they launched the App Store, there was a big rush for developers to try to take advantage of this platform. Chaggbt itself is still insanely primitive, as powerful and as world-changing as it has been. It's still very primitive. The way that it uses plugins is still very primitive. But the way that you code plugins with a mix of English and code and an open API spec, I think is a new programming paradigm that I really struggled to get around in my first day of coding with it. And then you're like, oh, okay, this is how all plugin systems should be. So do you have an example here of what a plugin could do? Yeah, you can just look at the ChatTpp plugins blog posts and video, and they demonstrated. So, for example, if you enable the Wolfram plugin, And it would give ChatTBC the ability to call out to Wolfram and do math or look up scientific data and not hallucinate them because it's just kind of reporting from an API. Or you can search hotels or flights and book them through chat and do all of them in the same session. And I think the most interesting effects will happen when plugins can talk to other plugins through a central chat interface which is very interesting Because I saw some videos on something called AutoGPT Yes. I don't understand quite how it works because it's kind of like GPT talking to itself. A little bit, yeah. It's doing its own reasoning. So AutoGPT is a different class of application called agents that is not chat, but it looks like chat. I can see why you're thinking about that. It also has the ability to do tools. Yeah, go ahead. Yeah, so sorry. I was thinking like, so AutoGPT, so an agent, I guess, could then talk to GPT, I guess, that would have some plugins enabled and do stuff there or something. Yes. I don't know. yeah okay yeah so yeah exactly so uh the components of an agent i actually had a blog post about this that did pretty well it's called the anatomy of autonomy which uh i i really liked i was very proud of myself for coming out that name by the way i live streamed the entire writing on that blog post so if you want to see me write for six hours uh you can see you can see my youtube yeah i think i saw that on youtube yeah like not the whole thing i just saw you streaming i know nobody sticks around for the whole thing but sometimes people drop by and i'll like chat with them for a bit, also using StreamYard, by the way. So the anatomy of autonomy starts with the base layer being language models, second layer being memory, third layer being web browsing for memory that it doesn't have yet, right? And then fourth layer being tools, connecting it up to Twitter, to GitHub, to your file system, whatever, right? And obviously, the web browsing is already a kind of tool, except that web browsing is read only and then tools are read and write. And then finally, the fifth layer, which is the most important and unknown layer is planning and prioritization, which is that, hey, I give you an objective, go figure out how to do it by yourself. Right. And that is actually an area that we know GPT-4 and all its predecessors are still bad at because it doesn't plan. It just predicts the next token. And so that's fascinating because we have now found an area that we want to improve. And therefore, a lot of the research going forward is actually going to focus on planning and prioritization, because we know that this is the next component in terms of building an autonomous agent. And I think that is

 useful to try out. Because even though we know it does badly today, if you try out BabyEGI or AutoGPT, you can see how it might work if it was a lot better. And that's what a lot of people are giving credit for these days, which is dreaming rather than being practical, which means that we're definitely in the mania phase of AI, where completely trivial projects that were done in a day get hundreds of thousands of GitHub stars. Yeah, this AutoGPT, so for those who don't know, if you go to AutoGPT's repo, they have more stars than PyTorch, which is the machine learning framework that it's based on. It will probably overtake React at some point pretty soon. And it's absurd. For the amount of value that it actually does, it is absurd. So people definitely want to dream and they're very interested in the AI future and more power to them. But for the rest of us, either you want to get on the hype train and sell dreams to people, or you figure out practical usage in your day jobs and apply that. And I make no value judgments as to which of those activities is more valuable to spend time in. Because definitely the people who help people dream are getting a lot of VC funding right now. Right. I guess it's more of a couple of years down the road kind of value rather than right now. Yeah. Cool. So that was a very good, nice primer on what the heck is happening in AI. I don't know if Brittany, you're muted. I don't know if you had. Yeah, I was going to ask if you had a take at all on Jeffrey Hinton's and leaving and saying, about the dangers of AI and that kind of stuff. Who is Jeffrey Hinton? One of the co-founders of deep learning. Godfather of AI, they call him. I think, so the famous moment that everyone was kind of deep learning pilled as opposed to traditional machine learning where you have a lot of understanding of the variables. In deep learning, you have so many hidden layers. GPT has 96 layers that you have no idea what they represent They just kind of represent abstract concepts that are in the latent space as they call it So Jeff Hinton was Alex advisor for AlexNet in 2012 when they solved ImageNet as a competition And that started the tenure cycle that has now led to deep learning for everything. And by the way, so Jeff Hinton, Joshua Bengio, and Jan LeCun were the three Turing Award winners of 2018. that they all got awards for deep learning. And so two out of the three of those Turing Award winners are now warning against the dangers of AI. And Jan LeCun is always the odd guy out because he likes to be extremely contrarian at every single thing. So AI safety debates, first of all, I think developers don't have a monopoly on them. And I actually try to spend less time on that because this is discussed a lot in the political domain by a non-technical podcast. And so I don't think it's super, like we don't have particular insights on safety. Even though we work on technology, we don't have particular insights on the social societal impact of technology. So I think we should be circumspect there. I will say that, yes, I am worried. The evidence of history points towards every time a native population encounters a more advanced civilization the native population gets wiped out it's extremely brutal and it's not even like sometimes it's intentional from the invading population but sometimes it's unintentional, we just show up and we're just like, oops we cut off all your food brought you disease brought you diseases, yes exactly and what we are encountering if you if you take this this logical conclusion is we are actually giving birth to a new life form which is artificial intelligence and you need to think about this in terms of like the span of hundreds of years not not our lives not our lifespans and so we have to be extremely careful because it it knows like one instance of this intelligence knows a lot more than any of us will ever learn in our lifetimes, can think much faster than us, is capable of increasing more things over time. And if we aren careful like that life is extremely fragile and there a very small range of conditions under which we exist If we break any one of those conditions by accident we may not be able to reverse it and with that we done ending on a on a on a happy fun super happy note yeah i mean like it's worth discussing and it's putting awareness so uh this is fundamentally okay i'll end it this way this is like ai safety is fundamentally at odds with individual freedom capitalism and democracy because there is no such thing as uh unilateral safety we all have to agree because it takes one person to disagree, to pursue money, to disregard safety in pursuit of money for the prisoner's dilemma to break. And then everyone pursues money. And that's essentially what OpenAI has done. Anthropic has now also gone from non-profit to for-profit. Illicit has also gone from non-profit to for-profit as well. And it is pretty alarming because this train doesn't stop until you nationalize Google and Microsoft. And there's no standards and there's no groups that like federate it, right? There's no standards and no groups. No, no, not right now. So at some point, at some point there will be some kind of commission that regulates these things, but they may be too late. And the secret is out such that China will do it before. the US. Yeah, I was going to say if a country bans AI, or I don't know, that's probably... It would just move to a different place. Yeah, exactly. It's kind of like cryptocurrency in a sense. It just moves to where it's still legal. I would probably mean like AI, crypto, handshake, and then tokens. AI, crypto, handshake, GPUs. I mean, if you think about it, like cryptocurrency is the payment systems for AI, right? Because no one can control it. No, I disagree with that. Really? Yeah. I would think they would start making transactions at some point with each other to buy services, but yeah, I don't know. I guess we'll see. Anyway so yeah we have got to the do we end democracy and capitalism part of the conversation which I think is a good stopping point Cool All right So I guess we still have two sections that we always do. So first one, unpopular opinions. I don't have one again this week. And Anthony is not here, so he doesn't have one. What about you guys? Do you have one? I don't. Yeah. Yeah, I don't. I just dropped this whole, you know, the only way to end democracy and capitalism. And it's, yeah, that's my unpopular opinion. That was kind of our hot take for the episode. For those who want more of my writing on this, look up A.I. Moloch, M-O-L-O-C-H, which is, that is the description of the race that we're in. A system that we're in that nobody particularly designed, but we're all trapped in. And there's kind of no way out unless we all collectively decide to stop playing. yep that's hard yeah okay I guess I guess we get to pick something nice then for our picks yes do you have any picks Brittany I almost wrote in there Night Agent we watched it a few weeks ago but last week I picked The Diplomat and I didn't want to pick another TV show but I don't know oh I really want to see that I'm a huge fan of Keri Russell it was really good i picked that last week and like it was from the writers of homeland and i really enjoyed the the series night agent was also of a similar kind of style like government agent does stuff and it it was cool i was i liked that too awesome so what's your what's your pick then or is that or is that your pick that's that's my pick i didn't have another pick i just didn't pick another show i didn't know by the way like i think you know the parents in the audience would always appreciate like a parenting pick in case you have any yeah my calendar like putting everything on my calendar is the only other people can't pick your calendar well no but like putting everything on your calendar like just whatever calendar app you use or whatever thing you use just anything like picking up kids like their their classes taking the garbage out like everything goes on my phone. Oh, everything. Literally everything so that I know when I have to... Because I can't keep it in my brain. I need space for other stuff. Wouldn't you like an AI assistant that did that for you? Yes, I need that. Yeah, I saw... I think...

 I think it was called Lindy AI. Yes, Flo Cervello. Actually, I need to interview him for my podcast. He's a good friend. So Lindy AI is like, actually, I'll pick that. It's like, I haven't used it. I don't know if it's out, but it looks cool. Yeah, check the demo. There's a very good series of videos, very short videos, where he introduces it. I think it's very well produced. Oh, I don't think I've seen those, unless it's those on the website. Yeah, I'll pick Lindy AI. It's like a personal AI assistant. Did we talk about Opus Pro? No. You picked that too? Yeah, that's true. I'll pick that. I'll pick that. I'll pick both. Opus Pro is another, I think, AI that does, you link it, YouTube videos, and it automatically generates YouTube shorts for you out of that longer video. And I actually used it and I posted two clips to the Svelte Society YouTube channel I don think anyone has noticed so I assume it doing a good job i looked them over and it looked fine so yeah that that a good tip yeah i actually quite impressed with the short stuff that you've been doing on the youtube so uh big kudos for that i actually need to learn how to do this um i can show you it's actually very very very easy like very it doesn't It doesn't take a long time. Any tool that you will shout out? Just for the listeners? The one I've been using is called Capwing. Yeah. Yeah, yeah. I need to try that. OK, so quickly, mine, one, so if you are loading in ChatGPT by navigating to it on a tab in your browser, you are doing it wrong. You should have a menu bar app. And so my menu bar app is ChatGPT Mac. It's an open source app. I have it on my GitHub. And literally, I do a command shift G, and it opens up in a very tiny window. I type in my question and it generates there and I dismiss it right away And it just shows like zero just shows up That great I need this Yeah What was it called Sorry ChatGPT Mac I don't know. It's on my GitHub. I'll drop it into the links. And I mean, but you can write your own. It's not very hard. Like literally, this is an embedded browser window that is a Mac app, right? That is a Tori app because electronics are extremely heavy. Which means you can also customize it with file if you want. but that's not strictly necessary. And then the other one I'll shout out just because we're doing two picks per person today. If you're feeling overwhelmed, you're not alone, right? I do think that there's too much, especially if this is not your day job, you just kind of want to dip your toe. So first of all, my newsletter is, I try to do that for people, but the one that I use is Andrew Yang's newsletter from The Batch. It's called The Batch. It from deeplearning which is his company All right So cool The patch All right Sweet Cool The patch All right I think that's it for us. It was a very high signal podcast this week. I liked it a lot. I'm definitely going to explore AI a bit more after Svelte Summit. Well, Svelte Summit's already been when this goes out. Talking in future terms here. Yeah. Unless we release this now on YouTube. Up to you. Who knows? For the subscribers. For the subscribers. Oh. All right. I recently paid for my first YouTube channel. Oh, interesting. All right. So, yeah. Thanks, everyone, for listening. Sean, I guess the latent dot space is the place they go for your podcast. Yeah. And yeah, I'll see you all next week. Bye-bye. See you next week. Next time.